{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from m4_feats_functions import *\n",
    "from m5_models import *\n",
    "from m7_utils import *\n",
    "from m3_model_params import lgb_params_1, xgb_params\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm  # Import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the train and test directories\n",
    "INPUT_DIR = 'kaggle/input/linking-writing-processes-to-writing-quality'\n",
    "FEATURE_STORE = 'feature_store'\n",
    "train_scores = pd.read_csv(f'{INPUT_DIR}/train_scores.csv')\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "train_dir = 'feature_store/train'\n",
    "test_dir = 'feature_store/test'\n",
    "# Usage\n",
    "seed = 42\n",
    "n_repeats = 5\n",
    "n_splits = 10\n",
    "target_col = 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.622802\n",
      "New best RMSE: 0.622802\n",
      "LGBM Average RMSE over 50 folds: 0.606161\n",
      "New best RMSE: 0.606161\n",
      "LGBM Average RMSE over 50 folds: 0.611611\n",
      "LGBM Average RMSE over 50 folds: 0.612280\n",
      "LGBM Average RMSE over 50 folds: 0.619868\n",
      "LGBM Average RMSE over 50 folds: 0.607789\n",
      "LGBM Average RMSE over 50 folds: 0.607032\n",
      "LGBM Average RMSE over 50 folds: 0.612013\n",
      "LGBM Average RMSE over 50 folds: 0.618102\n",
      "LGBM Average RMSE over 50 folds: 0.620845\n",
      "LGBM Average RMSE over 50 folds: 0.615602\n",
      "LGBM Average RMSE over 50 folds: 0.606533\n",
      "LGBM Average RMSE over 50 folds: 0.620912\n",
      "LGBM Average RMSE over 50 folds: 0.625116\n",
      "LGBM Average RMSE over 50 folds: 0.611155\n",
      "LGBM Average RMSE over 50 folds: 0.622289\n",
      "LGBM Average RMSE over 50 folds: 0.609465\n",
      "LGBM Average RMSE over 50 folds: 0.603816\n",
      "New best RMSE: 0.603816\n",
      "LGBM Average RMSE over 50 folds: 0.618701\n",
      "LGBM Average RMSE over 50 folds: 0.614396\n",
      "LGBM Average RMSE over 50 folds: 0.621933\n",
      "LGBM Average RMSE over 50 folds: 0.608788\n",
      "LGBM Average RMSE over 50 folds: 0.617259\n",
      "LGBM Average RMSE over 50 folds: 0.620534\n",
      "LGBM Average RMSE over 50 folds: 0.624707\n",
      "LGBM Average RMSE over 50 folds: 0.605975\n",
      "LGBM Average RMSE over 50 folds: 0.608382\n",
      "LGBM Average RMSE over 50 folds: 0.621535\n",
      "LGBM Average RMSE over 50 folds: 0.617372\n",
      "LGBM Average RMSE over 50 folds: 0.623978\n",
      "LGBM Average RMSE over 50 folds: 0.612969\n",
      "LGBM Average RMSE over 50 folds: 0.614495\n",
      "LGBM Average RMSE over 50 folds: 0.619603\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m test_predictions_df\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m test_predictions_df \u001b[39m=\u001b[39m random_param_search(train_feats, test_feats, \u001b[39m200\u001b[39;49m)\n",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Train and evaluate model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m boosting_type \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mboosting_type\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m test_preds, _, rmse, model \u001b[39m=\u001b[39m cv_pipeline(train_feats, test_feats, params, boosting_type)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m new_iter \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m: [rmse],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m(model\u001b[39m.\u001b[39mget_params())}\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_lgbm_randomsearch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m test_predictions_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([test_predictions_df, pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mnew_iter)])\n",
      "File \u001b[0;32m~/Projects/Kaggle/linking-writing/m5_models.py:77\u001b[0m, in \u001b[0;36mcv_pipeline\u001b[0;34m(train_feats, test_feats, lgb_params, boosting_type, seed, n_repeats, n_splits)\u001b[0m\n\u001b[1;32m     74\u001b[0m train_feats\u001b[39m.\u001b[39mreplace([np\u001b[39m.\u001b[39minf, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf], np\u001b[39m.\u001b[39mnan, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     75\u001b[0m test_feats\u001b[39m.\u001b[39mreplace([np\u001b[39m.\u001b[39minf, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf], np\u001b[39m.\u001b[39mnan, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 77\u001b[0m test_preds, oof_preds, rmse, model \u001b[39m=\u001b[39m run_lgb_cv(train_feats\u001b[39m=\u001b[39;49mtrain_feats, test_feats\u001b[39m=\u001b[39;49mtest_feats, \n\u001b[1;32m     78\u001b[0m                                          train_cols\u001b[39m=\u001b[39;49mtrain_cols, target_col\u001b[39m=\u001b[39;49mtarget_col, \n\u001b[1;32m     79\u001b[0m                                          lgb_params\u001b[39m=\u001b[39;49mlgb_params, boosting_type\u001b[39m=\u001b[39;49mboosting_type,\n\u001b[1;32m     80\u001b[0m                                          seed\u001b[39m=\u001b[39;49mseed, n_repeats\u001b[39m=\u001b[39;49mn_repeats, n_splits\u001b[39m=\u001b[39;49mn_splits)\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m test_preds, oof_preds, rmse, model\n",
      "File \u001b[0;32m~/Projects/Kaggle/linking-writing/m5_models.py:50\u001b[0m, in \u001b[0;36mrun_lgb_cv\u001b[0;34m(train_feats, test_feats, train_cols, target_col, lgb_params, boosting_type, seed, n_repeats, n_splits)\u001b[0m\n\u001b[1;32m     47\u001b[0m X_valid, y_valid \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mloc[valid_idx], y\u001b[39m.\u001b[39mloc[valid_idx]\n\u001b[1;32m     49\u001b[0m model_lgb \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mLGBMRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlgb_params, verbose\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39mseed)\n\u001b[0;32m---> 50\u001b[0m valid_preds_lgb, test_preds_lgb \u001b[39m=\u001b[39m run_lgb_model(model \u001b[39m=\u001b[39;49m model_lgb,\n\u001b[1;32m     51\u001b[0m                                    X_train\u001b[39m=\u001b[39;49mX_train, y_train\u001b[39m=\u001b[39;49my_train, \n\u001b[1;32m     52\u001b[0m                                    X_valid\u001b[39m=\u001b[39;49mX_valid, y_valid\u001b[39m=\u001b[39;49my_valid, \n\u001b[1;32m     53\u001b[0m                                    X_test\u001b[39m=\u001b[39;49mX_test, boosting_type\u001b[39m=\u001b[39;49mboosting_type)\n\u001b[1;32m     55\u001b[0m tmp_df \u001b[39m=\u001b[39m train_feats\u001b[39m.\u001b[39mloc[valid_idx][[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     56\u001b[0m tmp_df[\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m valid_preds_lgb\n",
      "File \u001b[0;32m~/Projects/Kaggle/linking-writing/m5_models.py:16\u001b[0m, in \u001b[0;36mrun_lgb_model\u001b[0;34m(model, X_train, y_train, X_valid, y_valid, X_test, boosting_type)\u001b[0m\n\u001b[1;32m     12\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train, \n\u001b[1;32m     13\u001b[0m               eval_set\u001b[39m=\u001b[39m[(X_valid, y_valid)], \n\u001b[1;32m     14\u001b[0m               callbacks\u001b[39m=\u001b[39m[lgb\u001b[39m.\u001b[39mearly_stopping(\u001b[39m250\u001b[39m, first_metric_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)])\n\u001b[1;32m     15\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)  \u001b[39m# No early stopping for DART\u001b[39;00m\n\u001b[1;32m     18\u001b[0m valid_predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_valid, num_iteration\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mbest_iteration_)\n\u001b[1;32m     19\u001b[0m test_predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test, num_iteration\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mbest_iteration_)\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1034\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     init_model: Optional[Union[\u001b[39mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLGBMRegressor\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1048\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1049\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1050\u001b[0m         X,\n\u001b[1;32m   1051\u001b[0m         y,\n\u001b[1;32m   1052\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1053\u001b[0m         init_score\u001b[39m=\u001b[39;49minit_score,\n\u001b[1;32m   1054\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1055\u001b[0m         eval_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[1;32m   1056\u001b[0m         eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[1;32m   1057\u001b[0m         eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[1;32m   1058\u001b[0m         eval_metric\u001b[39m=\u001b[39;49meval_metric,\n\u001b[1;32m   1059\u001b[0m         feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m   1060\u001b[0m         categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[1;32m   1061\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1062\u001b[0m         init_model\u001b[39m=\u001b[39;49minit_model\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1064\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/lightgbm/sklearn.py:842\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    839\u001b[0m evals_result: _EvalResultDict \u001b[39m=\u001b[39m {}\n\u001b[1;32m    840\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 842\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m    843\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    844\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[1;32m    845\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[1;32m    846\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[1;32m    847\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[1;32m    848\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    849\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[1;32m    850\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m    851\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[1;32m    852\u001b[0m )\n\u001b[1;32m    854\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n\u001b[1;32m    855\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_best_iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster\u001b[39m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[39m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/lightgbm/basic.py:3658\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3657\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3658\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle,\n\u001b[1;32m   3660\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3662\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "\n",
    "def random_param_search(train_feats, test_feats, n_iterations):\n",
    "    # Define parameter ranges\n",
    "    param_ranges = {\n",
    "        'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "        'num_leaves': (15, 150),  # Range for num_leaves\n",
    "        'learning_rate': (0.01, 0.2),  # Range for learning_rate\n",
    "        'max_depth': (5, 20),  # Range for max_depth\n",
    "        'min_child_samples': (5, 50),  # Range for min_child_samples\n",
    "        'reg_alpha': (0, 1),  # Range for L1 regularization\n",
    "        'reg_lambda': (0, 1),  # Range for L2 regularization\n",
    "    }\n",
    "\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_params = None\n",
    "    test_predictions_df = pd.DataFrame()\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "\n",
    "        # Sampling parameters from ranges\n",
    "        params = {\n",
    "            'boosting_type': random.choice(param_ranges['boosting_type']),\n",
    "            'num_leaves': random.randint(*param_ranges['num_leaves']),\n",
    "            'learning_rate': random.uniform(*param_ranges['learning_rate']),\n",
    "            'max_depth': random.randint(*param_ranges['max_depth']),\n",
    "            'min_child_samples': random.randint(*param_ranges['min_child_samples']),\n",
    "            'reg_alpha': random.uniform(*param_ranges['reg_alpha']),\n",
    "            'reg_lambda': random.uniform(*param_ranges['reg_lambda']),\n",
    "            'n_estimators': 300\n",
    "        }\n",
    "        \n",
    "        # Train and evaluate model\n",
    "        boosting_type = params['boosting_type']\n",
    "        _, _, rmse, model = cv_pipeline(train_feats, test_feats, params, boosting_type)\n",
    "                                        \n",
    "        new_iter = {'rmse': [rmse],\n",
    "                    'params': str(model.get_params())}\n",
    "\n",
    "        test_predictions_df = pd.concat([test_predictions_df, pd.DataFrame(data=new_iter)])\n",
    "        # Update best parameters if current model is better\n",
    "        if rmse < best_rmse:\n",
    "            print(f\"New best RMSE: {rmse:.6f}\")\n",
    "            best_rmse = rmse\n",
    "            best_params = model.get_params()\n",
    "    \n",
    "    print(f\"Best RMSE: {best_rmse:.6f}\")\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    return test_predictions_df\n",
    "\n",
    "# Example usage\n",
    "test_predictions_df = random_param_search(train_feats, test_feats, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603186</td>\n",
       "      <td>boosting_type: gbdt, num_leaves: 16, learning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603505</td>\n",
       "      <td>boosting_type: gbdt, num_leaves: 16, learning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603551</td>\n",
       "      <td>boosting_type: gbdt, num_leaves: 17, learning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.604466</td>\n",
       "      <td>boosting_type: goss, num_leaves: 88, learning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.604790</td>\n",
       "      <td>boosting_type: gbdt, num_leaves: 16, learning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.038624</td>\n",
       "      <td>boosting_type: dart, num_leaves: 35, learning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.086226</td>\n",
       "      <td>boosting_type: dart, num_leaves: 76, learning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.087839</td>\n",
       "      <td>boosting_type: dart, num_leaves: 100, learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.121359</td>\n",
       "      <td>boosting_type: dart, num_leaves: 120, learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.198231</td>\n",
       "      <td>boosting_type: dart, num_leaves: 117, learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rmse                                             params\n",
       "0   0.603186  boosting_type: gbdt, num_leaves: 16, learning_...\n",
       "0   0.603505  boosting_type: gbdt, num_leaves: 16, learning_...\n",
       "0   0.603551  boosting_type: gbdt, num_leaves: 17, learning_...\n",
       "0   0.604466  boosting_type: goss, num_leaves: 88, learning_...\n",
       "0   0.604790  boosting_type: gbdt, num_leaves: 16, learning_...\n",
       "..       ...                                                ...\n",
       "0   2.038624  boosting_type: dart, num_leaves: 35, learning_...\n",
       "0   2.086226  boosting_type: dart, num_leaves: 76, learning_...\n",
       "0   2.087839  boosting_type: dart, num_leaves: 100, learning...\n",
       "0   2.121359  boosting_type: dart, num_leaves: 120, learning...\n",
       "0   2.198231  boosting_type: dart, num_leaves: 117, learning...\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_df.sort_values('rmse')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
