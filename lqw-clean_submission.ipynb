{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e0f0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:36:57.952132Z",
     "iopub.status.busy": "2023-12-19T15:36:57.951686Z",
     "iopub.status.idle": "2023-12-19T15:36:58.010591Z",
     "shell.execute_reply": "2023-12-19T15:36:58.008917Z"
    },
    "papermill": {
     "duration": 0.068866,
     "end_time": "2023-12-19T15:36:58.013783",
     "exception": false,
     "start_time": "2023-12-19T15:36:57.944917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from m4_feats_polars import *\n",
    "from m5_sb_models import *\n",
    "\n",
    "lgb_params_1 = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'metric': 'rmse',\n",
    "    'reg_alpha': 0.0031, \n",
    "    'reg_lambda': 0.001, \n",
    "    'colsample_bytree': 0.8,  \n",
    "    'subsample_freq': 1,  \n",
    "    'subsample': 0.75,  \n",
    "    'learning_rate': 0.017, \n",
    "    'num_leaves': 19, \n",
    "    'min_child_samples': 46,\n",
    "    'n_estimators': 400,\n",
    "    'verbosity': -1,\n",
    "    'force_col_wise':True\n",
    "    }\n",
    "\n",
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n",
    "test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n",
    "train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a5982e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:36:58.027220Z",
     "iopub.status.busy": "2023-12-19T15:36:58.026302Z",
     "iopub.status.idle": "2023-12-19T15:38:20.664124Z",
     "shell.execute_reply": "2023-12-19T15:38:20.662904Z"
    },
    "papermill": {
     "duration": 82.648309,
     "end_time": "2023-12-19T15:38:20.667602",
     "exception": false,
     "start_time": "2023-12-19T15:36:58.019293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Events counts features >\n",
      "< Count vectorize one-grams >\n",
      "< Idle time features >\n",
      "< cursor position acceleration >\n",
      "< word count acceleration >\n",
      "< Count vectorize bi-grams >\n",
      "< R-burst features >\n",
      "< Categorical # unique values features >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays sentences feats >\n",
      "< Essays sentences feats >\n",
      "train feats shape (2471, 136)\n"
     ]
    }
   ],
   "source": [
    "Best_Feature_Set = ['train_down_events_counts.pkl', 'train_vector_one_gram.pkl', 'train_create_pauses.pkl', \n",
    "                   'train_essay_paragraphs.pkl', 'train_cursor_pos_acceleration.pkl', \n",
    "                   'train_word_count_acceleration.pkl', 'train_vector_two_gram.pkl']\n",
    "\n",
    "# PANDAS FEATS\n",
    "train_essays          = get_essay_df(train_logs.collect().to_pandas())\n",
    "test_essays           = get_essay_df(test_logs.collect().to_pandas())\n",
    "\n",
    "# train_down_events_counts\n",
    "tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n",
    "# train_vector_one_gram\n",
    "tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n",
    "# train_create_pauses\n",
    "tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n",
    "# train_cursor_pos_acceleration\n",
    "tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n",
    "# train_word_count_acceleration\n",
    "tr_word_count_acc, ts_word_count_acc = word_count_acceleration(train_logs, test_logs)\n",
    "# train_vector_two_gram\n",
    "tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n",
    "# r-bursts\n",
    "tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n",
    "# nunique\n",
    "tr_nunique, ts_nunique = categorical_nunique(train_logs, test_logs)\n",
    "#get_keys_pressed_per_second\n",
    "tr_get_keys, ts_get_keys = get_keys_pressed_per_second(train_logs.collect().to_pandas(), \n",
    "                                                       test_logs.collect().to_pandas())\n",
    "\n",
    "train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_pauses, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_word_count_acc, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_nunique, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_get_keys, on='id', how='left')\n",
    "\n",
    "\n",
    "test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_pauses, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_word_count_acc, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_nunique, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_get_keys, on='id', how='left')\n",
    "\n",
    "\n",
    "train_logs = train_logs.collect().to_pandas()\n",
    "test_logs = test_logs.collect().to_pandas()\n",
    "train_scores = train_scores.collect().to_pandas()\n",
    "train_feats = train_feats.collect().to_pandas()\n",
    "test_feats = test_feats.collect().to_pandas()\n",
    "\n",
    "train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n",
    "print(f'train feats shape {train_feats.shape}')\n",
    "\n",
    "missing_cols = set(train_feats.columns) - set(test_feats.columns)\n",
    "for col in missing_cols:\n",
    "    test_feats[col] = np.nan\n",
    "\n",
    "train_feats           = train_feats.merge(train_scores, on=['id'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5589b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_full_train_set(train, test, param, iterations=50):\n",
    "        \n",
    "    x = train.drop(['id', 'score'], axis=1)\n",
    "    y = train['score'].values\n",
    "    test_x = test.drop(columns = ['id'])\n",
    " \n",
    "    test_preds = []\n",
    "    valid_preds = pd.DataFrame()\n",
    "\n",
    "    for iter in range(iterations):\n",
    "\n",
    "        model = LGBMRegressor(**param, random_state = 42 + iter)\n",
    "        model.fit(x, y)\n",
    "        test_predictions = model.predict(test_x)\n",
    "        test_preds.append(test_predictions)\n",
    "\n",
    "    return test_preds, model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf777c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "def run_lgb_cv(train_feats, test_feats, train_cols, target_col, lgb_params, boosting_type, seed, n_repeats, n_splits):\n",
    "\n",
    "    oof_results = pd.DataFrame(columns = ['id', 'iteration', 'score', 'prediction'])\n",
    "\n",
    "    X = train_feats[train_cols]\n",
    "    y = train_feats[target_col]\n",
    "    X_test = test_feats[train_cols]\n",
    "    test_preds = []\n",
    "\n",
    "    for i in range(n_repeats):\n",
    "        skf = KFold(n_splits=n_splits, shuffle=True, random_state=seed + i)\n",
    "\n",
    "        for train_idx, valid_idx in skf.split(train_feats, y):\n",
    "            X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "            X_valid, y_valid = X.loc[valid_idx], y.loc[valid_idx]\n",
    "\n",
    "            model = lgb.LGBMRegressor(**lgb_params, verbose=-1, random_state=seed)\n",
    "            if boosting_type != 'dart':\n",
    "                model.fit(X_train, y_train, \n",
    "                        eval_set=[(X_valid, y_valid)], \n",
    "                        callbacks=[lgb.early_stopping(250, first_metric_only=True, verbose=False)])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)  # No early stopping for DART\n",
    "\n",
    "            valid_predictions = model.predict(X_valid, num_iteration=model.best_iteration_)\n",
    "            test_predictions = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            test_preds.append(test_predictions)\n",
    "        \n",
    "            tmp_df = train_feats.loc[valid_idx][['id','score']]\n",
    "            tmp_df['prediction'] = valid_predictions\n",
    "            tmp_df['iteration'] = i + 1\n",
    "            oof_results = pd.concat([oof_results, tmp_df])\n",
    "\n",
    "    avg_preds = oof_results.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "    rmse = mean_squared_error(avg_preds['score'], avg_preds['prediction'], squared=False)\n",
    "    print(f\"LGBM Average RMSE over {n_repeats * n_splits} folds: {rmse:.6f}\")\n",
    "    return test_preds, oof_results, rmse, model  \n",
    "\n",
    "def cv_pipeline(train_feats, test_feats, lgb_params, boosting_type, seed=42, n_repeats=5, n_splits=10):\n",
    "\n",
    "    target_col = ['score']\n",
    "    drop_cols = ['id']\n",
    "    train_cols = [col for col in train_feats.columns if col not in target_col + drop_cols]\n",
    "\n",
    "    missing_cols = [col for col in train_cols if col not in test_feats.columns]\n",
    "    missing_cols_df = pd.DataFrame({col: np.nan for col in missing_cols}, index=test_feats.index)\n",
    "    test_feats = pd.concat([test_feats, missing_cols_df], axis=1)\n",
    "\n",
    "\n",
    "    test_preds, oof_preds, rmse, model = run_lgb_cv(train_feats=train_feats, test_feats=test_feats, \n",
    "                                             train_cols=train_cols, target_col=target_col, \n",
    "                                             lgb_params=lgb_params, boosting_type=boosting_type,\n",
    "                                             seed=seed, n_repeats=n_repeats, n_splits=n_splits)\n",
    "    \n",
    "    rmse_per_iteration = oof_preds.groupby('iteration').apply(calculate_rmse)\n",
    "    print(f'Mean RMSE of all iterations: {np.mean(rmse_per_iteration):.6f}')\n",
    "\n",
    "    return test_preds, oof_preds, rmse, model\n",
    "\n",
    "def calculate_rmse(df):\n",
    "    return mean_squared_error(df['score'], df['prediction'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932fabdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:38:20.681687Z",
     "iopub.status.busy": "2023-12-19T15:38:20.681204Z",
     "iopub.status.idle": "2023-12-19T15:41:49.332729Z",
     "shell.execute_reply": "2023-12-19T15:41:49.331765Z"
    },
    "papermill": {
     "duration": 208.667692,
     "end_time": "2023-12-19T15:41:49.341236",
     "exception": false,
     "start_time": "2023-12-19T15:38:20.673544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.599216\n",
      "Mean RMSE of all iterations: 0.602228\n"
     ]
    }
   ],
   "source": [
    "test_preds, oof_preds, rmse, model = cv_pipeline(train_feats, test_feats, lgb_params_1, 'gbdt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692fee9",
   "metadata": {},
   "source": [
    "LGBM Average RMSE over 50 folds: 0.599971\n",
    "Mean RMSE of all iterations: 0.602992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b4817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:41:49.355191Z",
     "iopub.status.busy": "2023-12-19T15:41:49.354746Z",
     "iopub.status.idle": "2023-12-19T15:41:49.368455Z",
     "shell.execute_reply": "2023-12-19T15:41:49.367203Z"
    },
    "papermill": {
     "duration": 0.024601,
     "end_time": "2023-12-19T15:41:49.371731",
     "exception": false,
     "start_time": "2023-12-19T15:41:49.347130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ids = test_feats.id\n",
    "y_pred = np.mean(test_preds, axis=0)\n",
    "\n",
    "sub = pd.DataFrame({'id': test_ids, 'score': y_pred})\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb368e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:41:49.386529Z",
     "iopub.status.busy": "2023-12-19T15:41:49.386144Z",
     "iopub.status.idle": "2023-12-19T15:41:49.403665Z",
     "shell.execute_reply": "2023-12-19T15:41:49.402260Z"
    },
    "papermill": {
     "duration": 0.028713,
     "end_time": "2023-12-19T15:41:49.406791",
     "exception": false,
     "start_time": "2023-12-19T15:41:49.378078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>1.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>1.244537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  2222bbbb  1.240500\n",
       "1  0000aaaa  1.240500\n",
       "2  4444cccc  1.244537"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6678907,
     "sourceId": 59291,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 300.47277,
   "end_time": "2023-12-19T15:41:50.740152",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-19T15:36:50.267382",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
