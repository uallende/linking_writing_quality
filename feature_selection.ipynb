{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53076486",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-17T07:30:20.117514Z",
     "iopub.status.busy": "2023-12-17T07:30:20.117128Z",
     "iopub.status.idle": "2023-12-17T07:30:25.747577Z",
     "shell.execute_reply": "2023-12-17T07:30:25.746552Z"
    },
    "papermill": {
     "duration": 5.641939,
     "end_time": "2023-12-17T07:30:25.750156",
     "exception": false,
     "start_time": "2023-12-17T07:30:20.108217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re, os\n",
    "import random\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import skew, kurtosis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import warnings\n",
    "from m4_feats_polars import *\n",
    "from m5_sb_models import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7b059",
   "metadata": {
    "papermill": {
     "duration": 0.006455,
     "end_time": "2023-12-17T07:30:25.948793",
     "exception": false,
     "start_time": "2023-12-17T07:30:25.942338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Selection: Null Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ffca0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:30:25.964498Z",
     "iopub.status.busy": "2023-12-17T07:30:25.964105Z",
     "iopub.status.idle": "2023-12-17T07:30:25.997940Z",
     "shell.execute_reply": "2023-12-17T07:30:25.996747Z"
    },
    "papermill": {
     "duration": 0.044792,
     "end_time": "2023-12-17T07:30:26.000538",
     "exception": false,
     "start_time": "2023-12-17T07:30:25.955746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_importances(data_x, data_y, valid_x, valid_y, model_params, shuffle, seed=None):\n",
    "    if seed == None:\n",
    "        model_params['random_state'] = None\n",
    "\n",
    "    gain_model = LGBMRegressor(importance_type='gain', **model_params)\n",
    "    split_model = LGBMRegressor(importance_type='split', **model_params)\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(data_y)\n",
    "        random.shuffle(valid_y)\n",
    "        \n",
    "    gain_model.fit(data_x, data_y, eval_set=[(valid_x, valid_y)])\n",
    "    split_model.fit(data_x, data_y, eval_set=[(valid_x, valid_y)])\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df[\"feature\"] = list(data_x)\n",
    "    imp_df[\"importance_gain\"] = gain_model.feature_importances_\n",
    "    imp_df[\"importance_split\"] = split_model.feature_importances_    \n",
    "    return imp_df\n",
    "\n",
    "\n",
    "def get_batch_imp_df(data_x, data_y, valid_x, valid_y, model_params, nb_runs=10, null_flag=True):\n",
    "    batch_imp_df = pd.DataFrame()\n",
    "    print(f'Run {nb_runs} rounds of model training:')\n",
    "    for i in tqdm(range(nb_runs)):\n",
    "        if null_flag:\n",
    "            imp_df = get_feature_importances(data_x, data_y, valid_x, valid_y, model_params, shuffle=True, seed=None)\n",
    "        else:\n",
    "            imp_df = get_feature_importances(data_x, data_y, valid_x, valid_y, model_params, shuffle=False, seed=None)\n",
    "        imp_df['run'] = i + 1 \n",
    "        batch_imp_df = pd.concat([batch_imp_df, imp_df], axis=0)\n",
    "    return batch_imp_df\n",
    "\n",
    "\n",
    "def display_distributions(actual_imp_df_, null_imp_df_, feature_):\n",
    "    plt.figure(figsize=(13, 6))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    # Plot Split importances\n",
    "    ax = plt.subplot(gs[0, 0])\n",
    "    a = ax.hist(null_imp_df_.loc[null_imp_df_['feature'] == feature_, 'importance_split'].values, label='Null importances')\n",
    "    ax.vlines(x=actual_imp_df_.loc[actual_imp_df_['feature'] == feature_, 'importance_split'].mean(), \n",
    "               ymin=0, ymax=np.max(a[0]), color='r',linewidth=10, label='Real Target')\n",
    "    ax.legend()\n",
    "    ax.set_title('Split Importance of %s' % feature_.upper(), fontweight='bold')\n",
    "    plt.xlabel('Null Importance (split) Distribution for %s ' % feature_.upper())\n",
    "    # Plot Gain importances\n",
    "    ax = plt.subplot(gs[0, 1])\n",
    "    a = ax.hist(null_imp_df_.loc[null_imp_df_['feature'] == feature_, 'importance_gain'].values, label='Null importances')\n",
    "    ax.vlines(x=actual_imp_df_.loc[actual_imp_df_['feature'] == feature_, 'importance_gain'].mean(), \n",
    "               ymin=0, ymax=np.max(a[0]), color='r',linewidth=10, label='Real Target')\n",
    "    ax.legend()\n",
    "    ax.set_title('Gain Importance of %s' % feature_.upper(), fontweight='bold')\n",
    "    plt.xlabel('Null Importance (gain) Distribution for %s ' % feature_.upper())\n",
    "\n",
    "    \n",
    "def normalize_feat_imp(imp_df):\n",
    "    avg_gain_imp_df = imp_df.groupby(by=['feature'])['importance_gain'].mean().reset_index()\n",
    "    avg_split_imp_df = imp_df.groupby(by=['feature'])['importance_split'].mean().reset_index()\n",
    "    # rank-normalize score\n",
    "    avg_gain_imp_df['importance_gain'] = avg_gain_imp_df['importance_gain'].rank(ascending=False, pct=True)\n",
    "    avg_split_imp_df['importance_split'] = avg_split_imp_df['importance_split'].rank(ascending=False, pct=True)\n",
    "    avg_imp_df = pd.merge(avg_gain_imp_df, avg_split_imp_df, on='feature')\n",
    "    # # normalize score\n",
    "    # avg_imp_df['importance_gain'] = (avg_imp_df['importance_gain'] - avg_imp_df['importance_gain'].min())  / (avg_imp_df['importance_gain'].max() - avg_imp_df['importance_gain'].min())\n",
    "    # avg_imp_df['importance_split'] = (avg_imp_df['importance_split'] - avg_imp_df['importance_split'].min())  / (avg_imp_df['importance_split'].max() - avg_imp_df['importance_split'].min())\n",
    "    return avg_imp_df\n",
    "\n",
    "\n",
    "def nul_imp_feat_select(model_params,\n",
    "                        train_x, train_y, valid_x, valid_y,\n",
    "                        actual_avg_imp_df, null_avg_imp_df,\n",
    "                        search_thres=[ 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1],\n",
    "                        search_criterion=['gain', 'split', 'both']):\n",
    "    feat_select_dfs = []\n",
    "    for search_cri in search_criterion:\n",
    "        print(f'Feature Selection by Null Importances: {search_cri}:')\n",
    "        for threshold in tqdm(search_thres):\n",
    "            if 'split' == search_cri:\n",
    "                actual_feats = actual_avg_imp_df[actual_avg_imp_df['importance_split']>threshold]['feature'].values.tolist()\n",
    "                null_feats = null_avg_imp_df[null_avg_imp_df['importance_split']>threshold]['feature'].values.tolist()\n",
    "                unstable_feats = set(actual_feats + null_feats)\n",
    "                feats = [_f for _f in actual_avg_imp_df['feature'].unique() if _f not in unstable_feats]\n",
    "            elif 'gain' == search_cri:\n",
    "                actual_feats = actual_avg_imp_df[actual_avg_imp_df['importance_gain']>threshold]['feature'].values.tolist()\n",
    "                null_feats = null_avg_imp_df[null_avg_imp_df['importance_gain']>threshold]['feature'].values.tolist()\n",
    "                unstable_feats = set(actual_feats + null_feats)\n",
    "                feats = [_f for _f in actual_avg_imp_df['feature'].unique() if _f not in unstable_feats]\n",
    "            elif 'both' == search_cri:\n",
    "                actual_feats = actual_avg_imp_df[actual_avg_imp_df['importance_split']>threshold]['feature'].values.tolist()\n",
    "                null_feats = null_avg_imp_df[null_avg_imp_df['importance_split']>threshold]['feature'].values.tolist()\n",
    "                unstable_feats1 = set(actual_feats + null_feats)\n",
    "\n",
    "                actual_feats = actual_avg_imp_df[actual_avg_imp_df['importance_gain']>threshold]['feature'].values.tolist()\n",
    "                null_feats = null_avg_imp_df[null_avg_imp_df['importance_gain']>threshold]['feature'].values.tolist()\n",
    "                unstable_feats2 = set(actual_feats + null_feats)\n",
    "                \n",
    "                unstable_feats = set(list(unstable_feats1) + list(unstable_feats2))\n",
    "                feats = [_f for _f in actual_avg_imp_df['feature'].unique() if _f not in unstable_feats]\n",
    "\n",
    "            model = LGBMRegressor(**model_params)\n",
    "            model.fit(train_x[feats], train_y, eval_set=[(valid_x[feats], valid_y)], verbose= False)\n",
    "            valid_pred_y = model.predict(valid_x[feats], num_iteration=model.best_iteration_)  \n",
    "            valid_eval_rmse = mean_squared_error(valid_y, valid_pred_y, squared=False) \n",
    "            feat_select_dfs.append([search_cri, threshold, feats, len(feats), valid_eval_rmse])\n",
    "    feat_select_dfs = pd.DataFrame(feat_select_dfs)   \n",
    "    feat_select_dfs.columns = ['imp_type', 'threshold', 'features', 'feature_number', 'valid_eval_rmse']    \n",
    "    return feat_select_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac6ea4",
   "metadata": {
    "papermill": {
     "duration": 0.006453,
     "end_time": "2023-12-17T07:30:26.013919",
     "exception": false,
     "start_time": "2023-12-17T07:30:26.007466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5378f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [('train_down_events_counts.pkl', 26),\n",
    "#  ('train_vector_one_gram.pkl', 26),\n",
    "#  ('train_create_pauses.pkl', 26),\n",
    "#  ('train_essay_paragraphs.pkl', 26),\n",
    "#  ('train_cursor_pos_acceleration.pkl', 11),\n",
    "#  ('train_word_count_acceleration.pkl', 6),\n",
    "#  ('train_p_burst_feats.pkl', 5),\n",
    "#  ('train_r_burst_feats.pkl', 3),\n",
    "#  ('train_events_counts_acceleration.pkl', 3),\n",
    "#  ('train_essay_sentences.pkl', 3),\n",
    "#  ('train_categorical_nunique.pkl', 3),\n",
    "#  ('train_vector_two_gram.pkl', 2),\n",
    "#  ('train_cursor_pos_rate_of_change.pkl', 2),\n",
    "#  ('train_word_counts_rate_of_change.pkl', 2),\n",
    "#  ('train_count_of_activities.pkl', 2),\n",
    "#  ('train_action_time_by_activity.pkl', 1),\n",
    "#  ('train_product_to_keys.pkl', 1),\n",
    "#  ('train_IKI_based_fractals.pkl', 1),\n",
    "#  ('train_events_counts_baseline.pkl', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc6a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Events counts features >\n",
      "< Count vectorize one-grams >\n",
      "< Idle time features >\n",
      "< cursor position acceleration >\n",
      "< word count acceleration >\n",
      "< events counts acceleration >\n",
      "< Count vectorize bi-grams >\n",
      "< Action time by activities >\n",
      "< R-burst features >\n",
      "< P-burst features >\n",
      "< Categorical # unique values features >\n",
      "< Input text change features >\n",
      "< Word counts rate of change features >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays sentences feats >\n",
      "< Essays sentences feats >\n"
     ]
    }
   ],
   "source": [
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n",
    "test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n",
    "train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')\n",
    "\n",
    "train_essays          = get_essay_df(train_logs.collect().to_pandas())\n",
    "test_essays           = get_essay_df(test_logs.collect().to_pandas())\n",
    "\n",
    "tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n",
    "tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n",
    "tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n",
    "tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n",
    "tr_word_count_acc, ts_word_count_acc = word_count_acceleration(train_logs, test_logs)\n",
    "tr_event_acc, ts_event_acc = events_counts_acceleration(train_logs, test_logs)\n",
    "tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n",
    "tr_time_by_act, ts_time_by_act = action_time_by_activity(train_logs, test_logs)\n",
    "\n",
    "tr_act_count, ts_act_count = count_of_activities(train_logs, test_logs)\n",
    "tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n",
    "tr_p_burst, ts_p_burst = p_burst_feats(train_logs, test_logs, 2)\n",
    "tr_nunique, ts_nunique = categorical_nunique(train_logs, test_logs)\n",
    "tr_get_keys, ts_get_keys = get_keys_pressed_per_second(train_logs.collect().to_pandas(), \n",
    "                                                       test_logs.collect().to_pandas())\n",
    "\n",
    "tr_input_change, ts_input_change = input_text_change_feats(train_logs, test_logs)\n",
    "tr_wc_roc, ts_wc_roc =  word_counts_rate_of_change(train_logs, test_logs)\n",
    "\n",
    "\n",
    "train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_pauses, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_word_count_acc, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_p_burst, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_event_acc, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_nunique, on='id', how='left')\n",
    "\n",
    "\n",
    "# train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n",
    "# train_feats = train_feats.join(tr_get_keys, on='id', how='left')\n",
    "# train_feats = train_feats.join(tr_wc_roc, on='id', how='left')\n",
    "# train_feats = train_feats.join(tr_input_change, on='id', how='left')\n",
    "# train_feats = train_feats.join(tr_time_by_act, on='id', how='left')\n",
    "\n",
    "test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_pauses, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_word_count_acc, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_p_burst, on='id', how='left')\n",
    "test_feats = test_feats.join(tr_event_acc, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_nunique, on='id', how='left')\n",
    "\n",
    "# test_feats = test_feats.join(ts_get_keys, on='id', how='left')\n",
    "# test_feats = test_feats.join(ts_wc_roc, on='id', how='left')\n",
    "# test_feats = test_feats.join(ts_input_change, on='id', how='left')\n",
    "# test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n",
    "# test_feats = test_feats.join(ts_time_by_act, on='id', how='left')\n",
    "\n",
    "\n",
    "train_logs = train_logs.collect().to_pandas()\n",
    "test_logs = test_logs.collect().to_pandas()\n",
    "train_scores = train_scores.collect().to_pandas()\n",
    "train_feats = train_feats.sort('id')\n",
    "train_feats = train_feats.collect().to_pandas()\n",
    "test_feats = test_feats.collect().to_pandas()\n",
    "\n",
    "train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "\n",
    "train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d7f927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:30:26.029360Z",
     "iopub.status.busy": "2023-12-17T07:30:26.028780Z",
     "iopub.status.idle": "2023-12-17T07:31:59.775743Z",
     "shell.execute_reply": "2023-12-17T07:31:59.774628Z"
    },
    "papermill": {
     "duration": 93.764272,
     "end_time": "2023-12-17T07:31:59.785002",
     "exception": false,
     "start_time": "2023-12-17T07:30:26.020730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Mapping >\n",
      "Number of features: 137\n"
     ]
    }
   ],
   "source": [
    "# data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "# train_logs    = pl.scan_csv(data_path + 'train_logs.csv')\n",
    "# train_feats   = dev_feats(train_logs) # 特征工程\n",
    "# train_feats   = train_feats.collect().to_pandas()\n",
    "\n",
    "# print('< Essay Reconstruction >')\n",
    "# train_logs             = train_logs.collect().to_pandas()\n",
    "# train_essays           = get_essay_df(train_logs)\n",
    "# train_feats            = train_feats.merge(word_feats(train_essays), on='id', how='left')\n",
    "# train_feats            = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "# train_feats            = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "# train_feats            = train_feats.merge(get_keys_pressed_per_second(train_logs), on='id', how='left')\n",
    "# train_feats            = train_feats.merge(product_to_keys(train_logs, train_essays), on='id', how='left')\n",
    "\n",
    "\n",
    "print('< Mapping >')\n",
    "# train_scores   = pd.read_csv(data_path + 'train_scores.csv')\n",
    "data           = train_feats.merge(train_scores, on='id', how='left')\n",
    "x              = data.drop(['id', 'score'], axis=1)\n",
    "y              = data['score'].values\n",
    "print(f'Number of features: {len(x.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfde37",
   "metadata": {
    "papermill": {
     "duration": 0.00683,
     "end_time": "2023-12-17T07:31:59.798900",
     "exception": false,
     "start_time": "2023-12-17T07:31:59.792070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a429ae6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:31:59.851880Z",
     "iopub.status.busy": "2023-12-17T07:31:59.851224Z",
     "iopub.status.idle": "2023-12-17T10:41:55.497540Z",
     "shell.execute_reply": "2023-12-17T10:41:55.496175Z"
    },
    "papermill": {
     "duration": 11395.657816,
     "end_time": "2023-12-17T10:41:55.500390",
     "exception": false,
     "start_time": "2023-12-17T07:31:59.842574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0:\n",
      "Feature Selection (get null_imp_df):\n",
      "Run 50 rounds of model training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGBMRegressor.fit() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/feature_selection.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mif\u001b[39;00m train_feat_select:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFeature Selection (get null_imp_df):\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     null_imp_df \u001b[39m=\u001b[39m get_batch_imp_df(data_x\u001b[39m.\u001b[39;49mcopy(), data_y\u001b[39m.\u001b[39;49mcopy(), valid_x\u001b[39m.\u001b[39;49mcopy(), valid_y\u001b[39m.\u001b[39;49mcopy(), model_params, nb_runs\u001b[39m=\u001b[39;49mnb_runs, null_flag\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFeature Selection (actual_imp_df):\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     actual_imp_df \u001b[39m=\u001b[39m get_batch_imp_df(data_x\u001b[39m.\u001b[39mcopy(), data_y\u001b[39m.\u001b[39mcopy(), valid_x\u001b[39m.\u001b[39mcopy(), valid_y\u001b[39m.\u001b[39mcopy(), model_params, nb_runs\u001b[39m=\u001b[39mnb_runs, null_flag\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/feature_selection.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(nb_runs)):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m null_flag:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         imp_df \u001b[39m=\u001b[39m get_feature_importances(data_x, data_y, valid_x, valid_y, model_params, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, seed\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         imp_df \u001b[39m=\u001b[39m get_feature_importances(data_x, data_y, valid_x, valid_y, model_params, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, seed\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/feature_selection.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     random\u001b[39m.\u001b[39mshuffle(data_y)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     random\u001b[39m.\u001b[39mshuffle(valid_y)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m gain_model\u001b[39m.\u001b[39;49mfit(data_x, data_y, eval_set\u001b[39m=\u001b[39;49m[(valid_x, valid_y)], verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m split_model\u001b[39m.\u001b[39mfit(data_x, data_y, eval_set\u001b[39m=\u001b[39m[(valid_x, valid_y)], verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/feature_selection.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m imp_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n",
      "\u001b[0;31mTypeError\u001b[0m: LGBMRegressor.fit() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        'n_estimators': 1024,\n",
    "         'learning_rate': 0.005,\n",
    "         'metric': 'rmse',\n",
    "         'random_state': 42,\n",
    "         'force_col_wise': True,\n",
    "         'verbosity': -1,\n",
    "         'early_stopping_round': 100\n",
    "        }\n",
    "\n",
    "\n",
    "data_x = x.copy()\n",
    "data_y = y.copy()\n",
    "model_params = param\n",
    "random_state = 42\n",
    "n_splits = 5\n",
    "nb_runs = 50\n",
    "train_feat_select = True\n",
    "\n",
    "skf    = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "test_y = np.zeros(len(data_x))\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(data_x, data_y.astype(str))):\n",
    "    print(f'Fold:{i}:')\n",
    "    train_x, train_y, valid_x, valid_y = train_valid_split(data_x, data_y, train_index, valid_index)\n",
    "\n",
    "    if train_feat_select:\n",
    "        print('Feature Selection (get null_imp_df):')\n",
    "        null_imp_df = get_batch_imp_df(data_x.copy(), data_y.copy(), valid_x.copy(), valid_y.copy(), model_params, nb_runs=nb_runs, null_flag=True)\n",
    "        print('Feature Selection (actual_imp_df):')\n",
    "        actual_imp_df = get_batch_imp_df(data_x.copy(), data_y.copy(), valid_x.copy(), valid_y.copy(), model_params, nb_runs=nb_runs, null_flag=False)\n",
    "\n",
    "        actual_avg_imp_df = normalize_feat_imp(actual_imp_df)\n",
    "        null_avg_imp_df = normalize_feat_imp(null_imp_df)\n",
    "        feat_select_dfs = nul_imp_feat_select(model_params,\n",
    "                            train_x, train_y, valid_x, valid_y,\n",
    "                            actual_avg_imp_df, null_avg_imp_df,\n",
    "                            search_thres=[0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 1],\n",
    "                            search_criterion=['gain', 'split', 'both'])\n",
    "        \n",
    "        if not os.path.exists('feature_selection/'):\n",
    "            os.mkdir('feature_selection/')\n",
    "        feat_select_dfs.to_csv(f'feature_selection/feature_selection_res_fold{i}.csv', index=False)\n",
    "        valid_min_eval_rmse = feat_select_dfs['valid_eval_rmse'].min()\n",
    "        optimal_feat_select_res = feat_select_dfs[feat_select_dfs['valid_eval_rmse'] == valid_min_eval_rmse].values[0]\n",
    "        np.save(f'feature_selection/optimal_feat_select_res_fold{i}.npy', optimal_feat_select_res)\n",
    "\n",
    "    use_feats = np.load(f'feature_selection/optimal_feat_select_res_fold{i}.npy', allow_pickle=True)\n",
    "    print(f'After feature selection: {len(list(train_x))} -> {len(use_feats[2])}.')\n",
    "    train_x = train_x[use_feats[2]]\n",
    "    valid_x = valid_x[use_feats[2]]\n",
    "\n",
    "    model = LGBMRegressor(**model_params)\n",
    "    model.fit(train_x, train_y, \n",
    "            #   eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                eval_set=[(valid_x, valid_y)],\n",
    "                )\n",
    "    test_y[valid_index] = model.predict(valid_x, num_iteration=model.best_iteration_)\n",
    "\n",
    "    model.booster_.save_model(f'results/model_fold{i}.txt', num_iteration=model.best_iteration_)\n",
    "\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    feature_list = list(train_x)\n",
    "    feature_imp = pd.DataFrame({'feature':feature_list, 'importance':importances})\n",
    "    feature_imp['importance'] = (feature_imp['importance'] - feature_imp['importance'].min())  / (feature_imp['importance'].max() - feature_imp['importance'].min())\n",
    "    feature_imp = feature_imp.sort_values(by='importance', ascending=False)\n",
    "    feature_imp.to_csv(f'results/model_feat_imp_fold{i}.csv', index=False)\n",
    "    print('-'*20)\n",
    "    del model\n",
    "\n",
    "eval_rmse = mean_squared_error(data_y, test_y, squared=False)\n",
    "print('Eval RMSE:', eval_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b881b163",
   "metadata": {
    "papermill": {
     "duration": 0.113132,
     "end_time": "2023-12-17T10:41:55.724201",
     "exception": false,
     "start_time": "2023-12-17T10:41:55.611069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44478cd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T10:41:55.951324Z",
     "iopub.status.busy": "2023-12-17T10:41:55.950919Z",
     "iopub.status.idle": "2023-12-17T10:41:56.301558Z",
     "shell.execute_reply": "2023-12-17T10:41:56.300535Z"
    },
    "papermill": {
     "duration": 0.468979,
     "end_time": "2023-12-17T10:41:56.305554",
     "exception": false,
     "start_time": "2023-12-17T10:41:55.836575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Testing Data >\n",
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "< Learning and Evaluation >\n"
     ]
    }
   ],
   "source": [
    "data_path     = '/kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "\n",
    "print('< Testing Data >')\n",
    "test_logs   = pl.scan_csv(data_path + 'test_logs.csv')\n",
    "test_feats  = dev_feats(test_logs)\n",
    "test_feats  = test_feats.collect().to_pandas()\n",
    "\n",
    "test_logs             = test_logs.collect().to_pandas()\n",
    "test_essays           = get_essay_df(test_logs)\n",
    "test_feats            = test_feats.merge(word_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(get_keys_pressed_per_second(test_logs), on='id', how='left')\n",
    "test_feats            = test_feats.merge(product_to_keys(test_logs, test_essays), on='id', how='left')\n",
    "\n",
    "\n",
    "test_ids = test_feats['id'].values\n",
    "testin_x = test_feats.drop(['id'], axis=1)\n",
    "\n",
    "print('< Learning and Evaluation >')\n",
    "param = {\n",
    "        'n_estimators': 1024,\n",
    "         'learning_rate': 0.005,\n",
    "         'metric': 'rmse',\n",
    "         'random_state': 42,\n",
    "         'force_col_wise': True,\n",
    "         'verbosity': 1,\n",
    "         'early_stopping_round': 100\n",
    "        }\n",
    "\n",
    "\n",
    "solution = LGBMRegressor(**param)\n",
    "test_y_pred = inference(test_x=testin_x.copy())\n",
    "sub = pd.DataFrame({'id': test_ids, 'score': test_y_pred})\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31a3935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T10:41:56.551809Z",
     "iopub.status.busy": "2023-12-17T10:41:56.550308Z",
     "iopub.status.idle": "2023-12-17T10:41:58.859928Z",
     "shell.execute_reply": "2023-12-17T10:41:58.858071Z"
    },
    "papermill": {
     "duration": 2.429123,
     "end_time": "2023-12-17T10:41:58.862895",
     "exception": false,
     "start_time": "2023-12-17T10:41:56.433772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/results\n",
    "!rm -rf /kaggle/working/feature_selection"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6678907,
     "sourceId": 59291,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11503.81875,
   "end_time": "2023-12-17T10:42:00.327371",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-17T07:30:16.508621",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
