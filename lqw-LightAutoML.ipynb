{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "import joblib\n",
    "from m4_feats_polars import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from m5_sb_models import *\n",
    "import polars as pl\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "def map_class(x, task, reader):\n",
    "    if task.name == 'multiclass':\n",
    "        return reader[x]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "mapped = np.vectorize(map_class)\n",
    "\n",
    "def score(task, y_true, y_pred):\n",
    "    if task.name == 'binary':\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    elif task.name == 'multiclass':\n",
    "        return log_loss(y_true, y_pred)\n",
    "    elif task.name == 'reg' or task.name == 'multi:reg':\n",
    "        return mean_squared_error(y_true, y_pred, squared=False)\n",
    "    else:\n",
    "        raise 'Task is not correct.'\n",
    "        \n",
    "def take_pred_from_task(pred, task):\n",
    "    if task.name == 'binary' or task.name == 'reg':\n",
    "        return pred[:, 0]\n",
    "    elif task.name == 'multiclass' or task.name == 'multi:reg':\n",
    "        return pred\n",
    "    else:\n",
    "        raise 'Task is not correct.'\n",
    "        \n",
    "def use_plr(USE_PLR):\n",
    "    if USE_PLR:\n",
    "        return \"plr\"\n",
    "    else:\n",
    "        return \"cont\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Events counts features >\n",
      "< Count vectorize one-grams >\n",
      "< Idle time features >\n",
      "< cursor position acceleration >\n",
      "< R-burst features >\n",
      "< Categorical # unique values features >\n",
      "< event_id rate of change >\n",
      "< Word counts rate of change features >\n",
      "< removed words pauses basic\n",
      "< Count vectorize bi-grams >\n",
      "< word_wait_shift >\n",
      "< remove_words_time_spent >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays sentences feats >\n",
      "< Essays sentences feats >\n",
      "< Essays word feats >\n",
      "< Essays word feats >\n",
      "train feats shape (2471, 186)\n"
     ]
    }
   ],
   "source": [
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n",
    "test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n",
    "train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')\n",
    "\n",
    "# PANDAS FEATS\n",
    "train_essays          = get_essay_df(train_logs.collect().to_pandas())\n",
    "test_essays           = get_essay_df(test_logs.collect().to_pandas())\n",
    "\n",
    "tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n",
    "tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n",
    "tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n",
    "tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n",
    "tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n",
    "tr_nuni, ts_nuni = categorical_nunique(train_logs, test_logs)\n",
    "tr_e_counts_roc, ts_e_counts_roc = events_counts_rate_of_change(train_logs, test_logs, time_agg=3)\n",
    "tr_wc_roc, ts_wc_roc = word_counts_rate_of_change(train_logs, test_logs)\n",
    "tr_remove_pause, ts_remove_pause = remove_word_pauses(train_logs, test_logs)\n",
    "tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n",
    "tr_word_wait, ts_word_wait = word_wait_shift(train_logs, test_logs, 1)\n",
    "tr_rem_words_time_spent, ts_rem_words_time_spent = remove_words_time_spent(train_logs, test_logs)\n",
    "\n",
    "\n",
    "train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_pauses, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_nuni, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_e_counts_roc, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_wc_roc, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_remove_pause, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_word_wait, on='id', how='left')\n",
    "train_feats = train_feats.join(tr_rem_words_time_spent, on='id', how='left')\n",
    "\n",
    "\n",
    "test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_pauses, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_nuni, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_e_counts_roc, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_wc_roc, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_remove_pause, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_word_wait, on='id', how='left')\n",
    "test_feats = test_feats.join(ts_rem_words_time_spent, on='id', how='left')\n",
    "\n",
    "train_logs = train_logs.collect().to_pandas()\n",
    "test_logs = test_logs.collect().to_pandas()\n",
    "train_scores = train_scores.collect().to_pandas()\n",
    "train_feats = train_feats.collect().to_pandas()\n",
    "test_feats = test_feats.collect().to_pandas()\n",
    "\n",
    "train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n",
    "train_feats           = train_feats.merge(word_feats(train_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(word_feats(test_essays), on='id', how='left')\n",
    "\n",
    "# tr_ids = train_feats.id\n",
    "# ts_ids = test_feats.id\n",
    "\n",
    "# feats = pd.concat([train_feats,test_feats], axis=0)\n",
    "# feats = preprocess_feats(feats)\n",
    "# train_feats = feats[feats['id'].isin(tr_ids)]\n",
    "# test_feats = feats[feats['id'].isin(ts_ids)]\n",
    "\n",
    "train_feats           = train_feats.merge(train_scores, on=['id'], how='left')\n",
    "print(f'train feats shape {train_feats.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5921516, 2.4715698, 3.1458085, ..., 3.7550766, 3.0411086,\n",
       "       4.064627 ], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TabularAutoML.__init__() got an unexpected keyword argument 'snap_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m roles \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m: TARGET_NAME,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m algo \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdenselight\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m automl \u001b[39m=\u001b[39m TabularAutoML(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     task \u001b[39m=\u001b[39;49m task, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     timeout \u001b[39m=\u001b[39;49m TIMEOUT,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     cpu_limit \u001b[39m=\u001b[39;49m N_THREADS,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     general_params \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39muse_algos\u001b[39;49m\u001b[39m\"\u001b[39;49m: [[algo]]}, \u001b[39m# ['nn', 'mlp', 'dense', 'denselight', 'resnet', 'snn', 'node', 'autoint', 'fttransformer'] or custom torch model\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     nn_params \u001b[39m=\u001b[39;49m {\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mn_epochs\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m2000\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mbs\u001b[39;49m\u001b[39m\"\u001b[39;49m: b, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnum_workers\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpath_to_save\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mNone\u001b[39;49;00m, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mfreeze_defaults\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     nn_pipeline_params \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39muse_qnt\u001b[39;49m\u001b[39m\"\u001b[39;49m: USE_QNT, \u001b[39m\"\u001b[39;49m\u001b[39muse_te\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m},\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     reader_params \u001b[39m=\u001b[39;49m {\u001b[39m'\u001b[39;49m\u001b[39mn_jobs\u001b[39;49m\u001b[39m'\u001b[39;49m: N_THREADS, \u001b[39m'\u001b[39;49m\u001b[39mcv\u001b[39;49m\u001b[39m'\u001b[39;49m: N_FOLDS, \u001b[39m'\u001b[39;49m\u001b[39mrandom_state\u001b[39;49m\u001b[39m'\u001b[39;49m: RANDOM_STATE, \u001b[39m'\u001b[39;49m\u001b[39madvanced_roles\u001b[39;49m\u001b[39m'\u001b[39;49m: ADVANCED_ROLES},\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     snap_params \u001b[39m=\u001b[39;49m {\u001b[39m'\u001b[39;49m\u001b[39mearly_stopping\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39mpatience\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m20\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mswa\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m}\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m oof_pred \u001b[39m=\u001b[39m automl\u001b[39m.\u001b[39mfit_predict(train_feats, roles \u001b[39m=\u001b[39m roles, verbose \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-LightAutoML.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m test_pred \u001b[39m=\u001b[39m automl\u001b[39m.\u001b[39mpredict(test_feats)    \n",
      "\u001b[0;31mTypeError\u001b[0m: TabularAutoML.__init__() got an unexpected keyword argument 'snap_params'"
     ]
    }
   ],
   "source": [
    "oof_preds = []\n",
    "test_preds = []\n",
    "ITERATIONS = 1\n",
    "TRAIN_BS = [128,192,256,316,512]  # list(np.arange(64,64*6,64)) #[156,192,256,316,512] \n",
    "\n",
    "snap_params = {'early_stopping': True, 'patience': 20, 'swa': True}\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    for b in TRAIN_BS:\n",
    "        N_THREADS = 2\n",
    "        N_FOLDS = 10\n",
    "        TEST_SIZE = 0.15\n",
    "        VAL_SIZE = 0.15\n",
    "        TIMEOUT = 10000\n",
    "        ADVANCED_ROLES = False\n",
    "        USE_QNT = True\n",
    "        TASK = 'reg'\n",
    "        USE_PLR = True\n",
    "        USE_FS = True\n",
    "        TARGET_NAME = 'score'\n",
    "        FEATURE_RATIO = 0.8\n",
    "            \n",
    "        np.random.seed(RANDOM_STATE+b)\n",
    "        torch.set_num_threads(N_THREADS)\n",
    "\n",
    "        task = Task(TASK)\n",
    "\n",
    "    # example for binary classification\n",
    "        roles = {\n",
    "            'target': TARGET_NAME,\n",
    "            'drop': ['id']\n",
    "        }\n",
    "        algo = 'denselight'\n",
    "        automl = TabularAutoML(\n",
    "            task = task, \n",
    "            timeout = TIMEOUT,\n",
    "            cpu_limit = N_THREADS,\n",
    "            general_params = {\"use_algos\": [[algo]]}, # ['nn', 'mlp', 'dense', 'denselight', 'resnet', 'snn', 'node', 'autoint', 'fttransformer'] or custom torch model\n",
    "            nn_params = {\n",
    "                \"n_epochs\": 2000, \n",
    "                \"bs\": b, \n",
    "                \"num_workers\": 0, \n",
    "                \"path_to_save\": None, \n",
    "                \"freeze_defaults\": True,\n",
    "            },\n",
    "            nn_pipeline_params = {\"use_qnt\": USE_QNT, \"use_te\": False},\n",
    "            reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE, 'advanced_roles': ADVANCED_ROLES},\n",
    "        )\n",
    "\n",
    "        oof_pred = automl.fit_predict(train_feats, roles = roles, verbose = 3)\n",
    "        test_pred = automl.predict(test_feats)    \n",
    "        joblib.dump(automl, f'automl_model_{b}_{i}.joblib')            \n",
    "\n",
    "        oof_preds.append(oof_pred)\n",
    "        test_preds.append(test_pred)\n",
    "        oof = score(task, mapped(train_feats[TARGET_NAME].values, task, automl.reader.class_mapping), take_pred_from_task(oof_pred.data, task))\n",
    "        denselight_list = [(oof, oof_pred.data[:, 0], test_pred.data[:, 0])]\n",
    "        print(f'RMSE: {oof}')\n",
    "\n",
    "stacked_preds = np.stack([p.data[:, 0] for p in oof_preds])\n",
    "avg_preds = np.mean(stacked_preds, axis=0)\n",
    "y = train_feats[TARGET_NAME].values\n",
    "final_oof_rmse = mean_squared_error(y, avg_preds, squared=False)\n",
    "print(f'Final RMSE: {final_oof_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_stack = np.stack([p.data[:, 0] for p in test_preds])\n",
    "test_preds_mean = np.mean(test_preds_stack, axis=0)\n",
    "ts_ids = test_feats.id\n",
    "\n",
    "sub = pd.DataFrame({'id': ts_ids, 'score': test_preds_mean})\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
