{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_valid_split(data_x, data_y, train_idx, valid_idx):\n",
    "    x_train = data_x.loc[train_idx].values\n",
    "    y_train = data_y[train_idx].values.reshape(-1,1)\n",
    "    x_valid = data_x.loc[valid_idx].values\n",
    "    y_valid = data_y[valid_idx].values.reshape(-1,1)\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "def calculate_rmse(y, yhat):\n",
    "    return mean_squared_error(y, yhat, squared=False)\n",
    "\n",
    "def preprocess_feats(feats, scaler=StandardScaler()):\n",
    "    # Replace inf/-inf with NaN and then fill NaNs with a large negative number\n",
    "    feats = np.where(np.isinf(feats), np.nan, feats)\n",
    "    feats = np.nan_to_num(feats, nan=-1e10)\n",
    "    return scaler.fit_transform(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.read_pickle('feature_selection/train_feats.pkl')\n",
    "test_feats = pd.read_pickle('feature_selection/test_feats.pkl')\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO DO HYPER PARAMETER TUNNING AFTER FEATS SELECTION IS COMPLETED\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using {}\".format(DEVICE))\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters here as in previous examples\n",
    "    rmse_scores = []\n",
    "    params = {\n",
    "        'n_d': trial.suggest_int('n_d', 8, 32),\n",
    "        'n_a': trial.suggest_int('n_a', 8, 32),\n",
    "        'n_steps': trial.suggest_int('n_steps', 3, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "        'n_independent': trial.suggest_int('n_independent', 1, 5),\n",
    "        'n_shared': trial.suggest_int('n_shared', 1, 5),\n",
    "        # Include other parameters as needed\n",
    "        'optimizer_fn': torch.optim.Adam,\n",
    "        'scheduler_params': {\"milestones\": list(np.arange(50,1000,50)), 'gamma':0.2},\n",
    "        'scheduler_fn': torch.optim.lr_scheduler.MultiStepLR,\n",
    "    }\n",
    "\n",
    "    test_preds, valid_preds, final_rmse, model = TabNet_pipeline(train_feats, test_feats, params)\n",
    "    return np.mean(final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to be tuned by Optuna\n",
    "    param = {\n",
    "        'n_d': trial.suggest_int('n_d', 8, 32),\n",
    "        'n_a': trial.suggest_int('n_a', 8, 32),\n",
    "        'n_steps': trial.suggest_int('n_steps', 3, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "        'n_independent': trial.suggest_int('n_independent', 1, 5),\n",
    "        'n_shared': trial.suggest_int('n_shared', 1, 5),\n",
    "        # Include other parameters as needed\n",
    "        'optimizer_fn': torch.optim.Adam,\n",
    "        'scheduler_params': {\"milestones\": [150,250,300,350,400,450], 'gamma':0.2},\n",
    "        'scheduler_fn': torch.optim.lr_scheduler.MultiStepLR,\n",
    "        'device_name': DEVICE\n",
    "    }\n",
    "\n",
    "    # Initialize model\n",
    "    model = TabNetRegressor(**param)\n",
    "    train_feats = pd.read_pickle('feature_selection/train_feats_2.pkl')\n",
    "    test_feats = pd.read_pickle('feature_selection/test_feats_2.pkl')\n",
    "    train_feats = preprocess_feats(train_feats)\n",
    "    test_x = test_feats.drop(columns = ['id']).values\n",
    "    x = train_feats.drop(['id', 'score'], axis=1)\n",
    "    y = train_feats['score']\n",
    "\n",
    "    # Splitting data (use your own train_valid_split function)\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(x, y.astype(str))):\n",
    "        train_x, train_y, valid_x, valid_y = train_valid_split(x, y, train_index, valid_index)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(\n",
    "        X_train=train_x, y_train=train_y,\n",
    "        eval_set=[(valid_x, valid_y)],\n",
    "        max_epochs=1000,\n",
    "        patience=70,\n",
    "        batch_size=1024,  # or any other batch size\n",
    "        virtual_batch_size=128  # or any other virtual batch size\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    valid_predictions = model.predict(valid_x)\n",
    "    rmse = sqrt(mean_squared_error(valid_y, valid_predictions))\n",
    "\n",
    "    return rmse\n",
    "\n",
    "test_preds = []\n",
    "valid_preds = pd.DataFrame()\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
