{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-18T16:20:56.671429Z","iopub.status.busy":"2023-12-18T16:20:56.671017Z","iopub.status.idle":"2023-12-18T16:20:58.568632Z","shell.execute_reply":"2023-12-18T16:20:58.567768Z","shell.execute_reply.started":"2023-12-18T16:20:56.671393Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from m4_feats_polars import *\n","from m5_sb_models import *"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:20:58.587076Z","iopub.status.busy":"2023-12-18T16:20:58.586426Z","iopub.status.idle":"2023-12-18T16:20:58.601881Z","shell.execute_reply":"2023-12-18T16:20:58.600973Z","shell.execute_reply.started":"2023-12-18T16:20:58.587045Z"},"trusted":true},"outputs":[],"source":["lgb_params_1 = {\n","    'boosting_type': 'gbdt', \n","    'metric': 'rmse',\n","    'reg_alpha': 0.0031, \n","    'reg_lambda': 0.001, \n","    'colsample_bytree': 0.8,  \n","    'subsample_freq': 1,  \n","    'subsample': 0.75,  \n","    'learning_rate': 0.017, \n","    'num_leaves': 19, \n","    'min_child_samples': 46,\n","    'n_estimators': 400,\n","    'verbosity': -1\n","    }\n","\n","param = {'n_estimators': 1024,\n","         'learning_rate': 0.005,\n","         'metric': 'rmse',\n","         'force_col_wise': True,\n","         'verbosity': 0,}\n","\n","import polars as pl\n","data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n","train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n","test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n","train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["Best_Feature_Set = [\n","    'train_down_events_counts.pkl', \n","    'train_vector_one_gram.pkl', \n","    'train_create_pauses.pkl', \n","    'train_essay_paragraphs.pkl', \n","    'train_cursor_pos_acceleration.pkl', \n","    'train_word_count_acceleration.pkl', \n","    'train_vector_two_gram.pkl']\n","\n","best_feature_set_2 = [\n","    'train_down_events_counts.pkl',\n","    'train_vector_one_gram.pkl',\n","    'train_create_pauses.pkl',\n","    'train_essay_paragraphs.pkl',\n","    'train_essay_sentences.pkl',\n","    'train_cursor_pos_acceleration.pkl',\n","    'train_word_count_acceleration.pkl',\n","    'train_categorical_nunique.pkl',\n","    'train_cursor_pos_rate_of_change.pkl',\n","    'train_get_keys_pressed_per_second.pkl']   "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:20:58.604202Z","iopub.status.busy":"2023-12-18T16:20:58.603768Z","iopub.status.idle":"2023-12-18T16:21:44.319317Z","shell.execute_reply":"2023-12-18T16:21:44.318111Z","shell.execute_reply.started":"2023-12-18T16:20:58.604175Z"},"trusted":true},"outputs":[],"source":["# # best_feature_set_2 - DONE UNTIL THE END\n","# train_essays          = get_essay_df(train_logs.collect().to_pandas())\n","# test_essays           = get_essay_df(test_logs.collect().to_pandas())\n","\n","# # train_down_events_counts\n","# tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n","# # train_vector_one_gram\n","# tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n","# # train_create_pauses\n","# tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n","# # train_cursor_pos_acceleration\n","# tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n","# # train_word_count_acceleration\n","# tr_word_count_acc, ts_word_count_acc = word_count_acceleration(train_logs, test_logs)\n","# # nunique\n","# tr_nunique, ts_nunique = categorical_nunique(train_logs, test_logs)\n","# # cursor_pos_rate_of_change\n","# tr_cur_pos_roc, ts_cur_pos_roc = cursor_pos_rate_of_change(train_logs, test_logs)\n","# # get keys pressed per second\n","# tr_get_keys, ts_get_keys = get_keys_pressed_per_second(train_logs.collect().to_pandas(), test_logs.collect().to_pandas())\n","\n","# # # r_burst_feats\n","# # tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n","# # # p_burst_feats\n","# # tr_p_burst, ts_p_burst = p_burst_feats(train_logs, test_logs)\n","\n","# train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n","# train_feats = train_feats.join(tr_pauses, on='id', how='left')\n","# train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n","# train_feats = train_feats.join(tr_word_count_acc, on='id', how='left')\n","# train_feats = train_feats.join(tr_nunique, on='id', how='left')\n","# train_feats = train_feats.join(tr_cur_pos_roc, on='id', how='left')\n","# train_feats = train_feats.join(tr_get_keys, on='id', how='left')\n","\n","# #train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n","# #train_feats = train_feats.join(tr_p_burst, on='id', how='left')\n","# #train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n","# #train_feats = train_feats.join(tr_nunique, on='id', how='left')\n","\n","\n","# test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n","# test_feats = test_feats.join(ts_pauses, on='id', how='left')\n","# test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_word_count_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_nunique, on='id', how='left')\n","# test_feats = test_feats.join(ts_cur_pos_roc, on='id', how='left')\n","# test_feats = test_feats.join(ts_get_keys, on='id', how='left')\n","\n","# #test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n","# #test_feats = test_feats.join(ts_p_burst, on='id', how='left')\n","# #test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n","# #test_feats = test_feats.join(ts_nunique, on='id', how='left')\n","\n","\n","# train_logs = train_logs.collect().to_pandas()\n","# test_logs = test_logs.collect().to_pandas()\n","# train_scores = train_scores.collect().to_pandas()\n","# train_feats = train_feats.collect().to_pandas()\n","# test_feats = test_feats.collect().to_pandas()\n","\n","# train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n","# test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n","# train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n","# test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n","\n","# train_feats           = train_feats.merge(train_scores, on=['id'], how='left')\n","# print(f'train feats shape {train_feats.shape}')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< Events counts features >\n","< Count vectorize one-grams >\n","< Idle time features >\n","< cursor position acceleration >\n","< word count acceleration >\n","< Count vectorize bi-grams >\n","< R-burst features >\n","< P-burst features >\n","< Categorical # unique values features >\n","< Essays paragraphs feats >\n","< Essays paragraphs feats >\n","train feats shape (2471, 117)\n"]}],"source":["train_essays          = get_essay_df(train_logs.collect().to_pandas())\n","test_essays           = get_essay_df(test_logs.collect().to_pandas())\n","\n","# train_down_events_counts\n","tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n","# train_vector_one_gram\n","tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n","# train_create_pauses\n","tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n","# train_cursor_pos_acceleration\n","tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n","# train_word_count_acceleration\n","tr_word_count_acc, ts_word_count_acc = word_count_acceleration(train_logs, test_logs)\n","# train_vector_two_gram\n","tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n","# count_of_activities(train_logs, test_logs)\n","tr_act_count, ts_act_count = count_of_activities(train_logs, test_logs)\n","\n","# # r_burst_feats\n","tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n","# # p_burst_feats\n","tr_p_burst, ts_p_burst = p_burst_feats(train_logs, test_logs)\n","# nunique\n","tr_nunique, ts_nunique = categorical_nunique(train_logs, test_logs)\n","\n","train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n","train_feats = train_feats.join(tr_pauses, on='id', how='left')\n","train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_word_count_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n","#train_feats = train_feats.join(tr_p_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_nunique, on='id', how='left')\n","train_feats = train_feats.join(tr_act_count, on='id', how='left')\n","\n","\n","\n","test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n","test_feats = test_feats.join(ts_pauses, on='id', how='left')\n","test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_word_count_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n","#test_feats = test_feats.join(ts_p_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_nunique, on='id', how='left')\n","test_feats = test_feats.join(ts_act_count, on='id', how='left')\n","\n","\n","train_logs = train_logs.collect().to_pandas()\n","test_logs = test_logs.collect().to_pandas()\n","train_scores = train_scores.collect().to_pandas()\n","train_feats = train_feats.collect().to_pandas()\n","test_feats = test_feats.collect().to_pandas()\n","\n","train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n","\n","train_feats           = train_feats.merge(train_scores, on=['id'], how='left')\n","print(f'train feats shape {train_feats.shape}')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:21:44.320780Z","iopub.status.busy":"2023-12-18T16:21:44.320496Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/miniconda3/envs/lrp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n","  warnings.warn(\n","/root/miniconda3/envs/lrp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n","  warnings.warn(\n","/root/miniconda3/envs/lrp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n","  warnings.warn(\n","/root/miniconda3/envs/lrp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n","  warnings.warn(\n","/root/miniconda3/envs/lrp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Final RMSE over 50: 0.609640. Std 0.8220\n","RMSE by fold 0.609492. Std 0.0132\n"]}],"source":["missing_cols = set(train_feats.columns) - set(test_feats.columns)\n","missing_cols.remove('score')\n","\n","for col in missing_cols:\n","    test_feats[col] = np.nan\n","\n","test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, param)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train_feats = pd.read_pickle(f'feature_selection/train_feats.pkl')\n","# test_feats.to_pickle(f'feature_selection/test_feats.pkl')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["id\n","down_event_1\n","down_event_2\n","down_event_3\n","down_event_4\n","down_event_5\n","down_event_6\n","down_event_7\n","down_event_8\n","down_event_9\n","down_event_10\n","down_event_11\n","down_event_12\n","down_event_13\n","down_event_14\n","down_event_15\n","down_event_16\n","down_event_17\n","down_event_18\n","down_event_19\n","down_event_20\n","one_gram_tok_0\n","one_gram_tok_1\n","one_gram_tok_2\n","one_gram_tok_3\n","one_gram_tok_4\n","one_gram_tok_5\n","one_gram_tok_6\n","one_gram_tok_7\n","one_gram_tok_8\n","one_gram_tok_9\n","one_gram_tok_10\n","one_gram_tok_11\n","one_gram_tok_12\n","one_gram_tok_13\n","one_gram_tok_14\n","one_gram_tok_15\n","inter_key_largest_lantency\n","inter_key_median_lantency\n","mean_pause_time\n","std_pause_time\n","total_pause_time\n","pauses_half_sec\n","pauses_1_sec\n","pauses_1_half_sec\n","pauses_2_sec\n","pauses_3_sec\n","cursor_pos_acc_zero\n","cursor_pos_acc_pst\n","cursor_pos_acc_neg\n","cursor_pos_acc_sum\n","cursor_pos_acc_mean\n","cursor_pos_acc_std\n","cursor_pos_acc_max\n","cursor_pos_acc_q1\n","cursor_pos_acc_median\n","cursor_pos_acc_q3\n","cursor_pos_acc_kurt\n","cursor_pos_acc_skew\n","word_count_acc_zero\n","word_count_acc_pst\n","word_count_acc_neg\n","word_count_acc_sum\n","word_count_acc_mean\n","word_count_acc_std\n","word_count_acc_max\n","word_count_acc_q1\n","word_count_acc_median\n","word_count_acc_q3\n","word_count_acc_kurt\n","word_count_acc_skew\n","bigram_tok_0\n","bigram_tok_1\n","bigram_tok_2\n","bigram_tok_3\n","bigram_tok_4\n","bigram_tok_5\n","bigram_tok_6\n","bigram_tok_7\n","bigram_tok_8\n","bigram_tok_9\n","bigram_tok_10\n","bigram_tok_11\n","bigram_tok_12\n","bigram_tok_13\n","bigram_tok_14\n","bigram_tok_15\n","paragraph_count\n","paragraph_len_mean\n","paragraph_len_min\n","paragraph_len_max\n","paragraph_len_first\n","paragraph_len_last\n","paragraph_len_q1\n","paragraph_len_median\n","paragraph_len_q3\n","paragraph_len_sum\n","paragraph_word_count_mean\n","paragraph_word_count_min\n","paragraph_word_count_max\n","paragraph_word_count_first\n","paragraph_word_count_last\n","paragraph_word_count_q1\n","paragraph_word_count_median\n","paragraph_word_count_q3\n","paragraph_word_count_sum\n","score\n"]}],"source":["for col in train_feats.columns:\n","    print(col)"]},{"cell_type":"markdown","metadata":{},"source":["Best_Feature_Set\n","Final RMSE over 50: 0.603377. Std 0.8293\n","RMSE by fold 0.603282. Std 0.0112\n","\n","Final RMSE over 50: 0.609901. Std 0.8218\n","RMSE by fold 0.609733. Std 0.0145\n","\n","Best_Feature_Set_2\n","Final RMSE over 50: 0.605864. Std 0.8239\n","RMSE by fold 0.605801. Std 0.0091"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["test_ids = test_feats.id\n","y_pred = np.mean(test_preds, axis=0)\n","\n","sub = pd.DataFrame({'id': test_ids, 'score': y_pred})\n","sub.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000aaaa</td>\n","      <td>1.402126</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4444cccc</td>\n","      <td>1.353844</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2222bbbb</td>\n","      <td>1.336026</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id     score\n","0  0000aaaa  1.402126\n","1  4444cccc  1.353844\n","2  2222bbbb  1.336026"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["sub"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6678907,"sourceId":59291,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
