{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-18T16:20:56.671429Z","iopub.status.busy":"2023-12-18T16:20:56.671017Z","iopub.status.idle":"2023-12-18T16:20:58.568632Z","shell.execute_reply":"2023-12-18T16:20:58.567768Z","shell.execute_reply.started":"2023-12-18T16:20:56.671393Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import polars as pl\n","\n","from m4_feats_polars import *\n","from m5_sb_models import *\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:20:58.587076Z","iopub.status.busy":"2023-12-18T16:20:58.586426Z","iopub.status.idle":"2023-12-18T16:20:58.601881Z","shell.execute_reply":"2023-12-18T16:20:58.600973Z","shell.execute_reply.started":"2023-12-18T16:20:58.587045Z"},"trusted":true},"outputs":[],"source":["# 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\n","data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n","train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n","test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n","train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')\n","\n","# train_logs, test_logs = amend_event_id_order(train_logs, test_logs)     worsens"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def essay_sent_words(df):\n","    AGGREGATIONS = ['count', 'mean', 'max', 'first', q1, 'median', q3, 'sum']\n","    df['sent'] = df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n","    df = df.explode('sent')\n","    df['sent'] = df['sent'].apply(lambda x: x.replace('\\n','').strip())\n","    df['sent_word_count'] = df['sent'].apply(lambda x: len(x.split(' ')))\n","\n","    sent_agg_df = df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)\n","    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n","    sent_agg_df['id'] = sent_agg_df.index\n","    sent_agg_df = sent_agg_df.reset_index(drop=True)\n","    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n","    return sent_agg_df\n","\n","def essay_sent_length(df):\n","    AGGREGATIONS = ['count', 'mean', 'min', 'max', 'first', 'last', q1, 'median', q3, 'sum']\n","\n","    print(\"< Essays sentences feats >\")    \n","    df['sent'] = df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n","    df = df.explode('sent')\n","    df['sent'] = df['sent'].apply(lambda x: x.replace('\\n','').strip())\n","    df['sent_len'] = df['sent'].apply(lambda x: len(x))\n","    df = df[df.sent_len!=0].reset_index(drop=True)\n","\n","    sent_agg_df = df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS)\n","    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n","    sent_agg_df['id'] = sent_agg_df.index\n","    sent_agg_df = sent_agg_df.reset_index(drop=True)\n","    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n","    return sent_agg_df\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< Essays paragraphs feats >\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>paragraph_count</th>\n","      <th>paragraph_len_mean</th>\n","      <th>paragraph_len_min</th>\n","      <th>paragraph_len_max</th>\n","      <th>paragraph_len_first</th>\n","      <th>paragraph_len_last</th>\n","      <th>paragraph_len_q1</th>\n","      <th>paragraph_len_median</th>\n","      <th>paragraph_len_q3</th>\n","      <th>paragraph_len_sum</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>508.000000</td>\n","      <td>390</td>\n","      <td>654</td>\n","      <td>390</td>\n","      <td>480</td>\n","      <td>435.00</td>\n","      <td>480.0</td>\n","      <td>567.00</td>\n","      <td>1524</td>\n","      <td>001519c8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>278.166667</td>\n","      <td>176</td>\n","      <td>462</td>\n","      <td>240</td>\n","      <td>284</td>\n","      <td>228.75</td>\n","      <td>261.0</td>\n","      <td>283.50</td>\n","      <td>1669</td>\n","      <td>0022f953</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6</td>\n","      <td>429.500000</td>\n","      <td>296</td>\n","      <td>568</td>\n","      <td>491</td>\n","      <td>296</td>\n","      <td>356.75</td>\n","      <td>444.5</td>\n","      <td>483.50</td>\n","      <td>2577</td>\n","      <td>0042269b</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>384.000000</td>\n","      <td>347</td>\n","      <td>449</td>\n","      <td>347</td>\n","      <td>356</td>\n","      <td>351.50</td>\n","      <td>356.0</td>\n","      <td>402.50</td>\n","      <td>1152</td>\n","      <td>0059420b</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>283.400000</td>\n","      <td>23</td>\n","      <td>627</td>\n","      <td>351</td>\n","      <td>23</td>\n","      <td>124.00</td>\n","      <td>292.0</td>\n","      <td>351.00</td>\n","      <td>1417</td>\n","      <td>0075873a</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2466</th>\n","      <td>4</td>\n","      <td>407.750000</td>\n","      <td>301</td>\n","      <td>514</td>\n","      <td>372</td>\n","      <td>301</td>\n","      <td>354.25</td>\n","      <td>408.0</td>\n","      <td>461.50</td>\n","      <td>1631</td>\n","      <td>ffb8c745</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>6</td>\n","      <td>387.166667</td>\n","      <td>144</td>\n","      <td>648</td>\n","      <td>144</td>\n","      <td>228</td>\n","      <td>274.00</td>\n","      <td>424.0</td>\n","      <td>450.25</td>\n","      <td>2323</td>\n","      <td>ffbef7e5</td>\n","    </tr>\n","    <tr>\n","      <th>2468</th>\n","      <td>3</td>\n","      <td>918.333333</td>\n","      <td>327</td>\n","      <td>2002</td>\n","      <td>426</td>\n","      <td>2002</td>\n","      <td>376.50</td>\n","      <td>426.0</td>\n","      <td>1214.00</td>\n","      <td>2755</td>\n","      <td>ffccd6fd</td>\n","    </tr>\n","    <tr>\n","      <th>2469</th>\n","      <td>5</td>\n","      <td>509.600000</td>\n","      <td>380</td>\n","      <td>672</td>\n","      <td>672</td>\n","      <td>380</td>\n","      <td>394.00</td>\n","      <td>540.0</td>\n","      <td>562.00</td>\n","      <td>2548</td>\n","      <td>ffec5b38</td>\n","    </tr>\n","    <tr>\n","      <th>2470</th>\n","      <td>6</td>\n","      <td>247.166667</td>\n","      <td>59</td>\n","      <td>412</td>\n","      <td>59</td>\n","      <td>224</td>\n","      <td>171.50</td>\n","      <td>229.5</td>\n","      <td>358.00</td>\n","      <td>1483</td>\n","      <td>fff05981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2471 rows × 11 columns</p>\n","</div>"],"text/plain":["      paragraph_count  paragraph_len_mean  paragraph_len_min  \\\n","0                   3          508.000000                390   \n","1                   6          278.166667                176   \n","2                   6          429.500000                296   \n","3                   3          384.000000                347   \n","4                   5          283.400000                 23   \n","...               ...                 ...                ...   \n","2466                4          407.750000                301   \n","2467                6          387.166667                144   \n","2468                3          918.333333                327   \n","2469                5          509.600000                380   \n","2470                6          247.166667                 59   \n","\n","      paragraph_len_max  paragraph_len_first  paragraph_len_last  \\\n","0                   654                  390                 480   \n","1                   462                  240                 284   \n","2                   568                  491                 296   \n","3                   449                  347                 356   \n","4                   627                  351                  23   \n","...                 ...                  ...                 ...   \n","2466                514                  372                 301   \n","2467                648                  144                 228   \n","2468               2002                  426                2002   \n","2469                672                  672                 380   \n","2470                412                   59                 224   \n","\n","      paragraph_len_q1  paragraph_len_median  paragraph_len_q3  \\\n","0               435.00                 480.0            567.00   \n","1               228.75                 261.0            283.50   \n","2               356.75                 444.5            483.50   \n","3               351.50                 356.0            402.50   \n","4               124.00                 292.0            351.00   \n","...                ...                   ...               ...   \n","2466            354.25                 408.0            461.50   \n","2467            274.00                 424.0            450.25   \n","2468            376.50                 426.0           1214.00   \n","2469            394.00                 540.0            562.00   \n","2470            171.50                 229.5            358.00   \n","\n","      paragraph_len_sum        id  \n","0                  1524  001519c8  \n","1                  1669  0022f953  \n","2                  2577  0042269b  \n","3                  1152  0059420b  \n","4                  1417  0075873a  \n","...                 ...       ...  \n","2466               1631  ffb8c745  \n","2467               2323  ffbef7e5  \n","2468               2755  ffccd6fd  \n","2469               2548  ffec5b38  \n","2470               1483  fff05981  \n","\n","[2471 rows x 11 columns]"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["def essay_par_length(df):\n","    AGGREGATIONS = ['count', 'mean', 'min', 'max', 'first', 'last', q1, 'median', q3, 'sum']\n","\n","    print(\"< Essays paragraphs feats >\")    \n","    df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n","    df = df.explode('paragraph')\n","    df['paragraph_len'] = df['paragraph'].apply(lambda x: len(x)) \n","    df = df[df.paragraph_len!=0].reset_index(drop=True)\n","    \n","    paragraph_agg_df = df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS)\n","                                 \n","    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n","    paragraph_agg_df['id'] = paragraph_agg_df.index\n","    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n","    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n","    return paragraph_agg_df\n","\n","def essay_par_words(df):\n","    AGGREGATIONS = ['count', 'mean', 'min', 'max', 'first', 'last', q1, 'median', q3, 'sum']\n","    print(\"< Essays paragraphs feats >\")    \n","    df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n","    df = df.explode('paragraph')\n","    df['paragraph_word_count'] = df['paragraph'].apply(lambda x: len(x.split(' ')))\n","    \n","    paragraph_agg_df = df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)\n","    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n","    paragraph_agg_df['id'] = paragraph_agg_df.index\n","    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n","    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n","    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n","    return paragraph_agg_df"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< Essays paragraphs feats >\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>paragraph_word_count_mean</th>\n","      <th>paragraph_word_count_min</th>\n","      <th>paragraph_word_count_max</th>\n","      <th>paragraph_word_count_first</th>\n","      <th>paragraph_word_count_last</th>\n","      <th>paragraph_word_count_q1</th>\n","      <th>paragraph_word_count_median</th>\n","      <th>paragraph_word_count_q3</th>\n","      <th>paragraph_word_count_sum</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>54.200000</td>\n","      <td>1</td>\n","      <td>112</td>\n","      <td>71</td>\n","      <td>86</td>\n","      <td>1.0</td>\n","      <td>71.0</td>\n","      <td>86.00</td>\n","      <td>271</td>\n","      <td>001519c8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50.857143</td>\n","      <td>1</td>\n","      <td>96</td>\n","      <td>53</td>\n","      <td>1</td>\n","      <td>41.5</td>\n","      <td>53.0</td>\n","      <td>61.50</td>\n","      <td>356</td>\n","      <td>0022f953</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>37.727273</td>\n","      <td>1</td>\n","      <td>88</td>\n","      <td>79</td>\n","      <td>45</td>\n","      <td>1.0</td>\n","      <td>45.0</td>\n","      <td>73.50</td>\n","      <td>415</td>\n","      <td>0042269b</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>69.333333</td>\n","      <td>62</td>\n","      <td>81</td>\n","      <td>62</td>\n","      <td>65</td>\n","      <td>63.5</td>\n","      <td>65.0</td>\n","      <td>73.00</td>\n","      <td>208</td>\n","      <td>0059420b</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28.888889</td>\n","      <td>1</td>\n","      <td>114</td>\n","      <td>61</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>52.00</td>\n","      <td>260</td>\n","      <td>0075873a</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2466</th>\n","      <td>77.000000</td>\n","      <td>63</td>\n","      <td>88</td>\n","      <td>71</td>\n","      <td>63</td>\n","      <td>69.0</td>\n","      <td>78.5</td>\n","      <td>86.50</td>\n","      <td>308</td>\n","      <td>ffb8c745</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>34.615385</td>\n","      <td>1</td>\n","      <td>119</td>\n","      <td>27</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>80.00</td>\n","      <td>450</td>\n","      <td>ffbef7e5</td>\n","    </tr>\n","    <tr>\n","      <th>2468</th>\n","      <td>264.285714</td>\n","      <td>1</td>\n","      <td>1703</td>\n","      <td>83</td>\n","      <td>1703</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>71.50</td>\n","      <td>1850</td>\n","      <td>ffccd6fd</td>\n","    </tr>\n","    <tr>\n","      <th>2469</th>\n","      <td>83.400000</td>\n","      <td>62</td>\n","      <td>111</td>\n","      <td>111</td>\n","      <td>62</td>\n","      <td>66.0</td>\n","      <td>85.0</td>\n","      <td>93.00</td>\n","      <td>417</td>\n","      <td>ffec5b38</td>\n","    </tr>\n","    <tr>\n","      <th>2470</th>\n","      <td>24.900000</td>\n","      <td>1</td>\n","      <td>66</td>\n","      <td>10</td>\n","      <td>38</td>\n","      <td>1.0</td>\n","      <td>15.5</td>\n","      <td>43.25</td>\n","      <td>249</td>\n","      <td>fff05981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2471 rows × 10 columns</p>\n","</div>"],"text/plain":["      paragraph_word_count_mean  paragraph_word_count_min  \\\n","0                     54.200000                         1   \n","1                     50.857143                         1   \n","2                     37.727273                         1   \n","3                     69.333333                        62   \n","4                     28.888889                         1   \n","...                         ...                       ...   \n","2466                  77.000000                        63   \n","2467                  34.615385                         1   \n","2468                 264.285714                         1   \n","2469                  83.400000                        62   \n","2470                  24.900000                         1   \n","\n","      paragraph_word_count_max  paragraph_word_count_first  \\\n","0                          112                          71   \n","1                           96                          53   \n","2                           88                          79   \n","3                           81                          62   \n","4                          114                          61   \n","...                        ...                         ...   \n","2466                        88                          71   \n","2467                       119                          27   \n","2468                      1703                          83   \n","2469                       111                         111   \n","2470                        66                          10   \n","\n","      paragraph_word_count_last  paragraph_word_count_q1  \\\n","0                            86                      1.0   \n","1                             1                     41.5   \n","2                            45                      1.0   \n","3                            65                     63.5   \n","4                             3                      1.0   \n","...                         ...                      ...   \n","2466                         63                     69.0   \n","2467                          1                      1.0   \n","2468                       1703                      1.0   \n","2469                         62                     66.0   \n","2470                         38                      1.0   \n","\n","      paragraph_word_count_median  paragraph_word_count_q3  \\\n","0                            71.0                    86.00   \n","1                            53.0                    61.50   \n","2                            45.0                    73.50   \n","3                            65.0                    73.00   \n","4                             3.0                    52.00   \n","...                           ...                      ...   \n","2466                         78.5                    86.50   \n","2467                          1.0                    80.00   \n","2468                          1.0                    71.50   \n","2469                         85.0                    93.00   \n","2470                         15.5                    43.25   \n","\n","      paragraph_word_count_sum        id  \n","0                          271  001519c8  \n","1                          356  0022f953  \n","2                          415  0042269b  \n","3                          208  0059420b  \n","4                          260  0075873a  \n","...                        ...       ...  \n","2466                       308  ffb8c745  \n","2467                       450  ffbef7e5  \n","2468                      1850  ffccd6fd  \n","2469                       417  ffec5b38  \n","2470                       249  fff05981  \n","\n","[2471 rows x 10 columns]"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["def essay_par_words(df):\n","    AGGREGATIONS = ['count', 'mean', 'min', 'max', 'first', 'last', q1, 'median', q3, 'sum']\n","    print(\"< Essays paragraphs feats >\")    \n","    df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n","    df = df.explode('paragraph')\n","    df['paragraph_word_count'] = df['paragraph'].apply(lambda x: len(x.split(' ')))\n","    \n","    paragraph_agg_df = df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)\n","    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n","    paragraph_agg_df['id'] = paragraph_agg_df.index\n","    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n","    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n","    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n","    return paragraph_agg_df\n","parag_feats(train_essays)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< Essays sentences feats >\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent_count</th>\n","      <th>sent_len_mean</th>\n","      <th>sent_len_min</th>\n","      <th>sent_len_max</th>\n","      <th>sent_len_first</th>\n","      <th>sent_len_last</th>\n","      <th>sent_len_q1</th>\n","      <th>sent_len_median</th>\n","      <th>sent_len_q3</th>\n","      <th>sent_len_sum</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14</td>\n","      <td>106.142857</td>\n","      <td>31</td>\n","      <td>196</td>\n","      <td>31</td>\n","      <td>89</td>\n","      <td>75.50</td>\n","      <td>119.5</td>\n","      <td>126.00</td>\n","      <td>1486</td>\n","      <td>001519c8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>15</td>\n","      <td>107.666667</td>\n","      <td>19</td>\n","      <td>226</td>\n","      <td>19</td>\n","      <td>143</td>\n","      <td>56.50</td>\n","      <td>92.0</td>\n","      <td>149.50</td>\n","      <td>1615</td>\n","      <td>0022f953</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19</td>\n","      <td>133.842105</td>\n","      <td>73</td>\n","      <td>189</td>\n","      <td>139</td>\n","      <td>161</td>\n","      <td>108.00</td>\n","      <td>139.0</td>\n","      <td>161.00</td>\n","      <td>2543</td>\n","      <td>0042269b</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13</td>\n","      <td>86.846154</td>\n","      <td>39</td>\n","      <td>144</td>\n","      <td>99</td>\n","      <td>80</td>\n","      <td>62.00</td>\n","      <td>80.0</td>\n","      <td>99.00</td>\n","      <td>1129</td>\n","      <td>0059420b</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>16</td>\n","      <td>86.812500</td>\n","      <td>22</td>\n","      <td>182</td>\n","      <td>75</td>\n","      <td>22</td>\n","      <td>60.00</td>\n","      <td>74.0</td>\n","      <td>106.25</td>\n","      <td>1389</td>\n","      <td>0075873a</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2466</th>\n","      <td>13</td>\n","      <td>121.076923</td>\n","      <td>55</td>\n","      <td>180</td>\n","      <td>79</td>\n","      <td>109</td>\n","      <td>84.00</td>\n","      <td>132.0</td>\n","      <td>147.00</td>\n","      <td>1574</td>\n","      <td>ffb8c745</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>29</td>\n","      <td>78.310345</td>\n","      <td>20</td>\n","      <td>175</td>\n","      <td>143</td>\n","      <td>52</td>\n","      <td>52.00</td>\n","      <td>67.0</td>\n","      <td>105.00</td>\n","      <td>2271</td>\n","      <td>ffbef7e5</td>\n","    </tr>\n","    <tr>\n","      <th>2468</th>\n","      <td>4</td>\n","      <td>277.000000</td>\n","      <td>200</td>\n","      <td>359</td>\n","      <td>223</td>\n","      <td>359</td>\n","      <td>217.25</td>\n","      <td>274.5</td>\n","      <td>334.25</td>\n","      <td>1108</td>\n","      <td>ffccd6fd</td>\n","    </tr>\n","    <tr>\n","      <th>2469</th>\n","      <td>27</td>\n","      <td>92.592593</td>\n","      <td>36</td>\n","      <td>176</td>\n","      <td>79</td>\n","      <td>94</td>\n","      <td>63.00</td>\n","      <td>98.0</td>\n","      <td>105.50</td>\n","      <td>2500</td>\n","      <td>ffec5b38</td>\n","    </tr>\n","    <tr>\n","      <th>2470</th>\n","      <td>11</td>\n","      <td>133.272727</td>\n","      <td>56</td>\n","      <td>411</td>\n","      <td>57</td>\n","      <td>223</td>\n","      <td>69.00</td>\n","      <td>95.0</td>\n","      <td>145.00</td>\n","      <td>1466</td>\n","      <td>fff05981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2471 rows × 11 columns</p>\n","</div>"],"text/plain":["      sent_count  sent_len_mean  sent_len_min  sent_len_max  sent_len_first  \\\n","0             14     106.142857            31           196              31   \n","1             15     107.666667            19           226              19   \n","2             19     133.842105            73           189             139   \n","3             13      86.846154            39           144              99   \n","4             16      86.812500            22           182              75   \n","...          ...            ...           ...           ...             ...   \n","2466          13     121.076923            55           180              79   \n","2467          29      78.310345            20           175             143   \n","2468           4     277.000000           200           359             223   \n","2469          27      92.592593            36           176              79   \n","2470          11     133.272727            56           411              57   \n","\n","      sent_len_last  sent_len_q1  sent_len_median  sent_len_q3  sent_len_sum  \\\n","0                89        75.50            119.5       126.00          1486   \n","1               143        56.50             92.0       149.50          1615   \n","2               161       108.00            139.0       161.00          2543   \n","3                80        62.00             80.0        99.00          1129   \n","4                22        60.00             74.0       106.25          1389   \n","...             ...          ...              ...          ...           ...   \n","2466            109        84.00            132.0       147.00          1574   \n","2467             52        52.00             67.0       105.00          2271   \n","2468            359       217.25            274.5       334.25          1108   \n","2469             94        63.00             98.0       105.50          2500   \n","2470            223        69.00             95.0       145.00          1466   \n","\n","            id  \n","0     001519c8  \n","1     0022f953  \n","2     0042269b  \n","3     0059420b  \n","4     0075873a  \n","...        ...  \n","2466  ffb8c745  \n","2467  ffbef7e5  \n","2468  ffccd6fd  \n","2469  ffec5b38  \n","2470  fff05981  \n","\n","[2471 rows x 11 columns]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["essay_sent_length(train_essays)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent_word_count_mean</th>\n","      <th>sent_word_count_max</th>\n","      <th>sent_word_count_first</th>\n","      <th>sent_word_count_q1</th>\n","      <th>sent_word_count_median</th>\n","      <th>sent_word_count_q3</th>\n","      <th>sent_word_count_sum</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.133333</td>\n","      <td>29</td>\n","      <td>6</td>\n","      <td>11.00</td>\n","      <td>21.0</td>\n","      <td>22.00</td>\n","      <td>257</td>\n","      <td>001519c8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.375000</td>\n","      <td>45</td>\n","      <td>3</td>\n","      <td>10.50</td>\n","      <td>18.5</td>\n","      <td>30.50</td>\n","      <td>326</td>\n","      <td>0022f953</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20.450000</td>\n","      <td>29</td>\n","      <td>21</td>\n","      <td>17.00</td>\n","      <td>21.0</td>\n","      <td>26.25</td>\n","      <td>409</td>\n","      <td>0042269b</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14.928571</td>\n","      <td>27</td>\n","      <td>17</td>\n","      <td>11.00</td>\n","      <td>14.5</td>\n","      <td>17.75</td>\n","      <td>209</td>\n","      <td>0059420b</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>15.058824</td>\n","      <td>35</td>\n","      <td>11</td>\n","      <td>11.00</td>\n","      <td>12.0</td>\n","      <td>18.00</td>\n","      <td>256</td>\n","      <td>0075873a</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2466</th>\n","      <td>19.571429</td>\n","      <td>33</td>\n","      <td>16</td>\n","      <td>15.25</td>\n","      <td>22.5</td>\n","      <td>24.00</td>\n","      <td>274</td>\n","      <td>ffb8c745</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>14.800000</td>\n","      <td>33</td>\n","      <td>27</td>\n","      <td>9.25</td>\n","      <td>13.0</td>\n","      <td>19.00</td>\n","      <td>444</td>\n","      <td>ffbef7e5</td>\n","    </tr>\n","    <tr>\n","      <th>2468</th>\n","      <td>41.000000</td>\n","      <td>61</td>\n","      <td>42</td>\n","      <td>41.00</td>\n","      <td>42.0</td>\n","      <td>60.00</td>\n","      <td>205</td>\n","      <td>ffccd6fd</td>\n","    </tr>\n","    <tr>\n","      <th>2469</th>\n","      <td>14.964286</td>\n","      <td>29</td>\n","      <td>11</td>\n","      <td>10.75</td>\n","      <td>14.5</td>\n","      <td>18.25</td>\n","      <td>419</td>\n","      <td>ffec5b38</td>\n","    </tr>\n","    <tr>\n","      <th>2470</th>\n","      <td>20.416667</td>\n","      <td>66</td>\n","      <td>9</td>\n","      <td>10.50</td>\n","      <td>16.0</td>\n","      <td>24.25</td>\n","      <td>245</td>\n","      <td>fff05981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2471 rows × 8 columns</p>\n","</div>"],"text/plain":["      sent_word_count_mean  sent_word_count_max  sent_word_count_first  \\\n","0                17.133333                   29                      6   \n","1                20.375000                   45                      3   \n","2                20.450000                   29                     21   \n","3                14.928571                   27                     17   \n","4                15.058824                   35                     11   \n","...                    ...                  ...                    ...   \n","2466             19.571429                   33                     16   \n","2467             14.800000                   33                     27   \n","2468             41.000000                   61                     42   \n","2469             14.964286                   29                     11   \n","2470             20.416667                   66                      9   \n","\n","      sent_word_count_q1  sent_word_count_median  sent_word_count_q3  \\\n","0                  11.00                    21.0               22.00   \n","1                  10.50                    18.5               30.50   \n","2                  17.00                    21.0               26.25   \n","3                  11.00                    14.5               17.75   \n","4                  11.00                    12.0               18.00   \n","...                  ...                     ...                 ...   \n","2466               15.25                    22.5               24.00   \n","2467                9.25                    13.0               19.00   \n","2468               41.00                    42.0               60.00   \n","2469               10.75                    14.5               18.25   \n","2470               10.50                    16.0               24.25   \n","\n","      sent_word_count_sum        id  \n","0                     257  001519c8  \n","1                     326  0022f953  \n","2                     409  0042269b  \n","3                     209  0059420b  \n","4                     256  0075873a  \n","...                   ...       ...  \n","2466                  274  ffb8c745  \n","2467                  444  ffbef7e5  \n","2468                  205  ffccd6fd  \n","2469                  419  ffec5b38  \n","2470                  245  fff05981  \n","\n","[2471 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["train_essays = get_essay_df(train_logs.collect().to_pandas())\n","essay_sent_words(train_essays)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting round 0 of training feats\n","Training... train_categorical_nunique.pkl\n","Training... train_essay_sentences.pkl\n","Training... train_r_burst_feats.pkl\n","Training... train_action_time_by_activity.pkl\n","Training... train_word_count_time_based.pkl\n","Training... train_word_pauses.pkl\n","Training... train_cursor_pos_acceleration.pkl\n","Training... train_word_counts_rate_of_change.pkl\n","Training... train_create_pauses.pkl\n","Training... train_get_keys_pressed_per_second.pkl\n","Training... train_input_text_change_feats.pkl\n","Training... train_events_counts_acceleration.pkl\n","Training... train_sentence_pauses.pkl\n","Training... train_events_counts_rate_of_change.pkl\n","Training... train_p_burst_feats.pkl\n","Training... train_count_of_activities.pkl\n","Training... train_events_counts_baseline.pkl\n","Training... train_paragraph_pauses.pkl\n","Training... train_action_time_baseline_stats.pkl\n","Training... train_cursor_pos_time_based.pkl\n","Training... train_essay_words.pkl\n","Training... train_word_count_acceleration.pkl\n","Training... train_cursor_pos_rate_of_change.pkl\n","Training... train_vector_two_gram.pkl\n","Training... train_events_counts_time_based.pkl\n","Training... train_essay_paragraphs.pkl\n","Training... train_vector_one_gram.pkl\n","Training... train_product_to_keys.pkl\n","Results improved!: Selected feat train_essay_sentences.pkl - score 0.6617879649782765\n","list_train_feats: ['train_categorical_nunique.pkl', 'train_r_burst_feats.pkl', 'train_action_time_by_activity.pkl', 'train_word_count_time_based.pkl', 'train_word_pauses.pkl', 'train_cursor_pos_acceleration.pkl', 'train_word_counts_rate_of_change.pkl', 'train_create_pauses.pkl', 'train_get_keys_pressed_per_second.pkl', 'train_input_text_change_feats.pkl', 'train_events_counts_acceleration.pkl', 'train_sentence_pauses.pkl', 'train_events_counts_rate_of_change.pkl', 'train_p_burst_feats.pkl', 'train_count_of_activities.pkl', 'train_events_counts_baseline.pkl', 'train_paragraph_pauses.pkl', 'train_action_time_baseline_stats.pkl', 'train_cursor_pos_time_based.pkl', 'train_essay_words.pkl', 'train_word_count_acceleration.pkl', 'train_cursor_pos_rate_of_change.pkl', 'train_vector_two_gram.pkl', 'train_events_counts_time_based.pkl', 'train_essay_paragraphs.pkl', 'train_vector_one_gram.pkl', 'train_product_to_keys.pkl']\n","added_feats_list: ['train_essay_sentences.pkl']\n","best feat: train_essay_sentences.pkl\n","Starting round 1 of training feats\n","Training... train_categorical_nunique.pkl\n","Training... train_r_burst_feats.pkl\n","Training... train_action_time_by_activity.pkl\n","Training... train_word_count_time_based.pkl\n","Training... train_word_pauses.pkl\n","Training... train_cursor_pos_acceleration.pkl\n","Training... train_word_counts_rate_of_change.pkl\n","Training... train_create_pauses.pkl\n","Training... train_get_keys_pressed_per_second.pkl\n","Training... train_input_text_change_feats.pkl\n","Training... train_events_counts_acceleration.pkl\n","Training... train_sentence_pauses.pkl\n","Training... train_events_counts_rate_of_change.pkl\n","Training... train_p_burst_feats.pkl\n","Training... train_count_of_activities.pkl\n","Training... train_events_counts_baseline.pkl\n","Training... train_paragraph_pauses.pkl\n","Training... train_action_time_baseline_stats.pkl\n","Training... train_cursor_pos_time_based.pkl\n","Training... train_essay_words.pkl\n","Training... train_word_count_acceleration.pkl\n","Training... train_cursor_pos_rate_of_change.pkl\n","Training... train_vector_two_gram.pkl\n","Training... train_events_counts_time_based.pkl\n","Training... train_essay_paragraphs.pkl\n","Training... train_vector_one_gram.pkl\n","Training... train_product_to_keys.pkl\n","Results improved!: Selected feat train_create_pauses.pkl - score 0.6423756335232275\n","list_train_feats: ['train_categorical_nunique.pkl', 'train_r_burst_feats.pkl', 'train_action_time_by_activity.pkl', 'train_word_count_time_based.pkl', 'train_word_pauses.pkl', 'train_cursor_pos_acceleration.pkl', 'train_word_counts_rate_of_change.pkl', 'train_get_keys_pressed_per_second.pkl', 'train_input_text_change_feats.pkl', 'train_events_counts_acceleration.pkl', 'train_sentence_pauses.pkl', 'train_events_counts_rate_of_change.pkl', 'train_p_burst_feats.pkl', 'train_count_of_activities.pkl', 'train_events_counts_baseline.pkl', 'train_paragraph_pauses.pkl', 'train_action_time_baseline_stats.pkl', 'train_cursor_pos_time_based.pkl', 'train_essay_words.pkl', 'train_word_count_acceleration.pkl', 'train_cursor_pos_rate_of_change.pkl', 'train_vector_two_gram.pkl', 'train_events_counts_time_based.pkl', 'train_essay_paragraphs.pkl', 'train_vector_one_gram.pkl', 'train_product_to_keys.pkl']\n","added_feats_list: ['train_essay_sentences.pkl', 'train_create_pauses.pkl']\n","best feat: train_create_pauses.pkl\n","Starting round 2 of training feats\n","Training... train_categorical_nunique.pkl\n","Training... train_r_burst_feats.pkl\n","Training... train_action_time_by_activity.pkl\n","Training... train_word_count_time_based.pkl\n","Training... train_word_pauses.pkl\n","Training... train_cursor_pos_acceleration.pkl\n","Training... train_word_counts_rate_of_change.pkl\n","Training... train_get_keys_pressed_per_second.pkl\n","Training... train_input_text_change_feats.pkl\n","Training... train_events_counts_acceleration.pkl\n","Training... train_sentence_pauses.pkl\n","Training... train_events_counts_rate_of_change.pkl\n","Training... train_p_burst_feats.pkl\n","Training... train_count_of_activities.pkl\n","Training... train_events_counts_baseline.pkl\n","Training... train_paragraph_pauses.pkl\n","Training... train_action_time_baseline_stats.pkl\n","Training... train_cursor_pos_time_based.pkl\n","Training... train_essay_words.pkl\n","Training... train_word_count_acceleration.pkl\n","Training... train_cursor_pos_rate_of_change.pkl\n","Training... train_vector_two_gram.pkl\n","Training... train_events_counts_time_based.pkl\n","Training... train_essay_paragraphs.pkl\n","Training... train_vector_one_gram.pkl\n","Training... train_product_to_keys.pkl\n","Results improved!: Selected feat train_vector_one_gram.pkl - score 0.6302350991406214\n","list_train_feats: ['train_categorical_nunique.pkl', 'train_r_burst_feats.pkl', 'train_action_time_by_activity.pkl', 'train_word_count_time_based.pkl', 'train_word_pauses.pkl', 'train_cursor_pos_acceleration.pkl', 'train_word_counts_rate_of_change.pkl', 'train_get_keys_pressed_per_second.pkl', 'train_input_text_change_feats.pkl', 'train_events_counts_acceleration.pkl', 'train_sentence_pauses.pkl', 'train_events_counts_rate_of_change.pkl', 'train_p_burst_feats.pkl', 'train_count_of_activities.pkl', 'train_events_counts_baseline.pkl', 'train_paragraph_pauses.pkl', 'train_action_time_baseline_stats.pkl', 'train_cursor_pos_time_based.pkl', 'train_essay_words.pkl', 'train_word_count_acceleration.pkl', 'train_cursor_pos_rate_of_change.pkl', 'train_vector_two_gram.pkl', 'train_events_counts_time_based.pkl', 'train_essay_paragraphs.pkl', 'train_product_to_keys.pkl']\n","added_feats_list: ['train_essay_sentences.pkl', 'train_create_pauses.pkl', 'train_vector_one_gram.pkl']\n","best feat: train_vector_one_gram.pkl\n","Starting round 3 of training feats\n","Training... train_categorical_nunique.pkl\n","Training... train_r_burst_feats.pkl\n","Training... train_action_time_by_activity.pkl\n","Training... train_word_count_time_based.pkl\n","Training... train_word_pauses.pkl\n","Training... train_cursor_pos_acceleration.pkl\n","Training... train_word_counts_rate_of_change.pkl\n","Training... train_get_keys_pressed_per_second.pkl\n","Training... train_input_text_change_feats.pkl\n","Training... train_events_counts_acceleration.pkl\n","Training... train_sentence_pauses.pkl\n","Training... train_events_counts_rate_of_change.pkl\n","Training... train_p_burst_feats.pkl\n","Training... train_count_of_activities.pkl\n","Training... train_events_counts_baseline.pkl\n","Training... train_paragraph_pauses.pkl\n","Training... train_action_time_baseline_stats.pkl\n","Training... train_cursor_pos_time_based.pkl\n","Training... train_essay_words.pkl\n","Training... train_word_count_acceleration.pkl\n","Training... train_cursor_pos_rate_of_change.pkl\n","Training... train_vector_two_gram.pkl\n","Training... train_events_counts_time_based.pkl\n","Training... train_essay_paragraphs.pkl\n","Training... train_product_to_keys.pkl\n","Results improved!: Selected feat train_essay_paragraphs.pkl - score 0.6213365659951283\n","list_train_feats: ['train_categorical_nunique.pkl', 'train_r_burst_feats.pkl', 'train_action_time_by_activity.pkl', 'train_word_count_time_based.pkl', 'train_word_pauses.pkl', 'train_cursor_pos_acceleration.pkl', 'train_word_counts_rate_of_change.pkl', 'train_get_keys_pressed_per_second.pkl', 'train_input_text_change_feats.pkl', 'train_events_counts_acceleration.pkl', 'train_sentence_pauses.pkl', 'train_events_counts_rate_of_change.pkl', 'train_p_burst_feats.pkl', 'train_count_of_activities.pkl', 'train_events_counts_baseline.pkl', 'train_paragraph_pauses.pkl', 'train_action_time_baseline_stats.pkl', 'train_cursor_pos_time_based.pkl', 'train_essay_words.pkl', 'train_word_count_acceleration.pkl', 'train_cursor_pos_rate_of_change.pkl', 'train_vector_two_gram.pkl', 'train_events_counts_time_based.pkl', 'train_product_to_keys.pkl']\n","added_feats_list: ['train_essay_sentences.pkl', 'train_create_pauses.pkl', 'train_vector_one_gram.pkl', 'train_essay_paragraphs.pkl']\n","best feat: train_essay_paragraphs.pkl\n","Starting round 4 of training feats\n","Training... train_categorical_nunique.pkl\n","Training... train_r_burst_feats.pkl\n","Training... train_action_time_by_activity.pkl\n","Training... train_word_count_time_based.pkl\n","Training... train_word_pauses.pkl\n","Training... train_cursor_pos_acceleration.pkl\n","Training... train_word_counts_rate_of_change.pkl\n","Training... train_get_keys_pressed_per_second.pkl\n","Training... train_input_text_change_feats.pkl\n","Training... train_events_counts_acceleration.pkl\n","Training... train_sentence_pauses.pkl\n","Training... train_events_counts_rate_of_change.pkl\n","Training... train_p_burst_feats.pkl\n","Training... train_count_of_activities.pkl\n","Training... train_events_counts_baseline.pkl\n","Training... train_paragraph_pauses.pkl\n","Training... train_action_time_baseline_stats.pkl\n","Training... train_cursor_pos_time_based.pkl\n","Training... train_essay_words.pkl\n","Training... train_word_count_acceleration.pkl\n","Training... train_cursor_pos_rate_of_change.pkl\n","Training... train_vector_two_gram.pkl\n","Training... train_events_counts_time_based.pkl\n","Training... train_product_to_keys.pkl\n","Results improved!: Selected feat train_categorical_nunique.pkl - score 0.6166507670453621\n","list_train_feats: ['train_r_burst_feats.pkl', 'train_action_time_by_activity.pkl', 'train_word_count_time_based.pkl', 'train_word_pauses.pkl', 'train_cursor_pos_acceleration.pkl', 'train_word_counts_rate_of_change.pkl', 'train_get_keys_pressed_per_second.pkl', 'train_input_text_change_feats.pkl', 'train_events_counts_acceleration.pkl', 'train_sentence_pauses.pkl', 'train_events_counts_rate_of_change.pkl', 'train_p_burst_feats.pkl', 'train_count_of_activities.pkl', 'train_events_counts_baseline.pkl', 'train_paragraph_pauses.pkl', 'train_action_time_baseline_stats.pkl', 'train_cursor_pos_time_based.pkl', 'train_essay_words.pkl', 'train_word_count_acceleration.pkl', 'train_cursor_pos_rate_of_change.pkl', 'train_vector_two_gram.pkl', 'train_events_counts_time_based.pkl', 'train_product_to_keys.pkl']\n","added_feats_list: ['train_essay_sentences.pkl', 'train_create_pauses.pkl', 'train_vector_one_gram.pkl', 'train_essay_paragraphs.pkl', 'train_categorical_nunique.pkl']\n","best feat: train_categorical_nunique.pkl\n","Starting round 5 of training feats\n","Training... train_r_burst_feats.pkl\n","Training... train_action_time_by_activity.pkl\n","Training... train_word_count_time_based.pkl\n","Training... train_word_pauses.pkl\n","Training... train_cursor_pos_acceleration.pkl\n","Training... train_word_counts_rate_of_change.pkl\n","Training... train_get_keys_pressed_per_second.pkl\n","Training... train_input_text_change_feats.pkl\n","Training... train_events_counts_acceleration.pkl\n","Training... train_sentence_pauses.pkl\n","Training... train_events_counts_rate_of_change.pkl\n","Training... train_p_burst_feats.pkl\n"]}],"source":["best_feats = []\n","\n","train_feats, test_feats = pd.DataFrame(), pd.DataFrame()\n","best_rmse = float('inf')\n","round = 0\n","added_feats = []\n","improved = True\n","results = pd.DataFrame()\n","train_feats = train_feats.sample(frac=1).reset_index(drop=True)\n","list_train_feats = [feat for feat in feat_list if feat.startswith('train_')]\n","\n","while improved:\n","    print(f'Starting round {round} of training feats')\n","    improved = False\n","    list_train_feats = [feat for feat in list_train_feats if feat not in added_feats]\n","\n","    for tr_feats_cand in list_train_feats:\n","        ts_feats_cand = tr_feats_cand.replace('train', 'test')\n","\n","        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{tr_feats_cand}')\n","        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_feats_cand}')\n","\n","        existing_train_columns = set(train_feats.columns)\n","        existing_test_columns = set(test_feats.columns)\n","\n","        if not(train_feats.empty & test_feats.empty):\n","\n","            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n","            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n","\n","            if 'score' not in train_feats.columns:\n","                train_feats = train_feats.merge(train_scores, on='id', how='left')\n","                \n","            assert train_feats.shape[1] == test_feats.shape[1] + 1\n","        else:\n","            #print(f'feats empty - setting up train_feats')\n","            train_feats = tr_feats\n","            test_feats = ts_feats\n","            train_feats = train_feats.merge(train_scores, on='id', how='left')\n","\n","        print(f'Training... {tr_feats_cand}')\n","        # print(f'Train feats cols {train_feats.columns}')\n","        tr_cols = tr_feats.drop(columns=['id']).columns\n","        ts_cols = ts_feats.drop(columns=['id']).columns\n","        train_feats = train_feats.sample(frac=1).reset_index(drop=True)\n","        mean_rmse = []\n","\n","        for i in range(15):\n","            train_feats = train_feats.sample(frac=1).reset_index(drop=True)\n","            test_preds, valid_preds, final_rmse, cv_rm = lgb_pipeline(train_feats, test_feats, param)\n","            mean_rmse.append(final_rmse)\n","\n","        temp_res = {'feat_name': tr_feats_cand, 'RMSE': np.mean(mean_rmse)}\n","        results = pd.concat([results, pd.DataFrame([temp_res])])\n","\n","        train_feats.drop(columns=tr_cols, inplace=True)\n","        test_feats.drop(columns=ts_cols, inplace=True)\n","\n","    results = results.sort_values('RMSE', ascending=True)\n","    top_score = results.head(1).RMSE.values[0]\n","    top_feat = results.head(1).feat_name.values[0]\n","\n","    if top_score < best_rmse:\n","        best_rmse = top_score\n","        best_feat = top_feat\n","        improved = True\n","        print(f'Results improved!: Selected feat {top_feat} - score {top_score}')\n","\n","        ts_top_feat = top_feat.replace('train', 'test')\n","        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{top_feat}')\n","        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_top_feat}')\n","\n","        if round > 0:\n","            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n","            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n","        else:\n","            train_feats = tr_feats\n","            test_feats = ts_feats\n","\n","        added_feats.append(top_feat)\n","        round += 1\n","    else:\n","        print('Training Over!')\n","\n","    list_train_feats = [feat for feat in list_train_feats if feat not in added_feats]\n","    print(f'list_train_feats: {list_train_feats}')\n","    print(f'added_feats_list: {added_feats}')\n","    print(f'best feat: {top_feat}')\n","\n","print(f\"Best RMSE: {best_rmse:.4f}\")\n","print(f\"Best Feature Set: {added_feats}\")\n","best_feats.append(added_feats)\n","added_feats = []"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent_word_count_mean</th>\n","      <th>sent_word_count_max</th>\n","      <th>sent_word_count_first</th>\n","      <th>sent_word_count_q1</th>\n","      <th>sent_word_count_median</th>\n","      <th>sent_word_count_q3</th>\n","      <th>sent_word_count_sum</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.133333</td>\n","      <td>29</td>\n","      <td>6</td>\n","      <td>11.00</td>\n","      <td>21.0</td>\n","      <td>22.00</td>\n","      <td>257</td>\n","      <td>001519c8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.375000</td>\n","      <td>45</td>\n","      <td>3</td>\n","      <td>10.50</td>\n","      <td>18.5</td>\n","      <td>30.50</td>\n","      <td>326</td>\n","      <td>0022f953</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20.450000</td>\n","      <td>29</td>\n","      <td>21</td>\n","      <td>17.00</td>\n","      <td>21.0</td>\n","      <td>26.25</td>\n","      <td>409</td>\n","      <td>0042269b</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14.928571</td>\n","      <td>27</td>\n","      <td>17</td>\n","      <td>11.00</td>\n","      <td>14.5</td>\n","      <td>17.75</td>\n","      <td>209</td>\n","      <td>0059420b</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>15.058824</td>\n","      <td>35</td>\n","      <td>11</td>\n","      <td>11.00</td>\n","      <td>12.0</td>\n","      <td>18.00</td>\n","      <td>256</td>\n","      <td>0075873a</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2466</th>\n","      <td>19.571429</td>\n","      <td>33</td>\n","      <td>16</td>\n","      <td>15.25</td>\n","      <td>22.5</td>\n","      <td>24.00</td>\n","      <td>274</td>\n","      <td>ffb8c745</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>14.800000</td>\n","      <td>33</td>\n","      <td>27</td>\n","      <td>9.25</td>\n","      <td>13.0</td>\n","      <td>19.00</td>\n","      <td>444</td>\n","      <td>ffbef7e5</td>\n","    </tr>\n","    <tr>\n","      <th>2468</th>\n","      <td>41.000000</td>\n","      <td>61</td>\n","      <td>42</td>\n","      <td>41.00</td>\n","      <td>42.0</td>\n","      <td>60.00</td>\n","      <td>205</td>\n","      <td>ffccd6fd</td>\n","    </tr>\n","    <tr>\n","      <th>2469</th>\n","      <td>14.964286</td>\n","      <td>29</td>\n","      <td>11</td>\n","      <td>10.75</td>\n","      <td>14.5</td>\n","      <td>18.25</td>\n","      <td>419</td>\n","      <td>ffec5b38</td>\n","    </tr>\n","    <tr>\n","      <th>2470</th>\n","      <td>20.416667</td>\n","      <td>66</td>\n","      <td>9</td>\n","      <td>10.50</td>\n","      <td>16.0</td>\n","      <td>24.25</td>\n","      <td>245</td>\n","      <td>fff05981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2471 rows × 8 columns</p>\n","</div>"],"text/plain":["      sent_word_count_mean  sent_word_count_max  sent_word_count_first  \\\n","0                17.133333                   29                      6   \n","1                20.375000                   45                      3   \n","2                20.450000                   29                     21   \n","3                14.928571                   27                     17   \n","4                15.058824                   35                     11   \n","...                    ...                  ...                    ...   \n","2466             19.571429                   33                     16   \n","2467             14.800000                   33                     27   \n","2468             41.000000                   61                     42   \n","2469             14.964286                   29                     11   \n","2470             20.416667                   66                      9   \n","\n","      sent_word_count_q1  sent_word_count_median  sent_word_count_q3  \\\n","0                  11.00                    21.0               22.00   \n","1                  10.50                    18.5               30.50   \n","2                  17.00                    21.0               26.25   \n","3                  11.00                    14.5               17.75   \n","4                  11.00                    12.0               18.00   \n","...                  ...                     ...                 ...   \n","2466               15.25                    22.5               24.00   \n","2467                9.25                    13.0               19.00   \n","2468               41.00                    42.0               60.00   \n","2469               10.75                    14.5               18.25   \n","2470               10.50                    16.0               24.25   \n","\n","      sent_word_count_sum        id  \n","0                     257  001519c8  \n","1                     326  0022f953  \n","2                     409  0042269b  \n","3                     209  0059420b  \n","4                     256  0075873a  \n","...                   ...       ...  \n","2466                  274  ffb8c745  \n","2467                  444  ffbef7e5  \n","2468                  205  ffccd6fd  \n","2469                  419  ffec5b38  \n","2470                  245  fff05981  \n","\n","[2471 rows x 8 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["sent_agg_df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["1      2385\n","2         7\n","5         7\n","10        5\n","3         5\n","15        5\n","9         4\n","7         4\n","4         4\n","27        3\n","22        3\n","12        3\n","21        3\n","39        2\n","8         2\n","6         2\n","17        2\n","26        2\n","40        1\n","91        1\n","153       1\n","138       1\n","75        1\n","18        1\n","28        1\n","37        1\n","32        1\n","23        1\n","14        1\n","13        1\n","46        1\n","44        1\n","29        1\n","52        1\n","107       1\n","34        1\n","24        1\n","25        1\n","33        1\n","42        1\n","31        1\n","Name: sent_word_count_last, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["sent_agg_df.sent_word_count_last.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sent_feats(df):\n","    print(\"< Essays sentences feats >\")    \n","    df['sent'] = df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n","    df = df.explode('sent')\n","    df['sent'] = df['sent'].apply(lambda x: x.replace('\\n','').strip())\n","    # Number of characters in sentences\n","    df['sent_len'] = df['sent'].apply(lambda x: len(x))\n","    # Number of words in sentences\n","    df['sent_word_count'] = df['sent'].apply(lambda x: len(x.split(' ')))\n","    df = df[df.sent_len!=0].reset_index(drop=True)\n","\n","    sent_agg_df = pd.concat([df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), \n","                             df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1)\n","    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n","    sent_agg_df['id'] = sent_agg_df.index\n","    sent_agg_df = sent_agg_df.reset_index(drop=True)\n","    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n","    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n","    return sent_agg_df\n","\n","\n","def parag_feats(df):\n","    print(\"< Essays paragraphs feats >\")    \n","    df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n","    df = df.explode('paragraph')\n","    # Number of characters in paragraphs\n","    df['paragraph_len'] = df['paragraph'].apply(lambda x: len(x)) \n","    # Number of words in paragraphs\n","    df['paragraph_word_count'] = df['paragraph'].apply(lambda x: len(x.split(' ')))\n","    df = df[df.paragraph_len!=0].reset_index(drop=True)\n","    \n","    paragraph_agg_df = pd.concat([df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), \n","                                  df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1) \n","    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n","    paragraph_agg_df['id'] = paragraph_agg_df.index\n","    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n","    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n","    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n","    return paragraph_agg_df"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# everything is logged - DONE\n","# bursts = 2/3 of a second - input only - DONE\n","# inter word pauses\n","# between sentence pauses ?\n","# between paragraph pauses ?\n","# backspace pauses\n","# edit pauses"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# # TEST INDIVIDUAL FEATURES\n","# from m3_model_params import lgb_params_1\n","# tr_word_pause, ts_word_pause = word_pauses(train_logs, test_logs)\n","# train_feats = tr_word_pause.join(train_scores, on='id', how='left')\n","# test_feats = ts_word_pause.clone()\n","\n","# train_feats = train_feats.collect().to_pandas()\n","# test_feats = test_feats.collect().to_pandas()\n","# test_preds, valid_preds, final_rmse, cv_rm = lgb_pipeline(train_feats, test_feats, lgb_params_1)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# [('train_down_events_counts.pkl', 26),\n","#  ('train_vector_one_gram.pkl', 26),\n","#  ('train_create_pauses.pkl', 26),\n","#  ('train_essay_paragraphs.pkl', 26),\n","#  ('train_cursor_pos_acceleration.pkl', 11),\n","#  ('train_word_count_acceleration.pkl', 6),\n","#  ('train_p_burst_feats.pkl', 5),\n","#  ('train_r_burst_feats.pkl', 3),\n","#  ('train_events_counts_acceleration.pkl', 3),\n","#  ('train_essay_sentences.pkl', 3),\n","#  ('train_categorical_nunique.pkl', 3),\n","#  ('train_vector_two_gram.pkl', 2),\n","#  ('train_cursor_pos_rate_of_change.pkl', 2),\n","#  ('train_word_counts_rate_of_change.pkl', 2),\n","#  ('train_count_of_activities.pkl', 2),\n","#  ('train_action_time_by_activity.pkl', 1),\n","#  ('train_product_to_keys.pkl', 1),\n","#  ('train_IKI_based_fractals.pkl', 1),\n","#  ('train_events_counts_baseline.pkl', 1)]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< Events counts features >\n","< Count vectorize one-grams >\n","< Idle time features >\n","< cursor position acceleration >\n","word pauses\n","< word count acceleration >\n","< R-burst features >\n","< Count vectorize bi-grams >\n","< Essays paragraphs feats >\n","< Essays paragraphs feats >\n","< Essays sentences feats >\n","< Essays sentences feats >\n","train feats shape (2471, 144)\n"]}],"source":["# best_feature_set_1 - PARTIAL\n","train_essays          = get_essay_df(train_logs.collect().to_pandas())\n","test_essays           = get_essay_df(test_logs.collect().to_pandas())\n","\n","tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n","tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n","tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n","tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n","tr_word_pause, ts_word_pause = word_pauses(train_logs, test_logs)\n","tr_word_count_acc, ts_word_count_acc = word_count_acceleration(train_logs, test_logs)\n","#tr_p_burst, ts_p_burst = p_burst_feats(train_logs, test_logs, 2)\n","tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n","#tr_event_acc, ts_event_acc = events_counts_acceleration(train_logs, test_logs)\n","# tr_nunique, ts_nunique = categorical_nunique(train_logs, test_logs)\n","tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n","# tr_time_by_act, ts_time_by_act = action_time_by_activity(train_logs, test_logs)\n","# tr_cursor_pos_roc, ts_cursor_pos_roc = cursor_pos_rate_of_change(train_logs, test_logs)\n","# \n","# tr_act_count, ts_act_count = count_of_activities(train_logs, test_logs)\n","# tr_get_keys, ts_get_keys = get_keys_pressed_per_second(train_logs.collect().to_pandas(), \n","#                                                        test_logs.collect().to_pandas())\n","# \n","# tr_input_change, ts_input_change = input_text_change_feats(train_logs, test_logs)\n","# tr_wc_roc, ts_wc_roc =  word_counts_rate_of_change(train_logs, test_logs)\n","\n","train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n","train_feats = train_feats.join(tr_pauses, on='id', how='left')\n","train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_word_pause, on='id', how='left')\n","train_feats = train_feats.join(tr_word_count_acc, on='id', how='left')\n","#train_feats = train_feats.join(tr_p_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n","# train_feats = train_feats.join(tr_event_acc, on='id', how='left')\n","# train_feats = train_feats.join(tr_nunique, on='id', how='left')\n","# train_feats = train_feats.join(tr_wc_roc, on='id', how='left')\n","# train_feats = train_feats.join(tr_act_count, on='id', how='left')\n","# train_feats = train_feats.join(tr_cursor_pos_roc, on='id', how='left')\n","\n","# train_feats = train_feats.join(tr_get_keys, on='id', how='left')\n","# train_feats = train_feats.join(tr_input_change, on='id', how='left')\n","# train_feats = train_feats.join(tr_time_by_act, on='id', how='left')\n","\n","test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n","test_feats = test_feats.join(ts_pauses, on='id', how='left')\n","test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_word_pause, on='id', how='left')\n","test_feats = test_feats.join(ts_word_count_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_p_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n","# test_feats = test_feats.join(tr_event_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_nunique, on='id', how='left')\n","# test_feats = test_feats.join(ts_wc_roc, on='id', how='left')\n","# test_feats = test_feats.join(ts_act_count, on='id', how='left')\n","# test_feats = test_feats.join(ts_cursor_pos_roc, on='id', how='left')\n","\n","\n","# test_feats = test_feats.join(ts_get_keys, on='id', how='left')\n","# test_feats = test_feats.join(ts_input_change, on='id', how='left')\n","# test_feats = test_feats.join(ts_time_by_act, on='id', how='left')\n","\n","\n","train_logs = train_logs.collect().to_pandas()\n","test_logs = test_logs.collect().to_pandas()\n","train_scores = train_scores.collect().to_pandas()\n","train_feats = train_feats.sort('id')\n","train_feats = train_feats.collect().to_pandas()\n","test_feats = test_feats.collect().to_pandas()\n","\n","train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n","\n","train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n","\n","train_feats = train_feats.merge(train_scores, on='id', how='left')\n","print(f'train feats shape {train_feats.shape}')\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:21:44.320780Z","iopub.status.busy":"2023-12-18T16:21:44.320496Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train feats shape (2471, 144)\n"]}],"source":["from m5_sb_models import lgb_pipeline\n","lgb_params_1 = {\n","    'boosting_type': 'gbdt', \n","    'metric': 'rmse',\n","    'reg_alpha': 0.0031, \n","    'reg_lambda': 0.001, \n","    'colsample_bytree': 0.8,  \n","    'subsample_freq': 1,  \n","    'subsample': 0.75,  \n","    'learning_rate': 0.017, \n","    'num_leaves': 19, \n","    'min_child_samples': 46,\n","    'n_estimators': 350,\n","    'verbosity': -1\n","    }\n","\n","param = {'n_estimators': 1024,\n","        'learning_rate': 0.005,\n","        'metric': 'rmse',\n","        'force_col_wise': True,\n","        'verbosity': 0,}\n","\n","# train_feats = train_feats[['id', 'score'] + feat_select]\n","# test_feats = test_feats[['id'] + feat_select]\n","\n","print(f'train feats shape {train_feats.shape}')\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Final RMSE over 50: 0.603617. Std 0.8270\n","RMSE by fold 0.603563. Std 0.0083\n","Final RMSE over 50: 0.601545. Std 0.8255\n","RMSE by fold 0.601473. Std 0.0091\n","Final RMSE over 50: 0.602574. Std 0.8276\n","RMSE by fold 0.602372. Std 0.0151\n","Final RMSE over 50: 0.601950. Std 0.8275\n","RMSE by fold 0.601897. Std 0.0080\n","Final RMSE over 50: 0.604154. Std 0.8274\n","RMSE by fold 0.603977. Std 0.0149\n","Final RMSE over 50: 0.602163. Std 0.8266\n","RMSE by fold 0.602061. Std 0.0108\n","Final RMSE over 50: 0.603044. Std 0.8271\n","RMSE by fold 0.602868. Std 0.0148\n","Final RMSE over 50: 0.602455. Std 0.8275\n","RMSE by fold 0.602338. Std 0.0117\n","Final RMSE over 50: 0.602454. Std 0.8279\n","RMSE by fold 0.602405. Std 0.0079\n","Final RMSE over 50: 0.602837. Std 0.8266\n","RMSE by fold 0.602635. Std 0.0155\n","Final RMSE over 50: 0.602299. Std 0.8262\n","RMSE by fold 0.602235. Std 0.0083\n","Final RMSE over 50: 0.602076. Std 0.8286\n","RMSE by fold 0.601953. Std 0.0120\n","Final RMSE over 50: 0.602816. Std 0.8265\n","RMSE by fold 0.602714. Std 0.0110\n","Final RMSE over 50: 0.602905. Std 0.8268\n","RMSE by fold 0.602781. Std 0.0120\n","Final RMSE over 50: 0.603042. Std 0.8276\n","RMSE by fold 0.602884. Std 0.0137\n"]},{"data":{"text/plain":["0.6026620396931698"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["shuffle_preds = []\n","\n","for i in range(15):\n","    train_feats = train_feats.sample(frac=1).reset_index(drop=True)\n","    test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, lgb_params_1)\n","    shuffle_preds.append(rmse)\n","    #test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, param)\n","\n","np.mean(shuffle_preds)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#  0.6046250116470197 - baseline\n","#  0.6034392851713597 - word_pauses\n","#  0.6031532703206033 - word_count_acc\n","#  0.6030545803940613 - r_burst\n","#  0.60246384515886   - bigrams\n","# sentences"]},{"cell_type":"markdown","metadata":{},"source":["- M4 + cursor_pos_acc + word_count_acc + bigrams <br />\n","0.6044949502480581\n","\n","\n","- M4 + cursor_pos_acc + word_count_acc  <br />\n","0.6047963953877546 <br />\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","      <th>RMSE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.5</td>\n","      <td>1.528224</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.283878</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>6.0</td>\n","      <td>1.132529</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.5</td>\n","      <td>0.879977</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5.5</td>\n","      <td>0.738216</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>0.573584</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5.0</td>\n","      <td>0.474352</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.5</td>\n","      <td>0.461494</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3.0</td>\n","      <td>0.460465</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3.5</td>\n","      <td>0.402527</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.5</td>\n","      <td>0.355785</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4.0</td>\n","      <td>0.349586</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    score      RMSE\n","0     0.5  1.528224\n","1     1.0  1.283878\n","11    6.0  1.132529\n","2     1.5  0.879977\n","10    5.5  0.738216\n","3     2.0  0.573584\n","9     5.0  0.474352\n","4     2.5  0.461494\n","5     3.0  0.460465\n","6     3.5  0.402527\n","8     4.5  0.355785\n","7     4.0  0.349586"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["oof_res = oof_preds.groupby(['id', 'score'])['preds'].mean().reset_index()\n","# oof_res['rmse'] = oof_res.apply(lambda x: np.sqrt((x['score']-x['preds'])**2))\n","oof_res['RMSE'] = np.sqrt((oof_res['score']-oof_res['preds'])**2)\n","oof_res.groupby(['score'])['RMSE'].mean().reset_index().sort_values('RMSE', ascending=False)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","      <th>RMSE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.5</td>\n","      <td>1.528224</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.283878</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>6.0</td>\n","      <td>1.132529</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.5</td>\n","      <td>0.879977</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5.5</td>\n","      <td>0.738216</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>0.573584</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5.0</td>\n","      <td>0.474352</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.5</td>\n","      <td>0.461494</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3.0</td>\n","      <td>0.460465</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3.5</td>\n","      <td>0.402527</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.5</td>\n","      <td>0.355785</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4.0</td>\n","      <td>0.349586</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    score      RMSE\n","0     0.5  1.528224\n","1     1.0  1.283878\n","11    6.0  1.132529\n","2     1.5  0.879977\n","10    5.5  0.738216\n","3     2.0  0.573584\n","9     5.0  0.474352\n","4     2.5  0.461494\n","5     3.0  0.460465\n","6     3.5  0.402527\n","8     4.5  0.355785\n","7     4.0  0.349586"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["oof_res = oof_preds.groupby(['id', 'score'])['preds'].mean().reset_index()\n","oof_res['RMSE'] = np.sqrt((oof_res['score']-oof_res['preds'])**2)\n","oof_res.groupby(['score'])['RMSE'].mean().reset_index().sort_values('RMSE', ascending=False)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["oof_res = oof_preds.groupby(['id', 'score'])['preds'].mean().reset_index()\n","# oof_res['rmse'] = oof_res.apply(lambda x: np.sqrt((x['score']-x['preds'])**2))\n","oof_res['RMSE'] = np.sqrt((oof_res['score']-oof_res['preds'])**2)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'y' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlgb\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m weights \u001b[39m=\u001b[39m [\u001b[39m1.0\u001b[39m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y))]  \u001b[39m# Default weights\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m weights[some_specific_index] \u001b[39m=\u001b[39m \u001b[39m1.5\u001b[39m  \u001b[39m# Higher weight for a specific instance\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m train_data \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_train, label\u001b[39m=\u001b[39my_train, weight\u001b[39m=\u001b[39mweights)\n","\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"]}],"source":["import lightgbm as lgb\n","\n","weights = [1.0 for _ in range(len(y))]  # Default weights\n","weights[some_specific_index] = 1.5  # Higher weight for a specific instance\n","\n","train_data = lgb.Dataset(X_train, label=y_train, weight=weights)\n","# Proceed with setting up parameters and training the model\n"]},{"cell_type":"markdown","metadata":{},"source":["train feats shape (2471, 151)\n","Final RMSE over 50: 0.605768. Std 0.8244\n","RMSE by fold 0.605635. Std 0.0128\n","\n","reduced feats\n","Final RMSE over 50: 0.604472. Std 0.8245\n","RMSE by fold 0.604365. Std 0.0115\n","\n","r burst only\n","Number of estimators: 350\n","Final RMSE over 50: 0.604057. Std 0.8244\n","RMSE by fold 0.603946. Std 0.0116\n","\n","Number of estimators: 350\n","Final RMSE over 50: 0.604650. Std 0.8243\n","RMSE by fold 0.604527. Std 0.0122"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_ids = test_feats.id\n","y_pred = np.mean(test_preds, axis=0)\n","\n","sub = pd.DataFrame({'id': test_ids, 'score': y_pred})\n","sub.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6678907,"sourceId":59291,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
