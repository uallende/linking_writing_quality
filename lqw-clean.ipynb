{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-18T16:20:56.671429Z","iopub.status.busy":"2023-12-18T16:20:56.671017Z","iopub.status.idle":"2023-12-18T16:20:58.568632Z","shell.execute_reply":"2023-12-18T16:20:58.567768Z","shell.execute_reply.started":"2023-12-18T16:20:56.671393Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import polars as pl\n","\n","from m4_feats_polars import *\n","from m5_sb_models import *\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:20:58.587076Z","iopub.status.busy":"2023-12-18T16:20:58.586426Z","iopub.status.idle":"2023-12-18T16:20:58.601881Z","shell.execute_reply":"2023-12-18T16:20:58.600973Z","shell.execute_reply.started":"2023-12-18T16:20:58.587045Z"},"trusted":true},"outputs":[],"source":["# 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\n","data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n","train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n","test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n","train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')\n","\n","# train_logs, test_logs = amend_event_id_order(train_logs, test_logs)     worsens"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< added words pauses\n"]}],"source":["def added_word_pauses_basic(train_logs, test_logs):\n","    print(\"< added words pauses basic\")    \n","    feats = []\n","\n","    for data in [train_logs, test_logs]:\n","        logs = data.clone()\n","        logs = logs.with_columns(pl.col('word_count')\n","            .diff().over('id')\n","            .alias('word_diff'))\n","\n","        logs = logs.filter(\n","            pl.col('word_diff')>0).select(pl.col(['id','action_time']))\n","\n","        word_pause = logs.group_by(['id']).agg(\n","                        word_pause_count = pl.col('action_time').count(),\n","                        word_pause_mean = pl.col('action_time').mean(),\n","                        word_pause_sum = pl.col('action_time').sum(),\n","                        word_pause_std = pl.col('action_time').std(),\n","                        word_pause_median = pl.col('action_time').median(),\n","\n","        )\n","        feats.append(word_pause)\n","    return feats[0], feats[1]\n","\n","def added_word_pauses_adv(train_logs, test_logs):\n","    print(\"< added words pauses adv\")    \n","    feats = []\n","\n","    for data in [train_logs, test_logs]:\n","        logs = data.clone()\n","        logs = logs.with_columns(pl.col('word_count')\n","            .diff().over('id')\n","            .alias('word_diff'))\n","\n","        logs = logs.filter(\n","            pl.col('word_diff')>0).select(pl.col(['id','action_time']))\n","\n","        word_pause = logs.group_by(['id']).agg(\n","                        word_pause_max = pl.col('action_time').max(),\n","                        word_pause_min = pl.col('action_time').min(),\n","                        word_pasuse_q1 = pl.col('action_time').quantile(0.25),\n","                        word_pasuse_q3 = pl.col('action_time').quantile(0.75),\n","                        word_pasuse_kurt = pl.col('action_time').kurtosis(),\n","                        word_pasuse_skew = pl.col('action_time').skew(),\n","\n","        )\n","        feats.append(word_pause)\n","    return feats[0], feats[1]"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def remove_word_pauses_basic(train_logs, test_logs):\n","    print(\"< removed words pauses basic\")    \n","    feats = []\n","\n","    tr_logs, ts_logs = normalise_up_down_times(train_logs, test_logs)\n","\n","    for data in [tr_logs, ts_logs]:\n","        logs = data.clone()\n","        logs = logs.select(pl.col(['id','event_id','word_count','down_time','up_time','action_time']))\n","        logs = logs.with_columns(pl.col('word_count')\n","                    .diff()\n","                    .over('id')\n","                    .fill_null(1)\n","                    .alias('word_diff'))\n","\n","        logs = logs.with_columns(pl.col('down_time')\n","                    .diff()\n","                    .over('id')\n","                    .fill_null(0)\n","                    .alias('down_time_diff')) \n","\n","        word_pause = logs.filter(pl.col('word_diff')<0)\n","        word_pause = logs.group_by(['id']).agg(\n","                rmv_words_pause_count = pl.col('down_time_diff').count(),\n","                rmv_words_pause_mean = pl.col('down_time_diff').mean(),\n","                rmv_words_pause_sum = pl.col('down_time_diff').sum(),\n","                rmv_words_pause_std = pl.col('down_time_diff').std(),\n","                rmv_words_pause_median = pl.col('down_time_diff').median(),\n","        )\n","        feats.append(word_pause)\n","    return feats[0], feats[1]\n","\n","\n","def remove_word_pauses_adv(train_logs, test_logs):\n","    print(\"< removed words pauses advanced\")    \n","    feats = []\n","\n","    tr_logs, ts_logs = normalise_up_down_times(train_logs, test_logs)\n","\n","    for data in [tr_logs, ts_logs]:\n","        logs = data.clone()\n","        logs = logs.select(pl.col(['id','event_id','word_count','down_time','up_time','action_time']))\n","        logs = logs.with_columns(pl.col('word_count')\n","                    .diff()\n","                    .over('id')\n","                    .fill_null(1)\n","                    .alias('word_diff'))\n","\n","        logs = logs.with_columns(pl.col('down_time')\n","                    .diff()\n","                    .over('id')\n","                    .fill_null(0)\n","                    .alias('down_time_diff')) \n","\n","        word_pause = logs.filter(pl.col('word_diff')<0)\n","        word_pause = logs.group_by(['id']).agg(\n","                rmv_words_pause_max = pl.col('down_time_diff').max(),\n","                rmv_words_pause_q1 = pl.col('down_time_diff').quantile(0.25),\n","                rmv_words_pause_q3 = pl.col('down_time_diff').quantile(0.75),\n","                rmv_words_pause_kurt = pl.col('down_time_diff').kurtosis(),\n","                rmv_words_pause_skew = pl.col('down_time_diff').skew(),\n","        )\n","        feats.append(word_pause)\n","    return feats[0], feats[1]\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< removed words pauses advanced\n"]}],"source":["tr, ts = remove_word_pauses_adv(train_logs, test_logs)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>rmv_words_pause_max</th><th>rmv_words_pause_q1</th><th>rmv_words_pause_q3</th><th>rmv_words_pause_kurt</th><th>rmv_words_pause_skew</th></tr><tr><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;2222bbbb&quot;</td><td>0</td><td>-421454.0</td><td>0.0</td><td>-2.0</td><td>0.0</td></tr><tr><td>&quot;4444cccc&quot;</td><td>0</td><td>-450551.0</td><td>0.0</td><td>-2.0</td><td>0.0</td></tr><tr><td>&quot;0000aaaa&quot;</td><td>421640</td><td>0.0</td><td>421640.0</td><td>-2.0</td><td>0.0</td></tr></tbody></table></div>"],"text/plain":["shape: (3, 6)\n","┌──────────┬─────────────────┬─────────────────┬─────────────────┬────────────────┬────────────────┐\n","│ id       ┆ rmv_words_pause ┆ rmv_words_pause ┆ rmv_words_pause ┆ rmv_words_paus ┆ rmv_words_paus │\n","│ ---      ┆ _max            ┆ _q1             ┆ _q3             ┆ e_kurt         ┆ e_skew         │\n","│ str      ┆ ---             ┆ ---             ┆ ---             ┆ ---            ┆ ---            │\n","│          ┆ i64             ┆ f64             ┆ f64             ┆ f64            ┆ f64            │\n","╞══════════╪═════════════════╪═════════════════╪═════════════════╪════════════════╪════════════════╡\n","│ 2222bbbb ┆ 0               ┆ -421454.0       ┆ 0.0             ┆ -2.0           ┆ 0.0            │\n","│ 4444cccc ┆ 0               ┆ -450551.0       ┆ 0.0             ┆ -2.0           ┆ 0.0            │\n","│ 0000aaaa ┆ 421640          ┆ 0.0             ┆ 421640.0        ┆ -2.0           ┆ 0.0            │\n","└──────────┴─────────────────┴─────────────────┴─────────────────┴────────────────┴────────────────┘"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["ts.collect()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (0, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>event_id</th><th>word_count</th><th>down_time</th><th>up_time</th><th>action_time</th><th>word_diff</th><th>down_time_diff</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody></tbody></table></div>"],"text/plain":["shape: (0, 8)\n","┌─────┬──────────┬────────────┬───────────┬─────────┬─────────────┬───────────┬────────────────┐\n","│ id  ┆ event_id ┆ word_count ┆ down_time ┆ up_time ┆ action_time ┆ word_diff ┆ down_time_diff │\n","│ --- ┆ ---      ┆ ---        ┆ ---       ┆ ---     ┆ ---         ┆ ---       ┆ ---            │\n","│ str ┆ i64      ┆ i64        ┆ i64       ┆ i64     ┆ i64         ┆ i64       ┆ i64            │\n","╞═════╪══════════╪════════════╪═══════════╪═════════╪═════════════╪═══════════╪════════════════╡\n","└─────┴──────────┴────────────┴───────────┴─────────┴─────────────┴───────────┴────────────────┘"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["logs = test_logs.clone()\n","logs = logs.select(pl.col(['id','event_id','word_count','down_time','up_time','action_time']))\n","logs = logs.with_columns(pl.col('word_count')\n","                .diff()\n","                .over('id')\n","                .fill_null(1)\n","                .alias('word_diff'))\n","\n","logs = logs.with_columns(pl.col('down_time')\n","                .diff()\n","                .over('id')\n","                .fill_null(0)\n","                .alias('down_time_diff')) \n","\n","word_pause = logs.filter(pl.col('word_diff')<0)\n","word_pause.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["word_pause = logs.group_by(['id']).agg(\n","        rmv_words_pause_max = pl.col('down_time_diff').max(),\n","        rmv_words_pause_q1 = pl.col('down_time_diff').quantile(0.25),\n","        rmv_words_pause_q3 = pl.col('down_time_diff').quantile(0.75),\n","        rmv_words_pause_kurt = pl.col('down_time_diff').kurtosis(),\n","        rmv_words_pause_skew = pl.col('down_time_diff').skew(),\n",")\n","word_pause.collect()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>rmv_words_pause_count</th><th>rmv_words_pause_mean</th><th>rmv_words_pause_sum</th><th>rmv_words_pause_std</th><th>rmv_words_pause_median</th></tr><tr><td>str</td><td>u32</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;2222bbbb&quot;</td><td>2</td><td>-210727.0</td><td>-421454</td><td>298012.981358</td><td>-210727.0</td></tr><tr><td>&quot;4444cccc&quot;</td><td>2</td><td>-225275.5</td><td>-450551</td><td>318587.66737</td><td>-225275.5</td></tr><tr><td>&quot;0000aaaa&quot;</td><td>2</td><td>210820.0</td><td>421640</td><td>298144.503219</td><td>210820.0</td></tr></tbody></table></div>"],"text/plain":["shape: (3, 6)\n","┌──────────┬─────────────────┬─────────────────┬─────────────────┬────────────────┬────────────────┐\n","│ id       ┆ rmv_words_pause ┆ rmv_words_pause ┆ rmv_words_pause ┆ rmv_words_paus ┆ rmv_words_paus │\n","│ ---      ┆ _count          ┆ _mean           ┆ _sum            ┆ e_std          ┆ e_median       │\n","│ str      ┆ ---             ┆ ---             ┆ ---             ┆ ---            ┆ ---            │\n","│          ┆ u32             ┆ f64             ┆ i64             ┆ f64            ┆ f64            │\n","╞══════════╪═════════════════╪═════════════════╪═════════════════╪════════════════╪════════════════╡\n","│ 2222bbbb ┆ 2               ┆ -210727.0       ┆ -421454         ┆ 298012.981358  ┆ -210727.0      │\n","│ 4444cccc ┆ 2               ┆ -225275.5       ┆ -450551         ┆ 318587.66737   ┆ -225275.5      │\n","│ 0000aaaa ┆ 2               ┆ 210820.0        ┆ 421640          ┆ 298144.503219  ┆ 210820.0       │\n","└──────────┴─────────────────┴─────────────────┴─────────────────┴────────────────┴────────────────┘"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["ts.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< added words pauses\n"]}],"source":["\n","\n","tr_feats, ts_feats = added_word_pauses_basic(train_logs, test_logs)    "]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (0, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>event_id</th><th>word_count</th><th>down_time</th><th>up_time</th><th>action_time</th><th>word_diff</th><th>down_time_diff</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody></tbody></table></div>"],"text/plain":["shape: (0, 8)\n","┌─────┬──────────┬────────────┬───────────┬─────────┬─────────────┬───────────┬────────────────┐\n","│ id  ┆ event_id ┆ word_count ┆ down_time ┆ up_time ┆ action_time ┆ word_diff ┆ down_time_diff │\n","│ --- ┆ ---      ┆ ---        ┆ ---       ┆ ---     ┆ ---         ┆ ---       ┆ ---            │\n","│ str ┆ i64      ┆ i64        ┆ i64       ┆ i64     ┆ i64         ┆ i64       ┆ i64            │\n","╞═════╪══════════╪════════════╪═══════════╪═════════╪═════════════╪═══════════╪════════════════╡\n","└─────┴──────────┴────────────┴───────────┴─────────┴─────────────┴───────────┴────────────────┘"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["word_pause = logs.filter(pl.col('word_diff')<0)\n","word_pause.collect()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (6, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>event_id</th><th>down_time</th><th>up_time</th><th>action_time</th><th>activity</th><th>down_event</th><th>up_event</th><th>text_change</th><th>cursor_position</th><th>word_count</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;0000aaaa&quot;</td><td>1</td><td>338433</td><td>338518</td><td>85</td><td>&quot;Input&quot;</td><td>&quot;Space&quot;</td><td>&quot;Space&quot;</td><td>&quot; &quot;</td><td>0</td><td>0</td></tr><tr><td>&quot;0000aaaa&quot;</td><td>2</td><td>760073</td><td>760160</td><td>87</td><td>&quot;Input&quot;</td><td>&quot;Space&quot;</td><td>&quot;Space&quot;</td><td>&quot; &quot;</td><td>1</td><td>0</td></tr><tr><td>&quot;2222bbbb&quot;</td><td>1</td><td>711956</td><td>712023</td><td>67</td><td>&quot;Input&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>0</td><td>1</td></tr><tr><td>&quot;2222bbbb&quot;</td><td>2</td><td>290502</td><td>290548</td><td>46</td><td>&quot;Input&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>1</td><td>1</td></tr><tr><td>&quot;4444cccc&quot;</td><td>1</td><td>635547</td><td>635641</td><td>94</td><td>&quot;Input&quot;</td><td>&quot;Space&quot;</td><td>&quot;Space&quot;</td><td>&quot; &quot;</td><td>0</td><td>0</td></tr><tr><td>&quot;4444cccc&quot;</td><td>2</td><td>184996</td><td>185052</td><td>56</td><td>&quot;Input&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>1</td><td>1</td></tr></tbody></table></div>"],"text/plain":["shape: (6, 11)\n","┌──────────┬──────────┬───────────┬─────────┬───┬──────────┬─────────────┬────────────┬────────────┐\n","│ id       ┆ event_id ┆ down_time ┆ up_time ┆ … ┆ up_event ┆ text_change ┆ cursor_pos ┆ word_count │\n","│ ---      ┆ ---      ┆ ---       ┆ ---     ┆   ┆ ---      ┆ ---         ┆ ition      ┆ ---        │\n","│ str      ┆ i64      ┆ i64       ┆ i64     ┆   ┆ str      ┆ str         ┆ ---        ┆ i64        │\n","│          ┆          ┆           ┆         ┆   ┆          ┆             ┆ i64        ┆            │\n","╞══════════╪══════════╪═══════════╪═════════╪═══╪══════════╪═════════════╪════════════╪════════════╡\n","│ 0000aaaa ┆ 1        ┆ 338433    ┆ 338518  ┆ … ┆ Space    ┆             ┆ 0          ┆ 0          │\n","│ 0000aaaa ┆ 2        ┆ 760073    ┆ 760160  ┆ … ┆ Space    ┆             ┆ 1          ┆ 0          │\n","│ 2222bbbb ┆ 1        ┆ 711956    ┆ 712023  ┆ … ┆ q        ┆ q           ┆ 0          ┆ 1          │\n","│ 2222bbbb ┆ 2        ┆ 290502    ┆ 290548  ┆ … ┆ q        ┆ q           ┆ 1          ┆ 1          │\n","│ 4444cccc ┆ 1        ┆ 635547    ┆ 635641  ┆ … ┆ Space    ┆             ┆ 0          ┆ 0          │\n","│ 4444cccc ┆ 2        ┆ 184996    ┆ 185052  ┆ … ┆ q        ┆ q           ┆ 1          ┆ 1          │\n","└──────────┴──────────┴───────────┴─────────┴───┴──────────┴─────────────┴────────────┴────────────┘"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["test_logs.collect()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["0     2407\n","1       30\n","2       13\n","5        4\n","8        2\n","4        2\n","3        2\n","15       2\n","11       1\n","10       1\n","7        1\n","25       1\n","6        1\n","32       1\n","26       1\n","13       1\n","23       1\n","Name: rmv_words_pause_min, dtype: int64"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["x= tr.collect().to_pandas()\n","x.rmv_words_pause_min.value_counts()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from m3_model_params import lgb_params_1\n","tr_feats, ts_feats = remove_word_pauses(train_logs, test_logs)    \n","train_feats = tr_feats.join(train_scores, on='id', how='left')\n","train_feats = train_feats.collect().to_pandas()\n","test_feats = ts_feats.clone().collect().to_pandas()\n","test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, lgb_params_1)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def add_word_pauses(train_logs, test_logs):\n","\n","    feats = []\n","\n","    tr_logs, ts_logs = normalise_up_down_times(train_logs, test_logs)\n","\n","    for data in [tr_logs, ts_logs]:\n","        logs = data.clone()\n","        logs = logs.select(pl.col(['id','event_id','word_count','down_time','up_time','action_time']))\n","        logs = logs.with_columns(pl.col('word_count')\n","                    .diff()\n","                    .over('id')\n","                    .fill_null(1)\n","                    .alias('word_diff'))\n","\n","        logs = logs.with_columns(pl.col('down_time')\n","                    .diff()\n","                    .over('id')\n","                    .fill_null(0)\n","                    .alias('down_time_diff')) \n","\n","        word_pause = logs.filter(pl.col('word_diff')>0)\n","        word_pause = logs.group_by(['id']).agg(\n","                word_pause_pstv_count = pl.col('down_time_diff').count(),\n","                word_pause_pstv_mean = pl.col('down_time_diff').mean(),\n","                word_pause_pstv_sum = pl.col('down_time_diff').sum(),\n","                word_pause_pstv_std = pl.col('down_time_diff').std(),\n","                word_pause_pstv_max = pl.col('down_time_diff').max(),\n","                word_pause_pstv_median = pl.col('down_time_diff').median(),\n","        )\n","        feats.append(word_pause)\n","    return feats[0], feats[1]\n","\n","tr_feats, ts_feats = add_word_pauses(train_logs, test_logs)    "]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def remove_word_pauses(train_logs, test_logs):\n","\n","    feats = []\n","\n","    tr_logs, ts_logs = normalise_up_down_times(train_logs, test_logs)\n","\n","    for data in [tr_logs, ts_logs]:\n","        logs = data.clone()\n","        logs = logs.select(pl.col(['id','event_id','word_count','down_time','up_time','action_time']))\n","        logs = logs.with_columns(pl.col('word_count')\n","                    .diff()\n","                    .over('id')\n","                    .fill_null(1)\n","                    .alias('word_diff'))\n","\n","        logs = logs.with_columns(pl.col('down_time')\n","                    .diff()\n","                    .over('id')\n","                    .fill_null(0)\n","                    .alias('down_time_diff')) \n","\n","        word_pause = logs.filter(pl.col('word_diff')<0)\n","        word_pause = logs.group_by(['id']).agg(\n","                word_pause_pstv_count = pl.col('down_time_diff').count(),\n","                word_pause_pstv_mean = pl.col('down_time_diff').mean(),\n","                word_pause_pstv_sum = pl.col('down_time_diff').sum(),\n","                word_pause_pstv_std = pl.col('down_time_diff').std(),\n","                word_pause_pstv_max = pl.col('down_time_diff').max(),\n","                word_pause_pstv_median = pl.col('down_time_diff').median(),\n","        )\n","        feats.append(word_pause)\n","    return feats[0], feats[1]\n","\n","tr_feats, ts_feats = remove_word_pauses(train_logs, test_logs)    "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# everything is logged - DONE\n","# bursts = 2/3 of a second - input only - DONE\n","# inter word pauses\n","# between sentence pauses ?\n","# between paragraph pauses ?\n","# backspace pauses\n","# edit pauses"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Best Feature Set: ['train_essay_sentences.pkl', 'train_create_pauses.pkl', \n","# 'train_vector_one_gram.pkl', 'train_essay_paragraphs.pkl', \n","# 'train_categorical_nunique.pkl', 'train_word_pauses.pkl', \n","# 'train_events_counts_rate_of_change.pkl', 'train_word_counts_rate_of_change.pkl', \n","# 'train_r_burst_feats.pkl', 'train_vector_two_gram.pkl', 'train_events_counts_acceleration.pkl']\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< Events counts features >\n","< Count vectorize one-grams >\n","< Idle time features >\n","< cursor position acceleration >\n","word pauses\n","< word count acceleration >\n","< R-burst features >\n","< Count vectorize bi-grams >\n","< Essays paragraphs feats >\n","< Essays paragraphs feats >\n","< Essays sentences feats >\n","< Essays sentences feats >\n","train feats shape (2471, 144)\n"]}],"source":["# best_feature_set_1 - PARTIAL\n","train_essays          = get_essay_df(train_logs.collect().to_pandas())\n","test_essays           = get_essay_df(test_logs.collect().to_pandas())\n","\n","tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n","tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n","tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n","tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n","tr_word_pause, ts_word_pause = word_pauses(train_logs, test_logs)\n","tr_word_count_acc, ts_word_count_acc = word_count_acceleration(train_logs, test_logs)\n","#tr_p_burst, ts_p_burst = p_burst_feats(train_logs, test_logs, 2)\n","tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n","#tr_event_acc, ts_event_acc = events_counts_acceleration(train_logs, test_logs)\n","# tr_nunique, ts_nunique = categorical_nunique(train_logs, test_logs)\n","tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n","# tr_time_by_act, ts_time_by_act = action_time_by_activity(train_logs, test_logs)\n","# tr_cursor_pos_roc, ts_cursor_pos_roc = cursor_pos_rate_of_change(train_logs, test_logs)\n","# \n","# tr_act_count, ts_act_count = count_of_activities(train_logs, test_logs)\n","# tr_get_keys, ts_get_keys = get_keys_pressed_per_second(train_logs.collect().to_pandas(), \n","#                                                        test_logs.collect().to_pandas())\n","# \n","# tr_input_change, ts_input_change = input_text_change_feats(train_logs, test_logs)\n","# tr_wc_roc, ts_wc_roc =  word_counts_rate_of_change(train_logs, test_logs)\n","\n","train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n","train_feats = train_feats.join(tr_pauses, on='id', how='left')\n","train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_word_pause, on='id', how='left')\n","train_feats = train_feats.join(tr_word_count_acc, on='id', how='left')\n","#train_feats = train_feats.join(tr_p_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n","# train_feats = train_feats.join(tr_event_acc, on='id', how='left')\n","# train_feats = train_feats.join(tr_nunique, on='id', how='left')\n","# train_feats = train_feats.join(tr_wc_roc, on='id', how='left')\n","# train_feats = train_feats.join(tr_act_count, on='id', how='left')\n","# train_feats = train_feats.join(tr_cursor_pos_roc, on='id', how='left')\n","\n","# train_feats = train_feats.join(tr_get_keys, on='id', how='left')\n","# train_feats = train_feats.join(tr_input_change, on='id', how='left')\n","# train_feats = train_feats.join(tr_time_by_act, on='id', how='left')\n","\n","test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n","test_feats = test_feats.join(ts_pauses, on='id', how='left')\n","test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_word_pause, on='id', how='left')\n","test_feats = test_feats.join(ts_word_count_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_p_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n","# test_feats = test_feats.join(tr_event_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_nunique, on='id', how='left')\n","# test_feats = test_feats.join(ts_wc_roc, on='id', how='left')\n","# test_feats = test_feats.join(ts_act_count, on='id', how='left')\n","# test_feats = test_feats.join(ts_cursor_pos_roc, on='id', how='left')\n","\n","\n","# test_feats = test_feats.join(ts_get_keys, on='id', how='left')\n","# test_feats = test_feats.join(ts_input_change, on='id', how='left')\n","# test_feats = test_feats.join(ts_time_by_act, on='id', how='left')\n","\n","\n","train_logs = train_logs.collect().to_pandas()\n","test_logs = test_logs.collect().to_pandas()\n","train_scores = train_scores.collect().to_pandas()\n","train_feats = train_feats.sort('id')\n","train_feats = train_feats.collect().to_pandas()\n","test_feats = test_feats.collect().to_pandas()\n","\n","train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n","\n","train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n","\n","train_feats = train_feats.merge(train_scores, on='id', how='left')\n","print(f'train feats shape {train_feats.shape}')\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:21:44.320780Z","iopub.status.busy":"2023-12-18T16:21:44.320496Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train feats shape (2471, 144)\n"]}],"source":["from m5_sb_models import lgb_pipeline\n","lgb_params_1 = {\n","    'boosting_type': 'gbdt', \n","    'metric': 'rmse',\n","    'reg_alpha': 0.0031, \n","    'reg_lambda': 0.001, \n","    'colsample_bytree': 0.8,  \n","    'subsample_freq': 1,  \n","    'subsample': 0.75,  \n","    'learning_rate': 0.017, \n","    'num_leaves': 19, \n","    'min_child_samples': 46,\n","    'n_estimators': 350,\n","    'verbosity': -1\n","    }\n","\n","param = {'n_estimators': 1024,\n","        'learning_rate': 0.005,\n","        'metric': 'rmse',\n","        'force_col_wise': True,\n","        'verbosity': 0,}\n","\n","# train_feats = train_feats[['id', 'score'] + feat_select]\n","# test_feats = test_feats[['id'] + feat_select]\n","\n","print(f'train feats shape {train_feats.shape}')\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Final RMSE over 50: 0.603617. Std 0.8270\n","RMSE by fold 0.603563. Std 0.0083\n","Final RMSE over 50: 0.601545. Std 0.8255\n","RMSE by fold 0.601473. Std 0.0091\n","Final RMSE over 50: 0.602574. Std 0.8276\n","RMSE by fold 0.602372. Std 0.0151\n","Final RMSE over 50: 0.601950. Std 0.8275\n","RMSE by fold 0.601897. Std 0.0080\n","Final RMSE over 50: 0.604154. Std 0.8274\n","RMSE by fold 0.603977. Std 0.0149\n","Final RMSE over 50: 0.602163. Std 0.8266\n","RMSE by fold 0.602061. Std 0.0108\n","Final RMSE over 50: 0.603044. Std 0.8271\n","RMSE by fold 0.602868. Std 0.0148\n","Final RMSE over 50: 0.602455. Std 0.8275\n","RMSE by fold 0.602338. Std 0.0117\n","Final RMSE over 50: 0.602454. Std 0.8279\n","RMSE by fold 0.602405. Std 0.0079\n","Final RMSE over 50: 0.602837. Std 0.8266\n","RMSE by fold 0.602635. Std 0.0155\n","Final RMSE over 50: 0.602299. Std 0.8262\n","RMSE by fold 0.602235. Std 0.0083\n","Final RMSE over 50: 0.602076. Std 0.8286\n","RMSE by fold 0.601953. Std 0.0120\n","Final RMSE over 50: 0.602816. Std 0.8265\n","RMSE by fold 0.602714. Std 0.0110\n","Final RMSE over 50: 0.602905. Std 0.8268\n","RMSE by fold 0.602781. Std 0.0120\n","Final RMSE over 50: 0.603042. Std 0.8276\n","RMSE by fold 0.602884. Std 0.0137\n"]},{"data":{"text/plain":["0.6026620396931698"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["shuffle_preds = []\n","\n","for i in range(15):\n","    train_feats = train_feats.sample(frac=1).reset_index(drop=True)\n","    test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, lgb_params_1)\n","    shuffle_preds.append(rmse)\n","    #test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, param)\n","\n","np.mean(shuffle_preds)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","      <th>RMSE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.5</td>\n","      <td>1.528224</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.283878</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>6.0</td>\n","      <td>1.132529</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.5</td>\n","      <td>0.879977</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5.5</td>\n","      <td>0.738216</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>0.573584</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5.0</td>\n","      <td>0.474352</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.5</td>\n","      <td>0.461494</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3.0</td>\n","      <td>0.460465</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3.5</td>\n","      <td>0.402527</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.5</td>\n","      <td>0.355785</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4.0</td>\n","      <td>0.349586</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    score      RMSE\n","0     0.5  1.528224\n","1     1.0  1.283878\n","11    6.0  1.132529\n","2     1.5  0.879977\n","10    5.5  0.738216\n","3     2.0  0.573584\n","9     5.0  0.474352\n","4     2.5  0.461494\n","5     3.0  0.460465\n","6     3.5  0.402527\n","8     4.5  0.355785\n","7     4.0  0.349586"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["oof_res = oof_preds.groupby(['id', 'score'])['preds'].mean().reset_index()\n","# oof_res['rmse'] = oof_res.apply(lambda x: np.sqrt((x['score']-x['preds'])**2))\n","oof_res['RMSE'] = np.sqrt((oof_res['score']-oof_res['preds'])**2)\n","oof_res.groupby(['score'])['RMSE'].mean().reset_index().sort_values('RMSE', ascending=False)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","      <th>RMSE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.5</td>\n","      <td>1.528224</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.283878</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>6.0</td>\n","      <td>1.132529</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.5</td>\n","      <td>0.879977</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5.5</td>\n","      <td>0.738216</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>0.573584</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5.0</td>\n","      <td>0.474352</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.5</td>\n","      <td>0.461494</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3.0</td>\n","      <td>0.460465</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3.5</td>\n","      <td>0.402527</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.5</td>\n","      <td>0.355785</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4.0</td>\n","      <td>0.349586</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    score      RMSE\n","0     0.5  1.528224\n","1     1.0  1.283878\n","11    6.0  1.132529\n","2     1.5  0.879977\n","10    5.5  0.738216\n","3     2.0  0.573584\n","9     5.0  0.474352\n","4     2.5  0.461494\n","5     3.0  0.460465\n","6     3.5  0.402527\n","8     4.5  0.355785\n","7     4.0  0.349586"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["oof_res = oof_preds.groupby(['id', 'score'])['preds'].mean().reset_index()\n","oof_res['RMSE'] = np.sqrt((oof_res['score']-oof_res['preds'])**2)\n","oof_res.groupby(['score'])['RMSE'].mean().reset_index().sort_values('RMSE', ascending=False)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["oof_res = oof_preds.groupby(['id', 'score'])['preds'].mean().reset_index()\n","# oof_res['rmse'] = oof_res.apply(lambda x: np.sqrt((x['score']-x['preds'])**2))\n","oof_res['RMSE'] = np.sqrt((oof_res['score']-oof_res['preds'])**2)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6678907,"sourceId":59291,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
