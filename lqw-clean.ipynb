{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-18T16:20:56.671429Z","iopub.status.busy":"2023-12-18T16:20:56.671017Z","iopub.status.idle":"2023-12-18T16:20:58.568632Z","shell.execute_reply":"2023-12-18T16:20:58.567768Z","shell.execute_reply.started":"2023-12-18T16:20:56.671393Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from m4_feats_polars import *\n","from m5_sb_models import *\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:20:58.587076Z","iopub.status.busy":"2023-12-18T16:20:58.586426Z","iopub.status.idle":"2023-12-18T16:20:58.601881Z","shell.execute_reply":"2023-12-18T16:20:58.600973Z","shell.execute_reply.started":"2023-12-18T16:20:58.587045Z"},"trusted":true},"outputs":[],"source":["import polars as pl\n","data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n","train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n","test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n","train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# everything is logged\n","# bursts = 2/3 of a second - input only\n","# inter word pauses\n","# between sentence pauses ?\n","# between paragraph pauses ?\n","# backspace pauses\n","# edit pauses"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["Best_Feature_Set = [\n","    'train_down_events_counts.pkl', \n","    'train_vector_one_gram.pkl', \n","    'train_create_pauses.pkl', \n","    'train_essay_paragraphs.pkl', \n","    'train_cursor_pos_acceleration.pkl', \n","    'train_word_count_acceleration.pkl', \n","    'train_vector_two_gram.pkl']\n","\n","# (action_time_by_activity, categorical_nunique) # best 2 0.602997\n","('get_keys_pressed_per_second', 'p_burst_feats', 'r_burst_feats') # best 3 0.602696\n","\n","best_feature_set_2 = [\n","    'train_down_events_counts.pkl',\n","    'train_vector_one_gram.pkl',\n","    'train_create_pauses.pkl',\n","    'train_essay_paragraphs.pkl',\n","    'train_essay_sentences.pkl',\n","    'train_cursor_pos_acceleration.pkl',\n","    'train_word_count_acceleration.pkl',\n","    'train_categorical_nunique.pkl',\n","    'train_cursor_pos_rate_of_change.pkl',\n","    'train_get_keys_pressed_per_second.pkl']   \n","\n","base_feat_3 = ['train_down_events_counts.pkl', \n","               'train_vector_one_gram.pkl', \n","               'train_create_pauses.pkl', \n","               'train_essay_paragraphs.pkl', \n","               'train_cursor_pos_acceleration.pkl', \n","               'train_essay_sentences.pkl', \n","               'train_action_time_baseline_stats.pkl']"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["< Events counts features >\n","< Count vectorize one-grams >\n","< Idle time features >\n","< cursor position acceleration >\n","< word count acceleration >\n","< Count vectorize bi-grams >\n","< Action time by activities >\n","< R-burst features >\n","< P-burst features >\n","< Categorical # unique values features >\n","< Input text change features >\n","< Word counts rate of change features >\n","< Essays paragraphs feats >\n","< Essays paragraphs feats >\n","train feats shape (2471, 86)\n"]}],"source":["# best_feature_set_1 - PARTIAL\n","\n","train_essays          = get_essay_df(train_logs.collect().to_pandas())\n","test_essays           = get_essay_df(test_logs.collect().to_pandas())\n","\n","# train_down_events_counts\n","tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n","# train_vector_one_gram\n","tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n","# train_create_pauses\n","tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n","# train_cursor_pos_acceleration\n","tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n","# train_word_count_acceleration\n","tr_word_count_acc, ts_word_count_acc = word_count_acceleration(train_logs, test_logs)\n","# train_vector_two_gram\n","tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n","# time by activity\n","tr_time_by_act, ts_time_by_act = action_time_by_activity(train_logs, test_logs)\n","\n","# count_of_activities(train_logs, test_logs)\n","tr_act_count, ts_act_count = count_of_activities(train_logs, test_logs)\n","# # r_burst_feats\n","tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n","# # p_burst_feats\n","tr_p_burst, ts_p_burst = p_burst_feats(train_logs, test_logs, 2)\n","# nunique\n","tr_nunique, ts_nunique = categorical_nunique(train_logs, test_logs)\n","# get_keys_pressed_per_second\n","tr_get_keys, ts_get_keys = get_keys_pressed_per_second(train_logs.collect().to_pandas(), \n","                                                       test_logs.collect().to_pandas())\n","\n","# input change feats\n","tr_input_change, ts_input_change = input_text_change_feats(train_logs, test_logs)\n","#  word_counts_rate_of_change\n","\n","tr_wc_roc, ts_wc_roc =  word_counts_rate_of_change(train_logs, test_logs)\n","\n","['train_down_events_counts.pkl', 'train_vector_one_gram.pkl', 'train_create_pauses.pkl', 'train_essay_paragraphs.pkl', 'train_cursor_pos_acceleration.pkl']\n","\n","# (action_time_by_activity, categorical_nunique) # best 2 0.602997\n","# ('get_keys_pressed_per_second', 'p_burst_feats', 'r_burst_feats') # best 3 0.602696\n","\n","train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n","train_feats = train_feats.join(tr_pauses, on='id', how='left')\n","train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n","# train_feats = train_feats.join(tr_word_count_acc, on='id', how='left')\n","# train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n","# train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n","# train_feats = train_feats.join(tr_get_keys, on='id', how='left')\n","# train_feats = train_feats.join(tr_wc_roc, on='id', how='left')\n","# train_feats = train_feats.join(tr_input_change, on='id', how='left')\n","# train_feats = train_feats.join(tr_nunique, on='id', how='left')\n","train_feats = train_feats.join(tr_p_burst, on='id', how='left')\n","# train_feats = train_feats.join(tr_time_by_act, on='id', how='left')\n","\n","\n","test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n","test_feats = test_feats.join(ts_pauses, on='id', how='left')\n","test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_word_count_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n","# test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n","# test_feats = test_feats.join(ts_get_keys, on='id', how='left')\n","# test_feats = test_feats.join(ts_wc_roc, on='id', how='left')\n","# test_feats = test_feats.join(ts_input_change, on='id', how='left')\n","# test_feats = test_feats.join(ts_nunique, on='id', how='left')\n","test_feats = test_feats.join(ts_p_burst, on='id', how='left')\n","# test_feats = test_feats.join(ts_time_by_act, on='id', how='left')\n","\n","\n","train_logs = train_logs.collect().to_pandas()\n","test_logs = test_logs.collect().to_pandas()\n","train_scores = train_scores.collect().to_pandas()\n","train_feats = train_feats.sort('id')\n","train_feats = train_feats.collect().to_pandas()\n","test_feats = test_feats.collect().to_pandas()\n","\n","train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n","\n","# train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n","# test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n","\n","\n","train_feats           = train_feats.merge(train_scores, on=['id'], how='left')\n","train_feats           = train_feats.sort_values('id')\n","\n","print(f'train feats shape {train_feats.shape}')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T16:21:44.320780Z","iopub.status.busy":"2023-12-18T16:21:44.320496Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Final RMSE over 50: 0.605257. Std 0.8248\n","RMSE by fold 0.605152. Std 0.0113\n"]}],"source":["# missing_cols = set(train_feats.columns) - set(test_feats.columns)\n","# missing_cols.remove('score')\n","\n","# for col in missing_cols:\n","#     test_feats[col] = np.nan\n","\n","# for estimators in [350]:\n","\n","lgb_params_1 = {\n","    'boosting_type': 'gbdt', \n","    'metric': 'rmse',\n","    'reg_alpha': 0.0031, \n","    'reg_lambda': 0.001, \n","    'colsample_bytree': 0.8,  \n","    'subsample_freq': 1,  \n","    'subsample': 0.75,  \n","    'learning_rate': 0.017, \n","    'num_leaves': 19, \n","    'min_child_samples': 46,\n","    'n_estimators': 350,\n","    'verbosity': -1\n","    }\n","\n","param = {'n_estimators': 1024,\n","        'learning_rate': 0.005,\n","        'metric': 'rmse',\n","        'force_col_wise': True,\n","        'verbosity': 0,}\n","    \n","#print(f'Number of estimators: {estimators}')\n","test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, lgb_params_1)\n","#test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, param)"]},{"cell_type":"markdown","metadata":{},"source":["new_p_burst 2/3\n","Final RMSE over 50: 0.605179. Std 0.8250 \n","RMSE by fold 0.605076. Std 0.0113\n","Final RMSE over 50: 0.605200. Std 0.8245\n","RMSE by fold 0.605084. Std 0.0120\n","Final RMSE over 50: 0.605611. Std 0.8250\n","RMSE by fold 0.605490. Std 0.0122\n","Final RMSE over 50: 0.605304. Std 0.8246\n","RMSE by fold 0.605189. Std 0.0119\n","\n","-------------------------------------------\n","new_p_burst 2\n","Final RMSE over 50: 0.604866. Std 0.8248\n","RMSE by fold 0.604760. Std 0.0114\n","Final RMSE over 50: 0.605266. Std 0.8250\n","RMSE by fold 0.605167. Std 0.0110\n","Final RMSE over 50: 0.605132. Std 0.8249\n","RMSE by fold 0.605019. Std 0.0118\n","Final RMSE over 50: 0.605257. Std 0.8248\n","RMSE by fold 0.605152. Std 0.0113\n","\n","\n","reduced feats\n","Final RMSE over 50: 0.604472. Std 0.8245\n","RMSE by fold 0.604365. Std 0.0115\n","\n","r burst only\n","Number of estimators: 350\n","Final RMSE over 50: 0.604057. Std 0.8244\n","RMSE by fold 0.603946. Std 0.0116\n","\n","Number of estimators: 350\n","Final RMSE over 50: 0.604650. Std 0.8243\n","RMSE by fold 0.604527. Std 0.0122"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'y_train' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlgb\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Assuming X_train and y_train are your features and labels respectively\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m weights \u001b[39m=\u001b[39m [\u001b[39m1.0\u001b[39m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y_train))]  \u001b[39m# Default weights\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m weights[some_specific_index] \u001b[39m=\u001b[39m \u001b[39m1.5\u001b[39m  \u001b[39m# Higher weight for a specific instance\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lqw-clean.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m train_data \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_train, label\u001b[39m=\u001b[39my_train, weight\u001b[39m=\u001b[39mweights)\n","\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"]}],"source":["import lightgbm as lgb\n","\n","# Assuming X_train and y_train are your features and labels respectively\n","weights = [1.0 for _ in range(len(y_train))]  # Default weights\n","weights[some_specific_index] = 1.5  # Higher weight for a specific instance\n","\n","train_data = lgb.Dataset(X_train, label=y_train, weight=weights)\n","# Proceed with setting up parameters and training the model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_ids = test_feats.id\n","y_pred = np.mean(test_preds, axis=0)\n","\n","sub = pd.DataFrame({'id': test_ids, 'score': y_pred})\n","sub.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6678907,"sourceId":59291,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
