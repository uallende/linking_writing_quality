{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from m4_feats_functions import *\n",
    "from m5_models import *\n",
    "from m7_utils import *\n",
    "from m3_model_params import lgb_params_2 as params\n",
    "from m3_model_params import xgb_params_2 as xgb_params\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the train and test directories\n",
    "INPUT_DIR = 'kaggle/input/linking-writing-processes-to-writing-quality'\n",
    "FEATURE_STORE = 'feature_store'\n",
    "train_dir = 'feature_store/train'\n",
    "test_dir = 'feature_store/test'\n",
    "\n",
    "train_logs = pd.read_csv(f'{INPUT_DIR}/train_logs.csv')\n",
    "train_scores = pd.read_csv(f'{INPUT_DIR}/train_scores.csv')\n",
    "test_logs = pd.read_csv(f'{INPUT_DIR}/test_logs.csv')\n",
    "ss_df = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\n",
    "\n",
    "seed = 42\n",
    "n_repeats = 5\n",
    "n_splits = 10\n",
    "target_col = 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adj_eff_time', 'action_time_gap', 'rep_cut', 'at_by_bucket', 'wc_chage', 'wpm_feats', 'count_vectorized', 'IKI', 'action_time_gap_by_acti']\n",
      "adj_eff_time\n",
      "LGBM Average RMSE over 100 folds: 0.605755\n",
      "Features: adj_eff_time. RMSE: 0.605755, Improvement: -0.001441\n",
      "action_time_gap\n",
      "LGBM Average RMSE over 100 folds: 0.604004\n",
      "Features: action_time_gap. RMSE: 0.604004, Improvement: 0.000310\n",
      "rep_cut\n",
      "LGBM Average RMSE over 100 folds: 0.604101\n",
      "Features: rep_cut. RMSE: 0.604101, Improvement: 0.000213\n",
      "at_by_bucket\n",
      "LGBM Average RMSE over 100 folds: 0.605283\n",
      "Features: at_by_bucket. RMSE: 0.605283, Improvement: -0.000969\n",
      "wc_chage\n",
      "LGBM Average RMSE over 100 folds: 0.605597\n",
      "Features: wc_chage. RMSE: 0.605597, Improvement: -0.001283\n",
      "wpm_feats\n",
      "LGBM Average RMSE over 100 folds: 0.605465\n",
      "Features: wpm_feats. RMSE: 0.605465, Improvement: -0.001151\n",
      "count_vectorized\n",
      "LGBM Average RMSE over 100 folds: 0.602782\n",
      "Features: count_vectorized. RMSE: 0.602782, Improvement: 0.001532\n",
      "IKI\n",
      "LGBM Average RMSE over 100 folds: 0.604575\n",
      "Features: IKI. RMSE: 0.604575, Improvement: -0.000261\n",
      "action_time_gap_by_acti\n",
      "LGBM Average RMSE over 100 folds: 0.604244\n",
      "Features: action_time_gap_by_acti. RMSE: 0.604244, Improvement: 0.000070\n"
     ]
    }
   ],
   "source": [
    "train_feats = pd.read_pickle('feature_selection/test_feats.pkl')\n",
    "test_feats = pd.read_pickle('feature_selection/test_feats.pkl')\n",
    "\n",
    "lgb_params_1 = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'metric': 'rmse',\n",
    "    'reg_alpha': 0.0031, \n",
    "    'reg_lambda': 0.001, \n",
    "    'colsample_bytree': 0.8,  \n",
    "    'subsample_freq': 1,  \n",
    "    'subsample': 0.75,  \n",
    "    'learning_rate': 0.017, \n",
    "    'num_leaves': 19, \n",
    "    'min_child_samples': 46,\n",
    "    'n_estimators': 400,\n",
    "    'verbosity': -1\n",
    "    }\n",
    "\n",
    "results = compare_with_baseline(\n",
    "    base_dir=FEATURE_STORE, \n",
    "    base_train_feats=train_feats,\n",
    "    base_test_feats=test_feats,\n",
    "    params = lgb_params_1,\n",
    "    baseline_metrics=0.603377,\n",
    "    train_scores=train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.601710\n",
      "Mean RMSE of all iterations: 0.613188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 0/5 [00:00<?, ?it/s]/root/miniconda3/envs/lrp/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:03:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "Iterations: 100%|██████████| 5/5 [02:14<00:00, 26.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Average RMSE over 50 folds: 0.600903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 450\n",
      "Ridge Average RMSE over 50 folds: 0.619138\n",
      "Blend RMSE 0.597967\n"
     ]
    }
   ],
   "source": [
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "\n",
    "\n",
    "tr_count_vector = pd.read_pickle('feature_store/train/train_count_vectorized.pkl')\n",
    "ts_count_vector = pd.read_pickle('feature_store/test/test_count_vectorized.pkl')\n",
    "train_feats = train_feats.merge(tr_count_vector, on='id', how='left')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "feats_feats = test_feats.merge(ts_count_vector, on='id', how='left')\n",
    "\n",
    "alpha = 450\n",
    "\n",
    "_, oof_2, rmse, model1 = cv_pipeline(train_feats, test_feats, params, params['boosting_type'])\n",
    "\n",
    "_, oof_1, rmse, model1 = xgb_cv_pipeline(train_feats=train_feats, \n",
    "                                        test_feats=test_feats, \n",
    "                                        xgb_params=xgb_params, \n",
    "                                        seed=seed, \n",
    "                                        n_repeats=n_repeats, \n",
    "                                        n_splits=n_splits)\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "\n",
    "tr_count_vector = pd.read_pickle('feature_store/train/train_count_vectorized.pkl')\n",
    "ts_count_vector = pd.read_pickle('feature_store/test/test_count_vectorized.pkl')\n",
    "train_feats = train_feats.merge(tr_count_vector, on='id', how='left')\n",
    "feats_feats = test_feats.merge(ts_count_vector, on='id', how='left')\n",
    "\n",
    "train_feats = preprocess_feats(train_feats, PowerTransformer('yeo-johnson'))\n",
    "test_feats = preprocess_feats(test_feats, PowerTransformer('yeo-johnson'))\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')      \n",
    "\n",
    "\n",
    "ridge_params = {'alpha': alpha}  # Create a dictionary with alpha\n",
    "print(f'Alpha {alpha}')\n",
    "_, _, ridge_oof_preds, _ = ridge_cv_pipeline(train_feats, test_feats, ridge_params, seed=42, n_repeats=n_repeats, n_splits=n_splits)\n",
    "                                        \n",
    "blend = pd.concat([oof_1, oof_2, ridge_oof_preds], axis=0)\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 1001\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'agg_tmp_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 548) (3, 547)\n",
      "LGBM Average RMSE over 100 folds: 0.606230\n",
      "Mean RMSE of all iterations: 0.618151\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'agg_tmp_feats'). RMSE: 0.606230, Improvement: -0.001916\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'at_by_bucket')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 515) (3, 514)\n",
      "LGBM Average RMSE over 100 folds: 0.606332\n",
      "Mean RMSE of all iterations: 0.617830\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'at_by_bucket'). RMSE: 0.606332, Improvement: -0.002018\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'action_time_gap')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 514) (3, 513)\n",
      "LGBM Average RMSE over 100 folds: 0.604629\n",
      "Mean RMSE of all iterations: 0.616935\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'action_time_gap'). RMSE: 0.604629, Improvement: -0.000315\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'at_by_activity')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 569) (3, 568)\n",
      "LGBM Average RMSE over 100 folds: 0.605037\n",
      "Mean RMSE of all iterations: 0.616824\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'at_by_activity'). RMSE: 0.605037, Improvement: -0.000723\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 533) (3, 532)\n",
      "LGBM Average RMSE over 100 folds: 0.605602\n",
      "Mean RMSE of all iterations: 0.617856\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'wc_chage'). RMSE: 0.605602, Improvement: -0.001288\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 512) (3, 511)\n",
      "LGBM Average RMSE over 100 folds: 0.605721\n",
      "Mean RMSE of all iterations: 0.618207\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'pause'). RMSE: 0.605721, Improvement: -0.001407\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 530) (3, 529)\n",
      "LGBM Average RMSE over 100 folds: 0.603996\n",
      "Mean RMSE of all iterations: 0.615913\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'count_vectorized'). RMSE: 0.603996, Improvement: 0.000318\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 506) (3, 505)\n",
      "LGBM Average RMSE over 100 folds: 0.604898\n",
      "Mean RMSE of all iterations: 0.616965\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'wpm_feats'). RMSE: 0.604898, Improvement: -0.000584\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 794) (3, 793)\n",
      "LGBM Average RMSE over 100 folds: 0.604932\n",
      "Mean RMSE of all iterations: 0.617197\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'count_vectorized_bigrams'). RMSE: 0.604932, Improvement: -0.000618\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 507) (3, 506)\n",
      "LGBM Average RMSE over 100 folds: 0.605695\n",
      "Mean RMSE of all iterations: 0.617869\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'IKI'). RMSE: 0.605695, Improvement: -0.001381\n",
      "Feature set: ('action_time_gap_by_acti', 'adj_eff_time', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 514) (3, 513)\n",
      "LGBM Average RMSE over 100 folds: 0.606516\n",
      "Mean RMSE of all iterations: 0.618229\n",
      "Features: ('action_time_gap_by_acti', 'adj_eff_time', 'rep_cut'). RMSE: 0.606516, Improvement: -0.002202\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'at_by_bucket')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 542) (3, 541)\n",
      "LGBM Average RMSE over 100 folds: 0.604723\n",
      "Mean RMSE of all iterations: 0.617080\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'at_by_bucket'). RMSE: 0.604723, Improvement: -0.000409\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'action_time_gap')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 541) (3, 540)\n",
      "LGBM Average RMSE over 100 folds: 0.605364\n",
      "Mean RMSE of all iterations: 0.617459\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'action_time_gap'). RMSE: 0.605364, Improvement: -0.001050\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'at_by_activity')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 596) (3, 595)\n",
      "LGBM Average RMSE over 100 folds: 0.605818\n",
      "Mean RMSE of all iterations: 0.618109\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'at_by_activity'). RMSE: 0.605818, Improvement: -0.001504\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 560) (3, 559)\n",
      "LGBM Average RMSE over 100 folds: 0.606347\n",
      "Mean RMSE of all iterations: 0.618446\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'wc_chage'). RMSE: 0.606347, Improvement: -0.002033\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 539) (3, 538)\n",
      "LGBM Average RMSE over 100 folds: 0.604803\n",
      "Mean RMSE of all iterations: 0.617413\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'pause'). RMSE: 0.604803, Improvement: -0.000489\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 557) (3, 556)\n",
      "LGBM Average RMSE over 100 folds: 0.603256\n",
      "Mean RMSE of all iterations: 0.615669\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'count_vectorized'). RMSE: 0.603256, Improvement: 0.001058\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 533) (3, 532)\n",
      "LGBM Average RMSE over 100 folds: 0.605685\n",
      "Mean RMSE of all iterations: 0.618204\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'wpm_feats'). RMSE: 0.605685, Improvement: -0.001371\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 821) (3, 820)\n",
      "LGBM Average RMSE over 100 folds: 0.604647\n",
      "Mean RMSE of all iterations: 0.617119\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'count_vectorized_bigrams'). RMSE: 0.604647, Improvement: -0.000333\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 534) (3, 533)\n",
      "LGBM Average RMSE over 100 folds: 0.606068\n",
      "Mean RMSE of all iterations: 0.617653\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'IKI'). RMSE: 0.606068, Improvement: -0.001754\n",
      "Feature set: ('action_time_gap_by_acti', 'agg_tmp_feats', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 541) (3, 540)\n",
      "LGBM Average RMSE over 100 folds: 0.605241\n",
      "Mean RMSE of all iterations: 0.617648\n",
      "Features: ('action_time_gap_by_acti', 'agg_tmp_feats', 'rep_cut'). RMSE: 0.605241, Improvement: -0.000927\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'action_time_gap')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 508) (3, 507)\n",
      "LGBM Average RMSE over 100 folds: 0.605114\n",
      "Mean RMSE of all iterations: 0.617047\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'action_time_gap'). RMSE: 0.605114, Improvement: -0.000800\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'at_by_activity')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 563) (3, 562)\n",
      "LGBM Average RMSE over 100 folds: 0.605253\n",
      "Mean RMSE of all iterations: 0.617196\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'at_by_activity'). RMSE: 0.605253, Improvement: -0.000939\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 527) (3, 526)\n",
      "LGBM Average RMSE over 100 folds: 0.605362\n",
      "Mean RMSE of all iterations: 0.617608\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'wc_chage'). RMSE: 0.605362, Improvement: -0.001048\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 506) (3, 505)\n",
      "LGBM Average RMSE over 100 folds: 0.605323\n",
      "Mean RMSE of all iterations: 0.618064\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'pause'). RMSE: 0.605323, Improvement: -0.001009\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 524) (3, 523)\n",
      "LGBM Average RMSE over 100 folds: 0.603177\n",
      "Mean RMSE of all iterations: 0.615008\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'count_vectorized'). RMSE: 0.603177, Improvement: 0.001137\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 500) (3, 499)\n",
      "LGBM Average RMSE over 100 folds: 0.606573\n",
      "Mean RMSE of all iterations: 0.618162\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'wpm_feats'). RMSE: 0.606573, Improvement: -0.002259\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 788) (3, 787)\n",
      "LGBM Average RMSE over 100 folds: 0.606523\n",
      "Mean RMSE of all iterations: 0.618317\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'count_vectorized_bigrams'). RMSE: 0.606523, Improvement: -0.002209\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 501) (3, 500)\n",
      "LGBM Average RMSE over 100 folds: 0.605950\n",
      "Mean RMSE of all iterations: 0.618026\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'IKI'). RMSE: 0.605950, Improvement: -0.001636\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_bucket', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 508) (3, 507)\n",
      "LGBM Average RMSE over 100 folds: 0.604978\n",
      "Mean RMSE of all iterations: 0.617568\n",
      "Features: ('action_time_gap_by_acti', 'at_by_bucket', 'rep_cut'). RMSE: 0.604978, Improvement: -0.000664\n",
      "Feature set: ('action_time_gap_by_acti', 'action_time_gap', 'at_by_activity')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 562) (3, 561)\n",
      "LGBM Average RMSE over 100 folds: 0.603629\n",
      "Mean RMSE of all iterations: 0.616075\n",
      "Features: ('action_time_gap_by_acti', 'action_time_gap', 'at_by_activity'). RMSE: 0.603629, Improvement: 0.000685\n",
      "Feature set: ('action_time_gap_by_acti', 'action_time_gap', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 526) (3, 525)\n",
      "LGBM Average RMSE over 100 folds: 0.604884\n",
      "Mean RMSE of all iterations: 0.616781\n",
      "Features: ('action_time_gap_by_acti', 'action_time_gap', 'wc_chage'). RMSE: 0.604884, Improvement: -0.000570\n",
      "Feature set: ('action_time_gap_by_acti', 'action_time_gap', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 505) (3, 504)\n",
      "LGBM Average RMSE over 100 folds: 0.605186\n",
      "Mean RMSE of all iterations: 0.617278\n",
      "Features: ('action_time_gap_by_acti', 'action_time_gap', 'pause'). RMSE: 0.605186, Improvement: -0.000872\n",
      "Feature set: ('action_time_gap_by_acti', 'action_time_gap', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 523) (3, 522)\n",
      "LGBM Average RMSE over 100 folds: 0.602328\n",
      "Mean RMSE of all iterations: 0.613977\n",
      "Features: ('action_time_gap_by_acti', 'action_time_gap', 'count_vectorized'). RMSE: 0.602328, Improvement: 0.001986\n",
      "Feature set: ('action_time_gap_by_acti', 'action_time_gap', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 499) (3, 498)\n",
      "LGBM Average RMSE over 100 folds: 0.605357\n",
      "Mean RMSE of all iterations: 0.616875\n",
      "Features: ('action_time_gap_by_acti', 'action_time_gap', 'wpm_feats'). RMSE: 0.605357, Improvement: -0.001043\n",
      "Feature set: ('action_time_gap_by_acti', 'action_time_gap', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 787) (3, 786)\n",
      "LGBM Average RMSE over 100 folds: 0.604645\n",
      "Mean RMSE of all iterations: 0.616674\n",
      "Features: ('action_time_gap_by_acti', 'action_time_gap', 'count_vectorized_bigrams'). RMSE: 0.604645, Improvement: -0.000331\n",
      "Feature set: ('action_time_gap_by_acti', 'action_time_gap', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 500) (3, 499)\n",
      "LGBM Average RMSE over 100 folds: 0.604291\n",
      "Mean RMSE of all iterations: 0.616788\n",
      "Features: ('action_time_gap_by_acti', 'action_time_gap', 'IKI'). RMSE: 0.604291, Improvement: 0.000023\n",
      "Feature set: ('action_time_gap_by_acti', 'action_time_gap', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 507) (3, 506)\n",
      "LGBM Average RMSE over 100 folds: 0.605133\n",
      "Mean RMSE of all iterations: 0.617348\n",
      "Features: ('action_time_gap_by_acti', 'action_time_gap', 'rep_cut'). RMSE: 0.605133, Improvement: -0.000819\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_activity', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 581) (3, 580)\n",
      "LGBM Average RMSE over 100 folds: 0.605086\n",
      "Mean RMSE of all iterations: 0.617147\n",
      "Features: ('action_time_gap_by_acti', 'at_by_activity', 'wc_chage'). RMSE: 0.605086, Improvement: -0.000772\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_activity', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 560) (3, 559)\n",
      "LGBM Average RMSE over 100 folds: 0.605587\n",
      "Mean RMSE of all iterations: 0.617581\n",
      "Features: ('action_time_gap_by_acti', 'at_by_activity', 'pause'). RMSE: 0.605587, Improvement: -0.001273\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_activity', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 578) (3, 577)\n",
      "LGBM Average RMSE over 100 folds: 0.603166\n",
      "Mean RMSE of all iterations: 0.615235\n",
      "Features: ('action_time_gap_by_acti', 'at_by_activity', 'count_vectorized'). RMSE: 0.603166, Improvement: 0.001148\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_activity', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 554) (3, 553)\n",
      "LGBM Average RMSE over 100 folds: 0.604721\n",
      "Mean RMSE of all iterations: 0.616924\n",
      "Features: ('action_time_gap_by_acti', 'at_by_activity', 'wpm_feats'). RMSE: 0.604721, Improvement: -0.000407\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_activity', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 842) (3, 841)\n",
      "LGBM Average RMSE over 100 folds: 0.605298\n",
      "Mean RMSE of all iterations: 0.617407\n",
      "Features: ('action_time_gap_by_acti', 'at_by_activity', 'count_vectorized_bigrams'). RMSE: 0.605298, Improvement: -0.000984\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_activity', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 555) (3, 554)\n",
      "LGBM Average RMSE over 100 folds: 0.605958\n",
      "Mean RMSE of all iterations: 0.618019\n",
      "Features: ('action_time_gap_by_acti', 'at_by_activity', 'IKI'). RMSE: 0.605958, Improvement: -0.001644\n",
      "Feature set: ('action_time_gap_by_acti', 'at_by_activity', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 562) (3, 561)\n",
      "LGBM Average RMSE over 100 folds: 0.605336\n",
      "Mean RMSE of all iterations: 0.617350\n",
      "Features: ('action_time_gap_by_acti', 'at_by_activity', 'rep_cut'). RMSE: 0.605336, Improvement: -0.001022\n",
      "Feature set: ('action_time_gap_by_acti', 'wc_chage', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 524) (3, 523)\n",
      "LGBM Average RMSE over 100 folds: 0.605011\n",
      "Mean RMSE of all iterations: 0.617682\n",
      "Features: ('action_time_gap_by_acti', 'wc_chage', 'pause'). RMSE: 0.605011, Improvement: -0.000697\n",
      "Feature set: ('action_time_gap_by_acti', 'wc_chage', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 542) (3, 541)\n",
      "LGBM Average RMSE over 100 folds: 0.602894\n",
      "Mean RMSE of all iterations: 0.615466\n",
      "Features: ('action_time_gap_by_acti', 'wc_chage', 'count_vectorized'). RMSE: 0.602894, Improvement: 0.001420\n",
      "Feature set: ('action_time_gap_by_acti', 'wc_chage', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 518) (3, 517)\n",
      "LGBM Average RMSE over 100 folds: 0.605741\n",
      "Mean RMSE of all iterations: 0.617758\n",
      "Features: ('action_time_gap_by_acti', 'wc_chage', 'wpm_feats'). RMSE: 0.605741, Improvement: -0.001427\n",
      "Feature set: ('action_time_gap_by_acti', 'wc_chage', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 806) (3, 805)\n",
      "LGBM Average RMSE over 100 folds: 0.605249\n",
      "Mean RMSE of all iterations: 0.617681\n",
      "Features: ('action_time_gap_by_acti', 'wc_chage', 'count_vectorized_bigrams'). RMSE: 0.605249, Improvement: -0.000935\n",
      "Feature set: ('action_time_gap_by_acti', 'wc_chage', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 519) (3, 518)\n",
      "LGBM Average RMSE over 100 folds: 0.605703\n",
      "Mean RMSE of all iterations: 0.617298\n",
      "Features: ('action_time_gap_by_acti', 'wc_chage', 'IKI'). RMSE: 0.605703, Improvement: -0.001389\n",
      "Feature set: ('action_time_gap_by_acti', 'wc_chage', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 526) (3, 525)\n",
      "LGBM Average RMSE over 100 folds: 0.605542\n",
      "Mean RMSE of all iterations: 0.617650\n",
      "Features: ('action_time_gap_by_acti', 'wc_chage', 'rep_cut'). RMSE: 0.605542, Improvement: -0.001228\n",
      "Feature set: ('action_time_gap_by_acti', 'pause', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 521) (3, 520)\n",
      "LGBM Average RMSE over 100 folds: 0.604933\n",
      "Mean RMSE of all iterations: 0.617096\n",
      "Features: ('action_time_gap_by_acti', 'pause', 'count_vectorized'). RMSE: 0.604933, Improvement: -0.000619\n",
      "Feature set: ('action_time_gap_by_acti', 'pause', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 497) (3, 496)\n",
      "LGBM Average RMSE over 100 folds: 0.605876\n",
      "Mean RMSE of all iterations: 0.617716\n",
      "Features: ('action_time_gap_by_acti', 'pause', 'wpm_feats'). RMSE: 0.605876, Improvement: -0.001562\n",
      "Feature set: ('action_time_gap_by_acti', 'pause', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 785) (3, 784)\n",
      "LGBM Average RMSE over 100 folds: 0.605053\n",
      "Mean RMSE of all iterations: 0.617721\n",
      "Features: ('action_time_gap_by_acti', 'pause', 'count_vectorized_bigrams'). RMSE: 0.605053, Improvement: -0.000739\n",
      "Feature set: ('action_time_gap_by_acti', 'pause', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 498) (3, 497)\n",
      "LGBM Average RMSE over 100 folds: 0.605077\n",
      "Mean RMSE of all iterations: 0.617169\n",
      "Features: ('action_time_gap_by_acti', 'pause', 'IKI'). RMSE: 0.605077, Improvement: -0.000763\n",
      "Feature set: ('action_time_gap_by_acti', 'pause', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 505) (3, 504)\n",
      "LGBM Average RMSE over 100 folds: 0.605769\n",
      "Mean RMSE of all iterations: 0.618065\n",
      "Features: ('action_time_gap_by_acti', 'pause', 'rep_cut'). RMSE: 0.605769, Improvement: -0.001455\n",
      "Feature set: ('action_time_gap_by_acti', 'count_vectorized', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 515) (3, 514)\n",
      "LGBM Average RMSE over 100 folds: 0.603934\n",
      "Mean RMSE of all iterations: 0.616133\n",
      "Features: ('action_time_gap_by_acti', 'count_vectorized', 'wpm_feats'). RMSE: 0.603934, Improvement: 0.000380\n",
      "Feature set: ('action_time_gap_by_acti', 'count_vectorized', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 803) (3, 802)\n",
      "LGBM Average RMSE over 100 folds: 0.605298\n",
      "Mean RMSE of all iterations: 0.617407\n",
      "Features: ('action_time_gap_by_acti', 'count_vectorized', 'count_vectorized_bigrams'). RMSE: 0.605298, Improvement: -0.000984\n",
      "Feature set: ('action_time_gap_by_acti', 'count_vectorized', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 516) (3, 515)\n",
      "LGBM Average RMSE over 100 folds: 0.602815\n",
      "Mean RMSE of all iterations: 0.615519\n",
      "Features: ('action_time_gap_by_acti', 'count_vectorized', 'IKI'). RMSE: 0.602815, Improvement: 0.001499\n",
      "Feature set: ('action_time_gap_by_acti', 'count_vectorized', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 523) (3, 522)\n",
      "LGBM Average RMSE over 100 folds: 0.601978\n",
      "Mean RMSE of all iterations: 0.614411\n",
      "Features: ('action_time_gap_by_acti', 'count_vectorized', 'rep_cut'). RMSE: 0.601978, Improvement: 0.002336\n",
      "Feature set: ('action_time_gap_by_acti', 'wpm_feats', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 779) (3, 778)\n",
      "LGBM Average RMSE over 100 folds: 0.604897\n",
      "Mean RMSE of all iterations: 0.617028\n",
      "Features: ('action_time_gap_by_acti', 'wpm_feats', 'count_vectorized_bigrams'). RMSE: 0.604897, Improvement: -0.000583\n",
      "Feature set: ('action_time_gap_by_acti', 'wpm_feats', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 492) (3, 491)\n",
      "LGBM Average RMSE over 100 folds: 0.606134\n",
      "Mean RMSE of all iterations: 0.617984\n",
      "Features: ('action_time_gap_by_acti', 'wpm_feats', 'IKI'). RMSE: 0.606134, Improvement: -0.001820\n",
      "Feature set: ('action_time_gap_by_acti', 'wpm_feats', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 499) (3, 498)\n",
      "LGBM Average RMSE over 100 folds: 0.604403\n",
      "Mean RMSE of all iterations: 0.617434\n",
      "Features: ('action_time_gap_by_acti', 'wpm_feats', 'rep_cut'). RMSE: 0.604403, Improvement: -0.000089\n",
      "Feature set: ('action_time_gap_by_acti', 'count_vectorized_bigrams', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 780) (3, 779)\n",
      "LGBM Average RMSE over 100 folds: 0.604505\n",
      "Mean RMSE of all iterations: 0.616949\n",
      "Features: ('action_time_gap_by_acti', 'count_vectorized_bigrams', 'IKI'). RMSE: 0.604505, Improvement: -0.000191\n",
      "Feature set: ('action_time_gap_by_acti', 'count_vectorized_bigrams', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 787) (3, 786)\n",
      "LGBM Average RMSE over 100 folds: 0.604895\n",
      "Mean RMSE of all iterations: 0.616957\n",
      "Features: ('action_time_gap_by_acti', 'count_vectorized_bigrams', 'rep_cut'). RMSE: 0.604895, Improvement: -0.000581\n",
      "Feature set: ('action_time_gap_by_acti', 'IKI', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 500) (3, 499)\n",
      "LGBM Average RMSE over 100 folds: 0.605091\n",
      "Mean RMSE of all iterations: 0.617630\n",
      "Features: ('action_time_gap_by_acti', 'IKI', 'rep_cut'). RMSE: 0.605091, Improvement: -0.000777\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'at_by_bucket')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 494) (3, 493)\n",
      "LGBM Average RMSE over 100 folds: 0.606689\n",
      "Mean RMSE of all iterations: 0.618964\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'at_by_bucket'). RMSE: 0.606689, Improvement: -0.002375\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'action_time_gap')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 493) (3, 492)\n",
      "LGBM Average RMSE over 100 folds: 0.604095\n",
      "Mean RMSE of all iterations: 0.615778\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'action_time_gap'). RMSE: 0.604095, Improvement: 0.000219\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'at_by_activity')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 548) (3, 547)\n",
      "LGBM Average RMSE over 100 folds: 0.605885\n",
      "Mean RMSE of all iterations: 0.617683\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'at_by_activity'). RMSE: 0.605885, Improvement: -0.001571\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 512) (3, 511)\n",
      "LGBM Average RMSE over 100 folds: 0.605822\n",
      "Mean RMSE of all iterations: 0.617998\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'wc_chage'). RMSE: 0.605822, Improvement: -0.001508\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 491) (3, 490)\n",
      "LGBM Average RMSE over 100 folds: 0.606517\n",
      "Mean RMSE of all iterations: 0.618675\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'pause'). RMSE: 0.606517, Improvement: -0.002203\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 509) (3, 508)\n",
      "LGBM Average RMSE over 100 folds: 0.604385\n",
      "Mean RMSE of all iterations: 0.616674\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'count_vectorized'). RMSE: 0.604385, Improvement: -0.000071\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 485) (3, 484)\n",
      "LGBM Average RMSE over 100 folds: 0.606495\n",
      "Mean RMSE of all iterations: 0.617755\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'wpm_feats'). RMSE: 0.606495, Improvement: -0.002181\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 773) (3, 772)\n",
      "LGBM Average RMSE over 100 folds: 0.604571\n",
      "Mean RMSE of all iterations: 0.616755\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'count_vectorized_bigrams'). RMSE: 0.604571, Improvement: -0.000257\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 486) (3, 485)\n",
      "LGBM Average RMSE over 100 folds: 0.605510\n",
      "Mean RMSE of all iterations: 0.617397\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'IKI'). RMSE: 0.605510, Improvement: -0.001196\n",
      "Feature set: ('adj_eff_time', 'agg_tmp_feats', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 493) (3, 492)\n",
      "LGBM Average RMSE over 100 folds: 0.607587\n",
      "Mean RMSE of all iterations: 0.619060\n",
      "Features: ('adj_eff_time', 'agg_tmp_feats', 'rep_cut'). RMSE: 0.607587, Improvement: -0.003273\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'action_time_gap')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 460) (3, 459)\n",
      "LGBM Average RMSE over 100 folds: 0.604889\n",
      "Mean RMSE of all iterations: 0.616401\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'action_time_gap'). RMSE: 0.604889, Improvement: -0.000575\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'at_by_activity')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 515) (3, 514)\n",
      "LGBM Average RMSE over 100 folds: 0.606385\n",
      "Mean RMSE of all iterations: 0.617748\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'at_by_activity'). RMSE: 0.606385, Improvement: -0.002071\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 479) (3, 478)\n",
      "LGBM Average RMSE over 100 folds: 0.606272\n",
      "Mean RMSE of all iterations: 0.618137\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'wc_chage'). RMSE: 0.606272, Improvement: -0.001958\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 458) (3, 457)\n",
      "LGBM Average RMSE over 100 folds: 0.606694\n",
      "Mean RMSE of all iterations: 0.618165\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'pause'). RMSE: 0.606694, Improvement: -0.002380\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 476) (3, 475)\n",
      "LGBM Average RMSE over 100 folds: 0.604547\n",
      "Mean RMSE of all iterations: 0.616399\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'count_vectorized'). RMSE: 0.604547, Improvement: -0.000233\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 452) (3, 451)\n",
      "LGBM Average RMSE over 100 folds: 0.606807\n",
      "Mean RMSE of all iterations: 0.618361\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'wpm_feats'). RMSE: 0.606807, Improvement: -0.002493\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 740) (3, 739)\n",
      "LGBM Average RMSE over 100 folds: 0.604996\n",
      "Mean RMSE of all iterations: 0.617241\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'count_vectorized_bigrams'). RMSE: 0.604996, Improvement: -0.000682\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 453) (3, 452)\n",
      "LGBM Average RMSE over 100 folds: 0.605536\n",
      "Mean RMSE of all iterations: 0.617434\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'IKI'). RMSE: 0.605536, Improvement: -0.001222\n",
      "Feature set: ('adj_eff_time', 'at_by_bucket', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 460) (3, 459)\n",
      "LGBM Average RMSE over 100 folds: 0.605211\n",
      "Mean RMSE of all iterations: 0.617199\n",
      "Features: ('adj_eff_time', 'at_by_bucket', 'rep_cut'). RMSE: 0.605211, Improvement: -0.000897\n",
      "Feature set: ('adj_eff_time', 'action_time_gap', 'at_by_activity')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 514) (3, 513)\n",
      "LGBM Average RMSE over 100 folds: 0.604504\n",
      "Mean RMSE of all iterations: 0.616288\n",
      "Features: ('adj_eff_time', 'action_time_gap', 'at_by_activity'). RMSE: 0.604504, Improvement: -0.000190\n",
      "Feature set: ('adj_eff_time', 'action_time_gap', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 478) (3, 477)\n",
      "LGBM Average RMSE over 100 folds: 0.605056\n",
      "Mean RMSE of all iterations: 0.616566\n",
      "Features: ('adj_eff_time', 'action_time_gap', 'wc_chage'). RMSE: 0.605056, Improvement: -0.000742\n",
      "Feature set: ('adj_eff_time', 'action_time_gap', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 457) (3, 456)\n",
      "LGBM Average RMSE over 100 folds: 0.604398\n",
      "Mean RMSE of all iterations: 0.616941\n",
      "Features: ('adj_eff_time', 'action_time_gap', 'pause'). RMSE: 0.604398, Improvement: -0.000084\n",
      "Feature set: ('adj_eff_time', 'action_time_gap', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 475) (3, 474)\n",
      "LGBM Average RMSE over 100 folds: 0.603631\n",
      "Mean RMSE of all iterations: 0.614932\n",
      "Features: ('adj_eff_time', 'action_time_gap', 'count_vectorized'). RMSE: 0.603631, Improvement: 0.000683\n",
      "Feature set: ('adj_eff_time', 'action_time_gap', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 451) (3, 450)\n",
      "LGBM Average RMSE over 100 folds: 0.604785\n",
      "Mean RMSE of all iterations: 0.616635\n",
      "Features: ('adj_eff_time', 'action_time_gap', 'wpm_feats'). RMSE: 0.604785, Improvement: -0.000471\n",
      "Feature set: ('adj_eff_time', 'action_time_gap', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 739) (3, 738)\n",
      "LGBM Average RMSE over 100 folds: 0.603854\n",
      "Mean RMSE of all iterations: 0.615694\n",
      "Features: ('adj_eff_time', 'action_time_gap', 'count_vectorized_bigrams'). RMSE: 0.603854, Improvement: 0.000460\n",
      "Feature set: ('adj_eff_time', 'action_time_gap', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 452) (3, 451)\n",
      "LGBM Average RMSE over 100 folds: 0.604722\n",
      "Mean RMSE of all iterations: 0.616446\n",
      "Features: ('adj_eff_time', 'action_time_gap', 'IKI'). RMSE: 0.604722, Improvement: -0.000408\n",
      "Feature set: ('adj_eff_time', 'action_time_gap', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 459) (3, 458)\n",
      "LGBM Average RMSE over 100 folds: 0.605331\n",
      "Mean RMSE of all iterations: 0.617186\n",
      "Features: ('adj_eff_time', 'action_time_gap', 'rep_cut'). RMSE: 0.605331, Improvement: -0.001017\n",
      "Feature set: ('adj_eff_time', 'at_by_activity', 'wc_chage')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 533) (3, 532)\n",
      "LGBM Average RMSE over 100 folds: 0.605800\n",
      "Mean RMSE of all iterations: 0.617236\n",
      "Features: ('adj_eff_time', 'at_by_activity', 'wc_chage'). RMSE: 0.605800, Improvement: -0.001486\n",
      "Feature set: ('adj_eff_time', 'at_by_activity', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 512) (3, 511)\n",
      "LGBM Average RMSE over 100 folds: 0.606843\n",
      "Mean RMSE of all iterations: 0.618554\n",
      "Features: ('adj_eff_time', 'at_by_activity', 'pause'). RMSE: 0.606843, Improvement: -0.002529\n",
      "Feature set: ('adj_eff_time', 'at_by_activity', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 530) (3, 529)\n",
      "LGBM Average RMSE over 100 folds: 0.605139\n",
      "Mean RMSE of all iterations: 0.616823\n",
      "Features: ('adj_eff_time', 'at_by_activity', 'count_vectorized'). RMSE: 0.605139, Improvement: -0.000825\n",
      "Feature set: ('adj_eff_time', 'at_by_activity', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 506) (3, 505)\n",
      "LGBM Average RMSE over 100 folds: 0.606246\n",
      "Mean RMSE of all iterations: 0.618499\n",
      "Features: ('adj_eff_time', 'at_by_activity', 'wpm_feats'). RMSE: 0.606246, Improvement: -0.001932\n",
      "Feature set: ('adj_eff_time', 'at_by_activity', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 794) (3, 793)\n",
      "LGBM Average RMSE over 100 folds: 0.605159\n",
      "Mean RMSE of all iterations: 0.616742\n",
      "Features: ('adj_eff_time', 'at_by_activity', 'count_vectorized_bigrams'). RMSE: 0.605159, Improvement: -0.000845\n",
      "Feature set: ('adj_eff_time', 'at_by_activity', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 507) (3, 506)\n",
      "LGBM Average RMSE over 100 folds: 0.605710\n",
      "Mean RMSE of all iterations: 0.617451\n",
      "Features: ('adj_eff_time', 'at_by_activity', 'IKI'). RMSE: 0.605710, Improvement: -0.001396\n",
      "Feature set: ('adj_eff_time', 'at_by_activity', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 514) (3, 513)\n",
      "LGBM Average RMSE over 100 folds: 0.604843\n",
      "Mean RMSE of all iterations: 0.617184\n",
      "Features: ('adj_eff_time', 'at_by_activity', 'rep_cut'). RMSE: 0.604843, Improvement: -0.000529\n",
      "Feature set: ('adj_eff_time', 'wc_chage', 'pause')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 476) (3, 475)\n",
      "LGBM Average RMSE over 100 folds: 0.606646\n",
      "Mean RMSE of all iterations: 0.618386\n",
      "Features: ('adj_eff_time', 'wc_chage', 'pause'). RMSE: 0.606646, Improvement: -0.002332\n",
      "Feature set: ('adj_eff_time', 'wc_chage', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 494) (3, 493)\n",
      "LGBM Average RMSE over 100 folds: 0.603825\n",
      "Mean RMSE of all iterations: 0.615995\n",
      "Features: ('adj_eff_time', 'wc_chage', 'count_vectorized'). RMSE: 0.603825, Improvement: 0.000489\n",
      "Feature set: ('adj_eff_time', 'wc_chage', 'wpm_feats')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 470) (3, 469)\n",
      "LGBM Average RMSE over 100 folds: 0.605943\n",
      "Mean RMSE of all iterations: 0.617454\n",
      "Features: ('adj_eff_time', 'wc_chage', 'wpm_feats'). RMSE: 0.605943, Improvement: -0.001629\n",
      "Feature set: ('adj_eff_time', 'wc_chage', 'count_vectorized_bigrams')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 758) (3, 757)\n",
      "LGBM Average RMSE over 100 folds: 0.604810\n",
      "Mean RMSE of all iterations: 0.617142\n",
      "Features: ('adj_eff_time', 'wc_chage', 'count_vectorized_bigrams'). RMSE: 0.604810, Improvement: -0.000496\n",
      "Feature set: ('adj_eff_time', 'wc_chage', 'IKI')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 471) (3, 470)\n",
      "LGBM Average RMSE over 100 folds: 0.606194\n",
      "Mean RMSE of all iterations: 0.617927\n",
      "Features: ('adj_eff_time', 'wc_chage', 'IKI'). RMSE: 0.606194, Improvement: -0.001880\n",
      "Feature set: ('adj_eff_time', 'wc_chage', 'rep_cut')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 478) (3, 477)\n",
      "LGBM Average RMSE over 100 folds: 0.604834\n",
      "Mean RMSE of all iterations: 0.617293\n",
      "Features: ('adj_eff_time', 'wc_chage', 'rep_cut'). RMSE: 0.604834, Improvement: -0.000520\n",
      "Feature set: ('adj_eff_time', 'pause', 'count_vectorized')\n",
      "Base train size: (2471, 419)\n",
      "(2471, 473) (3, 472)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m max_combination_length \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m \u001b[39m# You can adjust this to test different combination lengths\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m min_combination_length \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m results_comb \u001b[39m=\u001b[39m compare_feature_combinations(base_dir\u001b[39m=\u001b[39;49mFEATURE_STORE, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m                                        base_train_feats\u001b[39m=\u001b[39;49mtrain_feats,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m                                        base_test_feats\u001b[39m=\u001b[39;49mtest_feats,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m                                        params \u001b[39m=\u001b[39;49m params,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m                                        baseline_metrics\u001b[39m=\u001b[39;49m\u001b[39m0.604314\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m                                        max_combination_length\u001b[39m=\u001b[39;49mmax_combination_length,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m                                        min_combination_length\u001b[39m=\u001b[39;49mmin_combination_length)\n",
      "File \u001b[0;32m~/Projects/Kaggle/linking-writing/m7_utils.py:185\u001b[0m, in \u001b[0;36mcompare_feature_combinations\u001b[0;34m(base_dir, base_train_feats, base_test_feats, params, baseline_metrics, seed, n_repeats, n_splits, max_combination_length, min_combination_length)\u001b[0m\n\u001b[1;32m    182\u001b[0m test_feats\u001b[39m.\u001b[39mreplace([np\u001b[39m.\u001b[39minf, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf], np\u001b[39m.\u001b[39mnan, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    183\u001b[0m \u001b[39mprint\u001b[39m(train_feats\u001b[39m.\u001b[39mshape, test_feats\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 185\u001b[0m _, oof_preds, rmse, _ \u001b[39m=\u001b[39m cv_pipeline(train_feats, test_feats, params, seed, n_repeats, n_splits)\n\u001b[1;32m    186\u001b[0m improvement \u001b[39m=\u001b[39m baseline_metrics \u001b[39m-\u001b[39m rmse\n\u001b[1;32m    187\u001b[0m results\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mFeature Combination\u001b[39m\u001b[39m'\u001b[39m: combo, \u001b[39m'\u001b[39m\u001b[39mMetric\u001b[39m\u001b[39m'\u001b[39m: rmse, \u001b[39m'\u001b[39m\u001b[39mImprovement\u001b[39m\u001b[39m'\u001b[39m: improvement})\n",
      "File \u001b[0;32m~/Projects/Kaggle/linking-writing/m5_models.py:85\u001b[0m, in \u001b[0;36mcv_pipeline\u001b[0;34m(train_feats, test_feats, lgb_params, boosting_type, seed, n_repeats, n_splits)\u001b[0m\n\u001b[1;32m     81\u001b[0m missing_cols_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({col: np\u001b[39m.\u001b[39mnan \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m missing_cols}, index\u001b[39m=\u001b[39mtest_feats\u001b[39m.\u001b[39mindex)\n\u001b[1;32m     82\u001b[0m test_feats \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([test_feats, missing_cols_df], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m test_preds, oof_preds, rmse, model \u001b[39m=\u001b[39m run_lgb_cv(train_feats\u001b[39m=\u001b[39;49mtrain_feats, test_feats\u001b[39m=\u001b[39;49mtest_feats, \n\u001b[1;32m     86\u001b[0m                                          train_cols\u001b[39m=\u001b[39;49mtrain_cols, target_col\u001b[39m=\u001b[39;49mtarget_col, \n\u001b[1;32m     87\u001b[0m                                          lgb_params\u001b[39m=\u001b[39;49mlgb_params, boosting_type\u001b[39m=\u001b[39;49mboosting_type,\n\u001b[1;32m     88\u001b[0m                                          seed\u001b[39m=\u001b[39;49mseed, n_repeats\u001b[39m=\u001b[39;49mn_repeats, n_splits\u001b[39m=\u001b[39;49mn_splits)\n\u001b[1;32m     90\u001b[0m rmse_per_iteration \u001b[39m=\u001b[39m oof_preds\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39miteration\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mapply(calculate_rmse)\n\u001b[1;32m     91\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMean RMSE of all iterations: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(rmse_per_iteration)\u001b[39m:\u001b[39;00m\u001b[39m.6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/Kaggle/linking-writing/m5_models.py:33\u001b[0m, in \u001b[0;36mrun_lgb_cv\u001b[0;34m(train_feats, test_feats, train_cols, target_col, lgb_params, boosting_type, seed, n_repeats, n_splits)\u001b[0m\n\u001b[1;32m     31\u001b[0m model \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mLGBMRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlgb_params, verbose\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39mseed)\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m boosting_type \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdart\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[1;32m     34\u001b[0m             eval_set\u001b[39m=\u001b[39;49m[(X_valid, y_valid)], \n\u001b[1;32m     35\u001b[0m             callbacks\u001b[39m=\u001b[39;49m[lgb\u001b[39m.\u001b[39;49mearly_stopping(\u001b[39m250\u001b[39;49m, first_metric_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)])\n\u001b[1;32m     36\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)  \u001b[39m# No early stopping for DART\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1034\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     init_model: Optional[Union[\u001b[39mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLGBMRegressor\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1048\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1049\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1050\u001b[0m         X,\n\u001b[1;32m   1051\u001b[0m         y,\n\u001b[1;32m   1052\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1053\u001b[0m         init_score\u001b[39m=\u001b[39;49minit_score,\n\u001b[1;32m   1054\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1055\u001b[0m         eval_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[1;32m   1056\u001b[0m         eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[1;32m   1057\u001b[0m         eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[1;32m   1058\u001b[0m         eval_metric\u001b[39m=\u001b[39;49meval_metric,\n\u001b[1;32m   1059\u001b[0m         feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m   1060\u001b[0m         categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[1;32m   1061\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1062\u001b[0m         init_model\u001b[39m=\u001b[39;49minit_model\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1064\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/lightgbm/sklearn.py:842\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    839\u001b[0m evals_result: _EvalResultDict \u001b[39m=\u001b[39m {}\n\u001b[1;32m    840\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 842\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m    843\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    844\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[1;32m    845\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[1;32m    846\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[1;32m    847\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[1;32m    848\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    849\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[1;32m    850\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m    851\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[1;32m    852\u001b[0m )\n\u001b[1;32m    854\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n\u001b[1;32m    855\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_best_iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster\u001b[39m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[39m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/lightgbm/basic.py:3658\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3657\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3658\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle,\n\u001b[1;32m   3660\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3662\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LGBM Average RMSE over 50 folds: 0.603452\n",
    "# Features: ('action_time_gap_by_acti', 'action_time_gap').\n",
    "\n",
    "INPUT_DIR = 'kaggle/input/linking-writing-processes-to-writing-quality'\n",
    "FEATURE_STORE = 'feature_store'\n",
    "train_scores = pd.read_csv(f'{INPUT_DIR}/train_scores.csv')\n",
    "# train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_1.pkl')\n",
    "# test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_1.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on=['id'], how='left')\n",
    "# Usage\n",
    "max_combination_length = 4 # You can adjust this to test different combination lengths\n",
    "min_combination_length = 3\n",
    "results_comb = compare_feature_combinations(base_dir=FEATURE_STORE, \n",
    "                                       base_train_feats=train_feats,\n",
    "                                       base_test_feats=test_feats,\n",
    "                                       params = params,\n",
    "                                       baseline_metrics=0.604314,\n",
    "                                       max_combination_length=max_combination_length,\n",
    "                                       min_combination_length=min_combination_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Combination</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>(count_vectorized, action_time_gap, wpm_feats)</td>\n",
       "      <td>0.601765</td>\n",
       "      <td>0.002549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>(count_vectorized, action_time_gap, pause)</td>\n",
       "      <td>0.601846</td>\n",
       "      <td>0.002468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>(count_vectorized, rep_cut, action_time_gap_by...</td>\n",
       "      <td>0.601978</td>\n",
       "      <td>0.002336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(at_by_activity, count_vectorized_bigrams, act...</td>\n",
       "      <td>0.602142</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(count_vectorized_bigrams, action_time_gap)</td>\n",
       "      <td>0.602142</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>(count_vectorized_bigrams, count_vectorized, a...</td>\n",
       "      <td>0.602142</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature Combination    Metric  Improvement\n",
       "245     (count_vectorized, action_time_gap, wpm_feats)  0.601765     0.002549\n",
       "244         (count_vectorized, action_time_gap, pause)  0.601846     0.002468\n",
       "272  (count_vectorized, rep_cut, action_time_gap_by...  0.601978     0.002336\n",
       "90   (at_by_activity, count_vectorized_bigrams, act...  0.602142     0.002172\n",
       "24         (count_vectorized_bigrams, action_time_gap)  0.602142     0.002172\n",
       "199  (count_vectorized_bigrams, count_vectorized, a...  0.602142     0.002172"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_comb.sort_values('Metric').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Set</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_vectorized</td>\n",
       "      <td>0.602782</td>\n",
       "      <td>0.001532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>action_time_gap</td>\n",
       "      <td>0.604004</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rep_cut</td>\n",
       "      <td>0.604101</td>\n",
       "      <td>0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>action_time_gap_by_acti</td>\n",
       "      <td>0.604244</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IKI</td>\n",
       "      <td>0.604575</td>\n",
       "      <td>-0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at_by_bucket</td>\n",
       "      <td>0.605283</td>\n",
       "      <td>-0.000969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wpm_feats</td>\n",
       "      <td>0.605465</td>\n",
       "      <td>-0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wc_chage</td>\n",
       "      <td>0.605597</td>\n",
       "      <td>-0.001283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adj_eff_time</td>\n",
       "      <td>0.605755</td>\n",
       "      <td>-0.001441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature Set    Metric  Improvement\n",
       "6         count_vectorized  0.602782     0.001532\n",
       "1          action_time_gap  0.604004     0.000310\n",
       "2                  rep_cut  0.604101     0.000213\n",
       "8  action_time_gap_by_acti  0.604244     0.000070\n",
       "7                      IKI  0.604575    -0.000261\n",
       "3             at_by_bucket  0.605283    -0.000969\n",
       "5                wpm_feats  0.605465    -0.001151\n",
       "4                 wc_chage  0.605597    -0.001283\n",
       "0             adj_eff_time  0.605755    -0.001441"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('Improvement', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Combination</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>(count_vectorized, action_time_gap, wpm_feats)</td>\n",
       "      <td>0.601765</td>\n",
       "      <td>0.002549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>(count_vectorized, action_time_gap, pause)</td>\n",
       "      <td>0.601846</td>\n",
       "      <td>0.002468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>(count_vectorized, rep_cut, action_time_gap_by...</td>\n",
       "      <td>0.601978</td>\n",
       "      <td>0.002336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(at_by_activity, count_vectorized_bigrams, act...</td>\n",
       "      <td>0.602142</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(count_vectorized_bigrams, action_time_gap)</td>\n",
       "      <td>0.602142</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>(count_vectorized_bigrams, count_vectorized, a...</td>\n",
       "      <td>0.602142</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature Combination    Metric  Improvement\n",
       "245     (count_vectorized, action_time_gap, wpm_feats)  0.601765     0.002549\n",
       "244         (count_vectorized, action_time_gap, pause)  0.601846     0.002468\n",
       "272  (count_vectorized, rep_cut, action_time_gap_by...  0.601978     0.002336\n",
       "90   (at_by_activity, count_vectorized_bigrams, act...  0.602142     0.002172\n",
       "24         (count_vectorized_bigrams, action_time_gap)  0.602142     0.002172\n",
       "199  (count_vectorized_bigrams, count_vectorized, a...  0.602142     0.002172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combinations of 3\n",
    "results_comb.sort_values('Metric').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.612893\n"
     ]
    }
   ],
   "source": [
    "best_params = {'reg_alpha': 0.007678095440286993, \n",
    "               'reg_lambda': 0.34230534302168353, \n",
    "               'colsample_bytree': 0.627061253588415, \n",
    "               'subsample': 0.854942238828458, \n",
    "               'learning_rate': 0.038697981947473245, \n",
    "               'num_leaves': 22, \n",
    "               'max_depth': 37, \n",
    "               'min_child_samples': 18}\n",
    "\n",
    "n_repeats = 5\n",
    "n_splits = 10\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')    \n",
    "#train_feats, test_feats = countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)\n",
    "\n",
    "_, oof_2, rmse, model1 = cv_pipeline(train_feats, test_feats, best_params, 'gbdt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 5/5 [06:05<00:00, 73.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Average RMSE over 30 folds: 0.607183\n",
      "LGBM Average RMSE over 50 folds: 0.604164\n",
      "Blend RMSE 0.603108\n"
     ]
    }
   ],
   "source": [
    "from m3_model_params import lgb_params_1, xgb_params_2\n",
    "\n",
    "n_repeats = 5\n",
    "n_splits = 6\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "#train_feats, test_feats = countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)\n",
    "_, oof_1, rmse, model1 = xgb_cv_pipeline(train_feats=train_feats, \n",
    "                                        test_feats=test_feats, \n",
    "                                        xgb_params=xgb_params_2, \n",
    "                                        seed=seed, \n",
    "                                        n_repeats=n_repeats, \n",
    "                                        n_splits=n_splits)\n",
    "                                        \n",
    "_, oof_2, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_2, lgb_params_1['boosting_type'])\n",
    "\n",
    "blend = pd.concat([oof_1, oof_2], axis=0)\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feats_1 - No countvectorizer\n",
    "XGB Average RMSE over 30 folds: 0.605292\n",
    "LGBM Average RMSE over 50 folds: 0.605479\n",
    "Blend RMSE 0.603148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = pd.read_csv('params.csv')\n",
    "params_df = params_df.head(2)\n",
    "params_df['params'] = params_df['params'].apply(ast.literal_eval)\n",
    "\n",
    "for i in range(2):\n",
    "    params = params_df.loc[i]['params']\n",
    "    params.pop('verbose')\n",
    "    params.pop('random_state')\n",
    "    params['n_estimators'] = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 0/5 [00:00<?, ?it/s]/root/miniconda3/envs/lrp/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [20:59:34] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "Iterations: 100%|██████████| 5/5 [01:46<00:00, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Average RMSE over 50 folds: 0.601289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "_, oof_1, rmse, model1 = xgb_cv_pipeline(train_feats=train_feats, \n",
    "                                        test_feats=test_feats, \n",
    "                                        xgb_params=xgb_params_2, \n",
    "                                        seed=seed, \n",
    "                                        n_repeats=n_repeats, \n",
    "                                        n_splits=n_splits)\n",
    "\n",
    "_, oof_2, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_2, lgb_params_1['boosting_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend RMSE 0.600613\n"
     ]
    }
   ],
   "source": [
    "blend = pd.concat([oof_2, oof_4], axis=0)\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:04<00:00, 523.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2966.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.602144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 0/5 [00:00<?, ?it/s]/root/miniconda3/envs/lrp/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [00:20:21] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "Iterations: 100%|██████████| 5/5 [06:53<00:00, 82.64s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Average RMSE over 50 folds: 0.604448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:05<00:00, 487.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2452.81it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['score'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m test_feats \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\u001b[39m'\u001b[39m\u001b[39mfeature_store/base_feats/test_base_feats_2.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m train_feats, test_feats \u001b[39m=\u001b[39m countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m _, oof_4, rmse, model1 \u001b[39m=\u001b[39m cv_pipeline(train_feats, test_feats, lgb_params_1, lgb_params_1[\u001b[39m'\u001b[39;49m\u001b[39mboosting_type\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m _, oof_2, rmse, model1 \u001b[39m=\u001b[39m xgb_cv_pipeline(train_feats\u001b[39m=\u001b[39mtrain_feats, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m                                         test_feats\u001b[39m=\u001b[39mtest_feats, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m                                         xgb_params\u001b[39m=\u001b[39mxgb_params, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m                                         seed\u001b[39m=\u001b[39mseed, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                                         n_repeats\u001b[39m=\u001b[39mn_repeats, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                                         n_splits\u001b[39m=\u001b[39mn_splits)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/SPF_experiments.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m blend \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([oof_1, oof_2, oof_3, oof_4], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/Kaggle/linking-writing/m5_models.py:77\u001b[0m, in \u001b[0;36mcv_pipeline\u001b[0;34m(train_feats, test_feats, lgb_params, boosting_type, seed, n_repeats, n_splits)\u001b[0m\n\u001b[1;32m     74\u001b[0m train_feats\u001b[39m.\u001b[39mreplace([np\u001b[39m.\u001b[39minf, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf], np\u001b[39m.\u001b[39mnan, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     75\u001b[0m test_feats\u001b[39m.\u001b[39mreplace([np\u001b[39m.\u001b[39minf, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf], np\u001b[39m.\u001b[39mnan, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 77\u001b[0m test_preds, oof_preds, rmse, model \u001b[39m=\u001b[39m run_lgb_cv(train_feats\u001b[39m=\u001b[39;49mtrain_feats, test_feats\u001b[39m=\u001b[39;49mtest_feats, \n\u001b[1;32m     78\u001b[0m                                          train_cols\u001b[39m=\u001b[39;49mtrain_cols, target_col\u001b[39m=\u001b[39;49mtarget_col, \n\u001b[1;32m     79\u001b[0m                                          lgb_params\u001b[39m=\u001b[39;49mlgb_params, boosting_type\u001b[39m=\u001b[39;49mboosting_type,\n\u001b[1;32m     80\u001b[0m                                          seed\u001b[39m=\u001b[39;49mseed, n_repeats\u001b[39m=\u001b[39;49mn_repeats, n_splits\u001b[39m=\u001b[39;49mn_splits)\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m test_preds, oof_preds, rmse, model\n",
      "File \u001b[0;32m~/Projects/Kaggle/linking-writing/m5_models.py:36\u001b[0m, in \u001b[0;36mrun_lgb_cv\u001b[0;34m(train_feats, test_feats, train_cols, target_col, lgb_params, boosting_type, seed, n_repeats, n_splits)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_lgb_cv\u001b[39m(train_feats, test_feats, train_cols, target_col, lgb_params, boosting_type, seed, n_repeats, n_splits):\n\u001b[1;32m     35\u001b[0m     oof_results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 36\u001b[0m     binned_y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdigitize(train_feats[target_col], bins\u001b[39m=\u001b[39m\u001b[39msorted\u001b[39m(train_feats[target_col]\u001b[39m.\u001b[39mvalue_counts()))\n\u001b[1;32m     38\u001b[0m     X \u001b[39m=\u001b[39m train_feats[train_cols]\n\u001b[1;32m     39\u001b[0m     y \u001b[39m=\u001b[39m train_feats[target_col]\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['score'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "lgb_params_1 = params_df.loc[0]['params']\n",
    "lgb_params_2 = params_df.loc[0]['params']\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_1.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_1.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "train_feats, test_feats = countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)\n",
    "_, oof_3, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_1, lgb_params_1['boosting_type'])\n",
    "_, oof_1, rmse, model1 = xgb_cv_pipeline(train_feats=train_feats, \n",
    "                                        test_feats=test_feats, \n",
    "                                        xgb_params=xgb_params, \n",
    "                                        seed=seed, \n",
    "                                        n_repeats=n_repeats, \n",
    "                                        n_splits=n_splits)\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "train_feats, test_feats = countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)\n",
    "_, oof_4, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_1, lgb_params_1['boosting_type'])\n",
    "\n",
    "\n",
    "blend = pd.concat([oof_1, oof_2, oof_3, oof_4], axis=0)\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:04<00:00, 521.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1652.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.601574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 5/5 [02:51<00:00, 34.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Average RMSE over 50 folds: 0.603451\n",
      "Blend RMSE 0.601227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### TO DELETE\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "train_feats, test_feats = countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)\n",
    "_, oof_4, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_1, lgb_params_1['boosting_type'])\n",
    "_, oof_2, rmse, model1 = xgb_cv_pipeline(train_feats=train_feats, \n",
    "                                        test_feats=test_feats, \n",
    "                                        xgb_params=xgb_params, \n",
    "                                        seed=seed, \n",
    "                                        n_repeats=n_repeats, \n",
    "                                        n_splits=n_splits)\n",
    "\n",
    "\n",
    "blend = pd.concat([oof_1, oof_2, oof_3, oof_4], axis=0)\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.602618\n",
      "Blend RMSE 0.600350\n"
     ]
    }
   ],
   "source": [
    "from m3_model_params import lgb_params_1\n",
    "_, oof_5, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_1, lgb_params_1['boosting_type'])\n",
    "\n",
    "blend = pd.concat([oof_4, oof_3, oof_5], axis=0) # , oof_3, oof_4, oof_5, oof_6\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.603961\n",
      "LGBM Average RMSE over 50 folds: 0.604117\n",
      "LGBM Average RMSE over 50 folds: 0.604946\n"
     ]
    }
   ],
   "source": [
    "# TEST HYPERPARAMS from search .csv\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_1.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_1.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "params_df = pd.read_csv('params.csv')\n",
    "params_df['params'] = params_df['params'].apply(ast.literal_eval)\n",
    "\n",
    "for i in range(3):\n",
    "    params = params_df.loc[i]['params']\n",
    "    params.pop('verbose')\n",
    "    params.pop('random_state')\n",
    "    params['n_estimators'] = 2000\n",
    "    _, oof_1, rmse, model1 = cv_pipeline(train_feats, test_feats, params, params['boosting_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.602618 with feats_2 and vektorizer for 1,1 n-grams\n",
    "# 0.602250 with feats_1 and vektorizer for 1,1 n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_feats is (2471, 446)\n",
      "LGBM Average RMSE over 50 folds: 0.602250\n",
      "LGBM Average RMSE over 50 folds: 0.602758\n",
      "LGBM Average RMSE over 50 folds: 0.603808\n",
      "Blend RMSE 0.601391683184638\n"
     ]
    }
   ],
   "source": [
    "print((f'The shape of train_feats is {train_feats.shape}'))\n",
    "\n",
    "# lgb_params_3 = params_df.loc[1]['params']\n",
    "\n",
    "_, oof_1, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_1, lgb_params_1['boosting_type'])\n",
    "_, oof_2, rmse, model2 = cv_pipeline(train_feats, test_feats, lgb_params_2, lgb_params_2['boosting_type'])\n",
    "_, oof_3, rmse, model3 = cv_pipeline(train_feats, test_feats, lgb_params_3, lgb_params_3['boosting_type'])\n",
    "\n",
    "blend = pd.concat([oof_1, oof_2, oof_3], axis=0)\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_feats is (2471, 446)\n",
      "LGBM Average RMSE over 50 folds: 0.602250\n",
      "LGBM Average RMSE over 50 folds: 0.602758\n",
      "Blend RMSE 0.6014560217995425\n"
     ]
    }
   ],
   "source": [
    "print((f'The shape of train_feats is {train_feats.shape}'))\n",
    "\n",
    "# lgb_params_3 = params_df.loc[1]['params']\n",
    "\n",
    "_, oof_1, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_1, lgb_params_1['boosting_type'])\n",
    "_, oof_2, rmse, model2 = cv_pipeline(train_feats, test_feats, lgb_params_2, lgb_params_2['boosting_type'])\n",
    "\n",
    "blend = pd.concat([oof_1, oof_2], axis=0)\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New LGBM_params2 - Blend RMSE 0.602450743997947\n",
    "Original 3 - Blend RMSE 0.602521633922091\n",
    "\n",
    "Percentage removed 0.25 - Full pred 0.602333. Top pred 0.602194\n",
    "Percentage removed 0.25 - Full pred 0.602161. Top pred 0.602109\n",
    "\n",
    "feats_2 - blend LGBM 2 - 0.6026870286911109\n",
    "feats_2 - blend LGBM 3 - 0.602521633922091\n",
    "\n",
    "feats_1 - blend LGBM 3 - 0.6030926120372674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.649328\n",
      "LGBM Average RMSE over 50 folds: 0.646151\n",
      "LGBM Average RMSE over 50 folds: 0.650191\n",
      "LGBM Average RMSE over 50 folds: 0.649058\n",
      "LGBM Average RMSE over 50 folds: 0.645658\n",
      "LGBM Average RMSE over 50 folds: 0.656797\n",
      "LGBM Average RMSE over 50 folds: 0.652602\n",
      "LGBM Average RMSE over 50 folds: 0.652666\n",
      "LGBM Average RMSE over 50 folds: 0.650218\n",
      "LGBM Average RMSE over 50 folds: 0.654699\n",
      "LGBM Average RMSE over 50 folds: 0.651360\n",
      "LGBM Average RMSE over 50 folds: 0.646451\n",
      "LGBM Average RMSE over 50 folds: 0.649629\n",
      "LGBM Average RMSE over 50 folds: 0.657803\n",
      "LGBM Average RMSE over 50 folds: 0.649285\n",
      "Percentage removed 0.8 - Full pred 0.603179. Top pred 0.601455\n",
      "LGBM Average RMSE over 50 folds: 0.658478\n",
      "LGBM Average RMSE over 50 folds: 0.657686\n",
      "LGBM Average RMSE over 50 folds: 0.660616\n",
      "LGBM Average RMSE over 50 folds: 0.662334\n",
      "LGBM Average RMSE over 50 folds: 0.657820\n",
      "LGBM Average RMSE over 50 folds: 0.666143\n",
      "LGBM Average RMSE over 50 folds: 0.664742\n",
      "LGBM Average RMSE over 50 folds: 0.663530\n",
      "LGBM Average RMSE over 50 folds: 0.665469\n",
      "LGBM Average RMSE over 50 folds: 0.662262\n",
      "LGBM Average RMSE over 50 folds: 0.659890\n",
      "LGBM Average RMSE over 50 folds: 0.659111\n",
      "LGBM Average RMSE over 50 folds: 0.655903\n",
      "LGBM Average RMSE over 50 folds: 0.662867\n",
      "LGBM Average RMSE over 50 folds: 0.659322\n",
      "Percentage removed 0.85 - Full pred 0.603663. Top pred 0.601525\n",
      "LGBM Average RMSE over 50 folds: 0.698010\n",
      "LGBM Average RMSE over 50 folds: 0.704796\n",
      "LGBM Average RMSE over 50 folds: 0.714076\n",
      "LGBM Average RMSE over 50 folds: 0.707087\n",
      "LGBM Average RMSE over 50 folds: 0.692691\n",
      "LGBM Average RMSE over 50 folds: 0.703550\n",
      "LGBM Average RMSE over 50 folds: 0.694097\n",
      "LGBM Average RMSE over 50 folds: 0.696183\n",
      "LGBM Average RMSE over 50 folds: 0.709539\n",
      "LGBM Average RMSE over 50 folds: 0.698972\n",
      "LGBM Average RMSE over 50 folds: 0.697556\n",
      "LGBM Average RMSE over 50 folds: 0.695830\n",
      "LGBM Average RMSE over 50 folds: 0.697626\n",
      "LGBM Average RMSE over 50 folds: 0.702510\n",
      "LGBM Average RMSE over 50 folds: 0.697232\n",
      "Percentage removed 0.95 - Full pred 0.604209. Top pred 0.601922\n"
     ]
    }
   ],
   "source": [
    "pct_to_remv = 0.8 \n",
    "#Percentage removed 0.8 - Full pred 0.603179. Top pred 0.601455\n",
    "\n",
    "params = [lgb_params_1, lgb_params_2, lgb_params_3]\n",
    "test_ids = test_feats.id\n",
    "test_bl_results, train_bl_results = pd.DataFrame(), pd.DataFrame()\n",
    "blend_scores = pd.read_pickle('blend_scores_ft2.pkl')\n",
    "\n",
    "for pct_to_remv in [0.80, 0.85, 0.95]: # 1.050000 BEST\n",
    "\n",
    "    for i, p in enumerate(params):\n",
    "\n",
    "        bal_scores = create_specific_balanced_datasets(train_scores, \n",
    "                                                        scores_to_split=[3, 3.5, 4, 4.5], \n",
    "                                                        pct_to_remv=pct_to_remv,\n",
    "                                                        n_datasets=5,\n",
    "                                                        seed=seed+i)\n",
    "        \n",
    "        for ds in bal_scores:\n",
    "                    \n",
    "                    ids = ds.id.unique()\n",
    "                    test_preds, oof_results, rmse = cv_balanced_pipeline(train_feats=train_feats,\n",
    "                                                                        test_feats=test_feats,\n",
    "                                                                        lgb_params=p,\n",
    "                                                                        balanced_dataset_ids=ids,\n",
    "                                                                        boosting_type=p['boosting_type']\n",
    "                                                                        )\n",
    "                    \n",
    "                    data = {'id': test_ids, 'prediction': test_preds}\n",
    "                    test_tmp = pd.DataFrame(data=data)\n",
    "                    test_bl_results = pd.concat([test_bl_results, test_tmp], axis=0)\n",
    "                    train_bl_results = pd.concat([train_bl_results, oof_results], axis=0)\n",
    "\n",
    "    train_avg_blc = train_bl_results.groupby(['id', 'score'])['prediction'].mean().reset_index()\n",
    "    test_avg_blc = test_bl_results.groupby(['id'])['prediction'].mean().reset_index()\n",
    "\n",
    "    train_bal_preds = train_avg_blc[(train_avg_blc['prediction'] < 2.5) | (train_avg_blc['prediction'] > 4.5)]\n",
    "    train_bal_preds.to_pickle('bal_scores_ft2_full.pkl')\n",
    "    train_concat_results = pd.concat([blend_scores, train_bal_preds], axis=0)\n",
    "    train_blend_preds = train_concat_results.groupby(['id', 'score'])['prediction'].mean().reset_index()\n",
    "    pred_full = np.sqrt(mean_squared_error(train_blend_preds['score'], train_blend_preds['prediction']))\n",
    "\n",
    "    train_bal_preds = train_avg_blc[(train_avg_blc['prediction'] > 4.5)]\n",
    "    train_bal_preds.to_pickle('bal_scores_ft2_top.pkl')\n",
    "    train_concat_results = pd.concat([blend_scores, train_bal_preds], axis=0)\n",
    "    train_blend_preds = train_concat_results.groupby(['id', 'score'])['prediction'].mean().reset_index()\n",
    "    pred_top = np.sqrt(mean_squared_error(train_blend_preds['score'], train_blend_preds['prediction']))\n",
    "    print(f'Percentage removed {pct_to_remv} - Full pred {pred_full:.6f}. Top pred {pred_top:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test one single instance of percentage removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.603452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6027577504973198"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_st, oof_results_st, rmse = cv_pipeline(train_feats, test_feats, lgb_params_1)\n",
    "data = {'id': test_ids, 'prediction': test_preds_st}\n",
    "test_tmp_st = pd.DataFrame(data=data)\n",
    "\n",
    "train_bal_preds = train_avg_blc[(train_avg_blc['prediction'] < 2.5) | (train_avg_blc['prediction'] > 4.5)]\n",
    "train_concat_results = pd.concat([oof_results_st, train_bal_preds], axis=0)\n",
    "train_blend_preds = train_concat_results.groupby(['id', 'score'])['prediction'].mean().reset_index()\n",
    "pred_full = np.sqrt(mean_squared_error(train_blend_preds['score'], train_blend_preds['prediction']))\n",
    "\n",
    "train_bal_preds = train_avg_blc[(train_avg_blc['prediction'] > 4.5)]\n",
    "train_concat_results = pd.concat([oof_results_st, train_bal_preds], axis=0)\n",
    "train_blend_preds = train_concat_results.groupby(['id', 'score'])['prediction'].mean().reset_index()\n",
    "pred_top = np.sqrt(mean_squared_error(train_blend_preds['score'], train_blend_preds['prediction']))\n",
    "print(f'Full pred {pred_full}. Top pred {pred_top}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6031404980252844"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bal_preds = train_avg_blc[(train_avg_blc['prediction'] < 2.5) | (train_avg_blc['prediction'] > 4.5)]\n",
    "train_concat_results = pd.concat([oof_results_st, train_bal_preds], axis=0)\n",
    "train_blend_preds = train_concat_results.groupby(['id', 'score'])['prediction'].mean().reset_index()\n",
    "np.sqrt(mean_squared_error(train_blend_preds['score'], train_blend_preds['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60293358997378"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bal_preds = train_avg_blc[(train_avg_blc['prediction'] > 4.5)]\n",
    "train_concat_results = pd.concat([oof_results_st, train_bal_preds], axis=0)\n",
    "train_blend_preds = train_concat_results.groupby(['id', 'score'])['prediction'].mean().reset_index()\n",
    "np.sqrt(mean_squared_error(train_blend_preds['score'], train_blend_preds['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Average RMSE over 50 folds: 0.604314\n"
     ]
    }
   ],
   "source": [
    "# COMPARE ALL FEATURES WITH BASELINE - ONE BY ONE\n",
    "\n",
    "lgb_params_2 = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'colsample_bytree': 1.0, \n",
    "    'importance_type': 'split', \n",
    "    'learning_rate': 0.17106535627270134, \n",
    "    'max_depth': 16, \n",
    "    'min_child_samples': 39, \n",
    "    'min_child_weight': 0.001, \n",
    "    'min_split_gain': 0.0, \n",
    "    'n_jobs': None, \n",
    "    'num_leaves': 15, \n",
    "    'reg_alpha': 0.8577521098353755, \n",
    "    'reg_lambda': 0.7679447672996995, \n",
    "    'subsample': 1.0, \n",
    "    'subsample_for_bin': 200000, \n",
    "    'subsample_freq': 0\n",
    "    }\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_1.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_1.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "\n",
    "_, oof_2, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_2, lgb_params_1['boosting_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:04<00:00, 553.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2004.93it/s]\n",
      "Iterations: 100%|██████████| 5/5 [15:27<00:00, 185.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Average RMSE over 50 folds: 0.600903\n",
      "LGBM Average RMSE over 50 folds: 0.601574\n",
      "Blend RMSE 0.598880\n"
     ]
    }
   ],
   "source": [
    "params_df = pd.read_csv('params.csv')\n",
    "params_df = params_df.head(2)\n",
    "params_df['params'] = params_df['params'].apply(ast.literal_eval)\n",
    "\n",
    "for i in range(2):\n",
    "    params = params_df.loc[i]['params']\n",
    "    params.pop('verbose')\n",
    "    params.pop('random_state')\n",
    "    params['n_estimators'] = 2000\n",
    "\n",
    "lgb_params_2 = params_df.loc[0]['params']\n",
    "\n",
    "from m3_model_params import lgb_params_1, xgb_params_2\n",
    "\n",
    "n_repeats = 5\n",
    "n_splits = 6\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "train_feats, test_feats = countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)\n",
    "_, oof_1, rmse, model1 = xgb_cv_pipeline(train_feats=train_feats, \n",
    "                                        test_feats=test_feats, \n",
    "                                        xgb_params=xgb_params_2, \n",
    "                                        seed=seed, \n",
    "                                        n_repeats=n_repeats, \n",
    "                                        n_splits=n_splits)\n",
    "                                        \n",
    "_, oof_2, rmse, model1 = cv_pipeline(train_feats, test_feats, lgb_params_2, lgb_params_1['boosting_type'])\n",
    "\n",
    "blend = pd.concat([oof_1, oof_2], axis=0)\n",
    "blend_scores = blend.groupby(['id','score'])['prediction'].mean().reset_index()\n",
    "blend_rmse = mean_squared_error(blend_scores['score'], blend_scores['prediction'], squared=False)\n",
    "print(f'Blend RMSE {blend_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # base_train_2 = pd.read_pickle('feature_store/base_feats/train_base_feats_1.pkl')\n",
    " # tr_ft1 = pd.read_pickle('feature_store/train/train_wpm_feats.pkl')\n",
    " # tr_ft2 = pd.read_pickle('feature_store/train/train_action_time_gap_by_acti.pkl')\n",
    " # tr_ft3 = pd.read_pickle('feature_store/train/train_IKI.pkl')\n",
    " # base_train_2 = base_train_2.merge(tr_ft1, on=['id'], how='left')\n",
    " # base_train_2 = base_train_2.merge(tr_ft2, on=['id'], how='left')\n",
    " # base_train_2 = base_train_2.merge(tr_ft3, on=['id'], how='left')\n",
    " # \n",
    " # base_test_2 = pd.read_pickle('feature_store/base_feats/test_base_feats_1.pkl')\n",
    " # ts_ft1 = pd.read_pickle('feature_store/test/test_wpm_feats.pkl')\n",
    " # ts_ft2 = pd.read_pickle('feature_store/test/test_action_time_gap_by_acti.pkl')\n",
    " # ts_ft3 = pd.read_pickle('feature_store/test/test_IKI.pkl')\n",
    " # base_test_2 = base_test_2.merge(ts_ft1, on=['id'], how='left')\n",
    " # base_test_2 = base_test_2.merge(ts_ft2, on=['id'], how='left')\n",
    " # base_test_2 = base_test_2.merge(ts_ft3, on=['id'], how='left')\n",
    "\n",
    "# base_train_2.to_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "# base_test_2.to_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "\n",
    "#(wpm_feats, IKI, action_time_gap_by_acti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2471, 495) (3, 385)\n"
     ]
    }
   ],
   "source": [
    "base_train_2 = pd.read_pickle('feature_store/base_feats/train_base_feats_1.pkl')\n",
    "tr_ft1 = pd.read_pickle('feature_store/train/train_action_time_gap_by_acti.pkl')\n",
    "tr_ft2 = pd.read_pickle('feature_store/train/train_action_time_gap.pkl')\n",
    "base_train_2 = base_train_2.merge(tr_ft1, on=['id'], how='left')\n",
    "base_train_2 = base_train_2.merge(tr_ft2, on=['id'], how='left')\n",
    "\n",
    "base_test_2 = pd.read_pickle('feature_store/base_feats/test_base_feats_1.pkl')\n",
    "ts_ft1 = pd.read_pickle('feature_store/test/test_action_time_gap_by_acti.pkl')\n",
    "ts_ft2 = pd.read_pickle('feature_store/train/train_action_time_gap.pkl')\n",
    "base_test_2 = base_test_2.merge(ts_ft1, on=['id'], how='left')\n",
    "base_test_2 = base_test_2.merge(ts_ft2, on=['id'], how='left')\n",
    "\n",
    "# base_train_2.to_pickle('feature_store/base_feats/train_base_feats_2.pkl')\n",
    "# base_test_2.to_pickle('feature_store/base_feats/test_base_feats_2.pkl')\n",
    "print(base_train_2.shape, base_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Combination</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>(action_time_gap_by_acti, action_time_gap)</td>\n",
       "      <td>0.603452</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(action_time_gap_by_acti, IKI, wpm_feats, rep_...</td>\n",
       "      <td>0.603481</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>(action_time_gap_by_acti, wpm_feats, action_ti...</td>\n",
       "      <td>0.603664</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(action_time_gap_by_acti, IKI, wpm_feats, rep_...</td>\n",
       "      <td>0.603668</td>\n",
       "      <td>0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>(IKI, wpm_feats, rep_cut, action_time_gap)</td>\n",
       "      <td>0.603718</td>\n",
       "      <td>0.000604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>(IKI, rep_cut, at_by_bucket, action_time_gap)</td>\n",
       "      <td>0.603842</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>(action_time_gap_by_acti, wpm_feats, rep_cut, ...</td>\n",
       "      <td>0.603907</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(action_time_gap_by_acti, IKI, wpm_feats, acti...</td>\n",
       "      <td>0.603984</td>\n",
       "      <td>0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>(action_time_gap_by_acti, IKI)</td>\n",
       "      <td>0.604015</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>(action_time_gap_by_acti, wpm_feats)</td>\n",
       "      <td>0.604043</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature Combination    Metric  Improvement\n",
       "225         (action_time_gap_by_acti, action_time_gap)  0.603452     0.000870\n",
       "40   (action_time_gap_by_acti, IKI, wpm_feats, rep_...  0.603481     0.000841\n",
       "173  (action_time_gap_by_acti, wpm_feats, action_ti...  0.603664     0.000658\n",
       "11   (action_time_gap_by_acti, IKI, wpm_feats, rep_...  0.603668     0.000654\n",
       "131         (IKI, wpm_feats, rep_cut, action_time_gap)  0.603718     0.000604\n",
       "142      (IKI, rep_cut, at_by_bucket, action_time_gap)  0.603842     0.000480\n",
       "110  (action_time_gap_by_acti, wpm_feats, rep_cut, ...  0.603907     0.000415\n",
       "97   (action_time_gap_by_acti, IKI, wpm_feats, acti...  0.603984     0.000338\n",
       "219                     (action_time_gap_by_acti, IKI)  0.604015     0.000307\n",
       "220               (action_time_gap_by_acti, wpm_feats)  0.604043     0.000279"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_comb.sort_values(by='Metric').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Combination</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(action_time_gap, count_vectorized, action_tim...</td>\n",
       "      <td>0.600539</td>\n",
       "      <td>0.003775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(action_time_gap, count_vectorized, action_tim...</td>\n",
       "      <td>0.600864</td>\n",
       "      <td>0.003450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>(action_time_gap, count_vectorized)</td>\n",
       "      <td>0.601028</td>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(action_time_gap, count_vectorized, action_tim...</td>\n",
       "      <td>0.601100</td>\n",
       "      <td>0.003214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>(count_vectorized, action_time_gap_by_acti, wc...</td>\n",
       "      <td>0.601112</td>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>(adj_eff_time, wpm_feats, IKI, rep_cut)</td>\n",
       "      <td>0.606174</td>\n",
       "      <td>-0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>(wc_chage, adj_eff_time)</td>\n",
       "      <td>0.606192</td>\n",
       "      <td>-0.001878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>(adj_eff_time, wpm_feats, IKI)</td>\n",
       "      <td>0.606394</td>\n",
       "      <td>-0.002080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>(at_by_bucket, action_time_gap_by_acti, wc_cha...</td>\n",
       "      <td>0.606476</td>\n",
       "      <td>-0.002162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>(adj_eff_time, IKI)</td>\n",
       "      <td>0.606549</td>\n",
       "      <td>-0.002235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature Combination    Metric  Improvement\n",
       "13   (action_time_gap, count_vectorized, action_tim...  0.600539     0.003775\n",
       "17   (action_time_gap, count_vectorized, action_tim...  0.600864     0.003450\n",
       "330                (action_time_gap, count_vectorized)  0.601028     0.003286\n",
       "16   (action_time_gap, count_vectorized, action_tim...  0.601100     0.003214\n",
       "122  (count_vectorized, action_time_gap_by_acti, wc...  0.601112     0.003202\n",
       "..                                                 ...       ...          ...\n",
       "209            (adj_eff_time, wpm_feats, IKI, rep_cut)  0.606174    -0.001860\n",
       "365                           (wc_chage, adj_eff_time)  0.606192    -0.001878\n",
       "326                     (adj_eff_time, wpm_feats, IKI)  0.606394    -0.002080\n",
       "155  (at_by_bucket, action_time_gap_by_acti, wc_cha...  0.606476    -0.002162\n",
       "370                                (adj_eff_time, IKI)  0.606549    -0.002235\n",
       "\n",
       "[385 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_comb.sort_values('Improvement', ascending=False)\n",
    "\n",
    "#('action_time_gap', 'count_vectorized', 'action_time_gap_by_acti', 'wc_chage')\n",
    "#('action_time_gap', 'count_vectorized', 'action_time_gap_by_acti', 'rep_cut')\n",
    "#('action_time_gap', 'count_vectorized')\n",
    "#('action_time_gap', 'count_vectorized', 'action_time_gap_by_acti', 'IKI')\n",
    "#('count_vectorized', 'action_time_gap_by_acti', 'wc_chage', 'IKI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Combination</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(action_time_gap, count_vectorized, action_tim...</td>\n",
       "      <td>0.600539</td>\n",
       "      <td>0.003775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(action_time_gap, count_vectorized, action_tim...</td>\n",
       "      <td>0.600864</td>\n",
       "      <td>0.003450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>(action_time_gap, count_vectorized)</td>\n",
       "      <td>0.601028</td>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(action_time_gap, count_vectorized, action_tim...</td>\n",
       "      <td>0.601100</td>\n",
       "      <td>0.003214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>(count_vectorized, action_time_gap_by_acti, wc...</td>\n",
       "      <td>0.601112</td>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(action_time_gap, count_vectorized, at_by_buck...</td>\n",
       "      <td>0.601142</td>\n",
       "      <td>0.003172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>(count_vectorized, action_time_gap_by_acti, wp...</td>\n",
       "      <td>0.601183</td>\n",
       "      <td>0.003131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(action_time_gap, count_vectorized, action_tim...</td>\n",
       "      <td>0.601221</td>\n",
       "      <td>0.003093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>(count_vectorized, action_time_gap_by_acti, re...</td>\n",
       "      <td>0.601315</td>\n",
       "      <td>0.002999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>(count_vectorized, action_time_gap_by_acti, ad...</td>\n",
       "      <td>0.601395</td>\n",
       "      <td>0.002919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>(count_vectorized, action_time_gap_by_acti, wc...</td>\n",
       "      <td>0.601485</td>\n",
       "      <td>0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(action_time_gap, count_vectorized, action_tim...</td>\n",
       "      <td>0.601536</td>\n",
       "      <td>0.002778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>(count_vectorized, action_time_gap_by_acti, ad...</td>\n",
       "      <td>0.601629</td>\n",
       "      <td>0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>(count_vectorized, action_time_gap_by_acti, wc...</td>\n",
       "      <td>0.601637</td>\n",
       "      <td>0.002677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>(action_time_gap, count_vectorized, wpm_feats)</td>\n",
       "      <td>0.601650</td>\n",
       "      <td>0.002664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature Combination    Metric  Improvement\n",
       "13   (action_time_gap, count_vectorized, action_tim...  0.600539     0.003775\n",
       "17   (action_time_gap, count_vectorized, action_tim...  0.600864     0.003450\n",
       "330                (action_time_gap, count_vectorized)  0.601028     0.003286\n",
       "16   (action_time_gap, count_vectorized, action_tim...  0.601100     0.003214\n",
       "122  (count_vectorized, action_time_gap_by_acti, wc...  0.601112     0.003202\n",
       "1    (action_time_gap, count_vectorized, at_by_buck...  0.601142     0.003172\n",
       "127  (count_vectorized, action_time_gap_by_acti, wp...  0.601183     0.003131\n",
       "14   (action_time_gap, count_vectorized, action_tim...  0.601221     0.003093\n",
       "263  (count_vectorized, action_time_gap_by_acti, re...  0.601315     0.002999\n",
       "126  (count_vectorized, action_time_gap_by_acti, ad...  0.601395     0.002919\n",
       "259  (count_vectorized, action_time_gap_by_acti, wc...  0.601485     0.002829\n",
       "15   (action_time_gap, count_vectorized, action_tim...  0.601536     0.002778\n",
       "260  (count_vectorized, action_time_gap_by_acti, ad...  0.601629     0.002685\n",
       "121  (count_vectorized, action_time_gap_by_acti, wc...  0.601637     0.002677\n",
       "215     (action_time_gap, count_vectorized, wpm_feats)  0.601650     0.002664"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_comb.sort_values('Improvement', ascending=False).head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
