{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import polars as pl\n","\n","from m4_feats_polars import *\n","from m5_sb_models import *\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T16:51:03.054893Z","iopub.status.busy":"2023-12-21T16:51:03.054297Z","iopub.status.idle":"2023-12-21T16:51:03.076257Z","shell.execute_reply":"2023-12-21T16:51:03.075002Z","shell.execute_reply.started":"2023-12-21T16:51:03.054836Z"},"trusted":true},"outputs":[],"source":["lgb_params_1 = {\n","    'boosting_type': 'gbdt', \n","    'metric': 'rmse',\n","    'reg_alpha': 0.003188447814669599, \n","    'reg_lambda': 0.0010228604507564066, \n","    'colsample_bytree': 0.8,  \n","    'subsample_freq': 1,  \n","    'subsample': 0.75,  \n","    'learning_rate': 0.01716485155812008, \n","    'num_leaves': 19, \n","    'min_child_samples': 46,\n","    'n_estimators': 2000,\n","    'force_col_wise': True,\n","    'verbosity': -1,\n","    }\n","\n","data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n","train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n","test_logs     = pl.scan_csv(f'{data_path}/test_logs.csv')\n","train_scores  = pl.scan_csv(f'{data_path}/train_scores.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T16:51:03.081906Z","iopub.status.busy":"2023-12-21T16:51:03.080838Z","iopub.status.idle":"2023-12-21T16:52:10.267784Z","shell.execute_reply":"2023-12-21T16:52:10.266167Z","shell.execute_reply.started":"2023-12-21T16:51:03.081850Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["< Events counts features >\n","< Count vectorize one-grams >\n","< Idle time features >\n","< cursor position acceleration >\n","< word count acceleration >\n","< Count vectorize bi-grams >\n","< R-burst features >\n","< Categorical # unique values features >\n","< Essays paragraphs feats >\n","< Essays paragraphs feats >\n","train feats shape (2471, 118)\n"]}],"source":["# [('train_down_events_counts.pkl', 26),\n","#  ('train_vector_one_gram.pkl', 26),\n","#  ('train_create_pauses.pkl', 26),\n","#  ('train_essay_paragraphs.pkl', 26),\n","#  ('train_cursor_pos_acceleration.pkl', 11),\n","#  ('train_word_count_acceleration.pkl', 6),\n","#  ('train_p_burst_feats.pkl', 5),\n","#  ('train_r_burst_feats.pkl', 3),\n","#  ('train_events_counts_acceleration.pkl', 3),\n","#  ('train_essay_sentences.pkl', 3),\n","#  ('train_categorical_nunique.pkl', 3),\n","#  ('train_vector_two_gram.pkl', 2),\n","#  ('train_cursor_pos_rate_of_change.pkl', 2),\n","#  ('train_word_counts_rate_of_change.pkl', 2),\n","#  ('train_count_of_activities.pkl', 2),\n","#  ('train_action_time_by_activity.pkl', 1),\n","#  ('train_product_to_keys.pkl', 1),\n","#  ('train_IKI_based_fractals.pkl', 1),\n","#  ('train_events_counts_baseline.pkl', 1)]\n","\n","# best_feature_set_1 - PARTIAL\n","train_essays          = get_essay_df(train_logs.collect().to_pandas())\n","test_essays           = get_essay_df(test_logs.collect().to_pandas())\n","\n","tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n","tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n","tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n","tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n","tr_word_count_acc, ts_word_count_acc = word_count_acceleration(train_logs, test_logs)\n","tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n","tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n","tr_nunique, ts_nunique = categorical_nunique(train_logs, test_logs)\n","tr_get_keys, ts_get_keys = get_keys_pressed_per_second(train_logs.collect().to_pandas(), \n","                                                       test_logs.collect().to_pandas())\n","\n","# tr_p_burst, ts_p_burst = p_burst_feats(train_logs, test_logs, 2)\n","# tr_event_acc, ts_event_acc = events_counts_acceleration(train_logs, test_logs)\n","# tr_time_by_act, ts_time_by_act = action_time_by_activity(train_logs, test_logs)\n","# tr_cursor_pos_roc, ts_cursor_pos_roc = cursor_pos_rate_of_change(train_logs, test_logs)\n","# \n","# tr_act_count, ts_act_count = count_of_activities(train_logs, test_logs)\n","# \n","# tr_input_change, ts_input_change = input_text_change_feats(train_logs, test_logs)\n","# tr_wc_roc, ts_wc_roc =  word_counts_rate_of_change(train_logs, test_logs)\n","\n","\n","train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n","train_feats = train_feats.join(tr_pauses, on='id', how='left')\n","train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_word_count_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n","train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_nunique, on='id', how='left')\n","train_feats = train_feats.join(tr_get_keys, on='id', how='left')\n","# train_feats = train_feats.join(tr_p_burst, on='id', how='left')\n","# train_feats = train_feats.join(tr_event_acc, on='id', how='left')\n","# train_feats = train_feats.join(tr_wc_roc, on='id', how='left')\n","# train_feats = train_feats.join(tr_act_count, on='id', how='left')\n","# train_feats = train_feats.join(tr_cursor_pos_roc, on='id', how='left')\n","# train_feats = train_feats.join(tr_input_change, on='id', how='left')\n","# train_feats = train_feats.join(tr_time_by_act, on='id', how='left')\n","\n","test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n","test_feats = test_feats.join(ts_pauses, on='id', how='left')\n","test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_word_count_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n","test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_nunique, on='id', how='left')\n","test_feats = test_feats.join(ts_get_keys, on='id', how='left')\n","# test_feats = test_feats.join(ts_p_burst, on='id', how='left')\n","# test_feats = test_feats.join(tr_event_acc, on='id', how='left')\n","# test_feats = test_feats.join(ts_wc_roc, on='id', how='left')\n","# test_feats = test_feats.join(ts_act_count, on='id', how='left')\n","# test_feats = test_feats.join(ts_cursor_pos_roc, on='id', how='left')\n","# test_feats = test_feats.join(ts_input_change, on='id', how='left')\n","# test_feats = test_feats.join(ts_time_by_act, on='id', how='left')\n","\n","\n","train_logs = train_logs.collect().to_pandas()\n","test_logs = test_logs.collect().to_pandas()\n","train_scores = train_scores.collect().to_pandas()\n","train_feats = train_feats.sort('id')\n","train_feats = train_feats.collect().to_pandas()\n","test_feats = test_feats.collect().to_pandas()\n","\n","train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n","\n","# train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n","# test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n","\n","train_feats = train_feats.merge(train_scores, on='id', how='left')\n","print(f'train feats shape {train_feats.shape}')"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-12-21T16:52:10.270176Z","iopub.status.busy":"2023-12-21T16:52:10.269767Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6183842119315204\n"]}],"source":["test_preds, oof_preds, rmse, model = lgb_pipeline(train_feats, test_feats, lgb_params_1)\n","print(rmse)\n","# test_preds_w, oof_preds_w, rmse_w, model_w = lgb_w_pipeline(train_feats, test_feats, lgb_params_1)\n","# test_preds2, oof_preds, rmse, model = xgb_pipeline(train_feats, test_feats, lgb_params_1)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Final RMSE over 50: 0.663325. Std 0.7942\n","RMSE by fold 0.663288. Std 0.0068\n"]}],"source":["from sklearn.preprocessing import StandardScaler\n","\n","def preprocess_feats(feats, scaler=StandardScaler()):\n","    feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    feats.fillna(-1e10, inplace=True)\n","    feats_columns = feats.columns\n","    feats.loc[:, feats_columns != 'id'] = scaler.fit_transform(feats.loc[:, feats_columns != 'id'])\n","    return feats\n","\n","train_feats.iloc[:,:-1] = preprocess_feats(train_feats.iloc[:,:-1], StandardScaler())\n","test_feats = preprocess_feats(test_feats, StandardScaler())\n","\n","alpha = 100\n","ridge_params = {'alpha': alpha}  # Create a dictionary with alpha\n","test_preds, oof_preds_rid, rmse, model = ridge_pipeline(train_feats, test_feats, ridge_params)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Combined RMSE: 0.6152482871990806\n"]}],"source":["comb_oof_preds = pd.concat([oof_preds, oof_preds_rid], axis=0).groupby(['id','score'])['preds'].mean().reset_index()\n","oof_rmse = mean_squared_error(comb_oof_preds['score'], comb_oof_preds['preds'], squared=False)\n","print(f'Combined RMSE: {oof_rmse}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# OOF summary\n","oof_w_preds_filt = oof_preds_w[(oof_preds_w['score']<1.5) | (oof_preds_w['score']>5.5)]\n","comb_oof_preds = pd.concat([oof_preds, oof_w_preds_filt], axis=0).groupby(['id','score'])['preds'].mean().reset_index()\n","oof_rmse = mean_squared_error(comb_oof_preds['score'], comb_oof_preds['preds'], squared=False)\n","print(f'Combined RMSE: {oof_rmse}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Predictions\n","n_preds = pd.DataFrame(data={'id': test_feats.id, 'score': np.mean(test_preds, axis=0)})\n","w_preds = pd.DataFrame(data={'id': test_feats.id, 'score': np.mean(test_preds_w, axis=0)})\n","preds_filt = n_preds[(n_preds['score']<1.5) | (n_preds['score']>5.5)]\n","comb_preds = pd.concat([w_preds, preds_filt], axis=0).groupby(['id'])['score'].mean().reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["comb_preds.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_preds, model  = lgb_full_train_set(train_feats, test_feats, lgb_params_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # scores = np.mean(np.vstack([test_preds, test_preds2]), axis=0)\n","\n","# test_ids = test_feats.id\n","# y_pred = np.mean(test_preds, axis=0)\n","\n","# sub = pd.DataFrame({'id': test_ids, 'score': y_pred})\n","# sub.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6678907,"sourceId":59291,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
