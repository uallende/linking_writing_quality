{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from m4_feats_polars import *\n",
    "from m5_sb_models import lgb_pipeline\n",
    "import polars as pl\n",
    "import os, warnings\n",
    "from m4_small_feats import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_STORE = 'feat_small'\n",
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n",
    "test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n",
    "train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')\n",
    "train_scores = train_scores.collect().to_pandas()\n",
    "\n",
    "param = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'metric': 'rmse',\n",
    "    'reg_alpha': 0.0031, \n",
    "    'reg_lambda': 0.001, \n",
    "    'colsample_bytree': 0.8,  \n",
    "    'subsample_freq': 1,  \n",
    "    'subsample': 0.75,  \n",
    "    'learning_rate': 0.017, \n",
    "    'num_leaves': 19, \n",
    "    'min_child_samples': 46,\n",
    "    'n_estimators': 350,\n",
    "    'verbosity': -1\n",
    "    }\n",
    "\n",
    "feat_list = os.listdir(FEAT_STORE)\n",
    "list_train_feats = [feat for feat in feat_list if feat.startswith('train_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Events counts features >\n",
      "< Events counts features >\n",
      "< Events counts features >\n",
      "< Events counts features >\n",
      "< Idle time features >\n",
      "< cursor position acceleration >\n",
      "< cursor position acceleration >\n",
      "< P-burst features >\n",
      "< P-burst features >\n",
      "< R-burst features >\n",
      "< R-burst features >\n",
      "< events counts acceleration >\n",
      "< events counts acceleration >\n",
      "< word count acceleration >\n",
      "< word count acceleration >\n",
      "< added words pauses basic\n",
      "< added words pauses advanced\n",
      "< removed words pauses basic\n",
      "< removed words pauses advanced\n",
      "< word timings advanced\n",
      "< word timings advanced\n",
      "< Categorical # unique values features >\n",
      "< Essays sentences feats >\n",
      "< Essays sentences feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n",
      "< Count vectorize one-grams >\n",
      "< Count vectorize one-grams >\n",
      "< Count vectorize one-grams >\n",
      "< Count vectorize bi-grams >\n",
      "< Count vectorize bi-grams >\n",
      "< Count vectorize bi-grams >\n"
     ]
    }
   ],
   "source": [
    "file_name = 'down_events_counts_three'\n",
    "tr,ts = down_events_counts_three(train_logs, test_logs, n_events=20)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'down_events_counts_two'\n",
    "tr,ts = down_events_counts_two(train_logs, test_logs, n_events=20)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'down_events_counts_three'\n",
    "tr,ts = down_events_counts_three(train_logs, test_logs, n_events=20)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'down_events_counts_one'\n",
    "tr,ts = down_events_counts_one(train_logs, test_logs, n_events=20)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'create_pauses'\n",
    "tr,ts = create_pauses(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'cursor_pos_acceleration_basic'\n",
    "tr,ts = cursor_pos_acceleration_basic(train_logs, test_logs, time_agg=8)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'cursor_pos_acceleration_adv'\n",
    "tr,ts = cursor_pos_acceleration_adv(train_logs, test_logs, time_agg=8)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'p_burst_feats_basic'\n",
    "tr,ts = p_burst_feats_basic(train_logs, test_logs, time_agg=2)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'p_burst_feats_adv'\n",
    "tr,ts = p_burst_feats_adv(train_logs, test_logs, time_agg=2)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'r_burst_feats_basic'\n",
    "tr,ts = r_burst_feats_basic(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'r_burst_feats_adv'\n",
    "tr,ts = r_burst_feats_adv(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts_acceleration_basic'\n",
    "tr,ts = events_counts_acceleration_basic(train_logs, test_logs, time_agg=4)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts_acceleration_adv'\n",
    "tr,ts = events_counts_acceleration_adv(train_logs, test_logs, time_agg=4)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_count_acceleration_basic'\n",
    "tr,ts = word_count_acceleration_basic(train_logs, test_logs, time_agg=8)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_count_acceleration_adv'\n",
    "tr,ts = word_count_acceleration_adv(train_logs, test_logs, time_agg=8)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'add_word_pauses_basic'\n",
    "tr,ts = add_word_pauses_basic(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'add_word_pauses_adv'\n",
    "tr,ts = add_word_pauses_adv(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'remove_word_pauses_basic'\n",
    "tr,ts = remove_word_pauses_basic(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'remove_word_pauses_adv'\n",
    "tr,ts = remove_word_pauses_adv(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_timings_basic'\n",
    "tr,ts = word_timings_basic(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_timings_adv'\n",
    "tr,ts = word_timings_adv(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'categorical_nunique'\n",
    "tr,ts = categorical_nunique(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "\n",
    "\n",
    "train_essays = get_essay_df(train_logs.collect().to_pandas())\n",
    "test_essays = get_essay_df(test_logs.collect().to_pandas())\n",
    "file_name = 'essay_sent_words'\n",
    "tr,ts = essay_sent_words(train_essays), essay_sent_words(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_sent_length'\n",
    "tr,ts = essay_sent_length(train_essays), essay_sent_length(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_par_length'\n",
    "tr,ts = essay_par_length(train_essays), essay_par_length(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_par_words'\n",
    "tr,ts = essay_par_words(train_essays), essay_par_words(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_sents_per_par'\n",
    "tr,ts = essay_sents_per_par(train_essays), essay_sents_per_par(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_sents_per_par_basic'\n",
    "tr,ts = essay_sents_per_par_basic(train_essays), essay_sents_per_par_basic(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_sents_per_par_adv'\n",
    "tr,ts = essay_sents_per_par_adv(train_essays), essay_sents_per_par_adv(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'countvectorize_one_two'\n",
    "tr,ts = countvectorize_one_two(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'countvectorize_one_three'\n",
    "tr,ts = countvectorize_one_three(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'countvectorize_one_four'\n",
    "tr,ts = countvectorize_one_four(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'countvectorize_two_one'\n",
    "tr,ts = countvectorize_two_one(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'countvectorize_two_one'\n",
    "tr,ts = countvectorize_two_one(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'countvectorize_two_two'\n",
    "tr,ts = countvectorize_two_two(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': 1024,\n",
    "        'learning_rate': 0.005,\n",
    "        'metric': 'rmse',\n",
    "        'force_col_wise': True,\n",
    "        'verbosity': 0,}\n",
    "\n",
    "best_feats = []\n",
    "train_feats, test_feats = pd.DataFrame(), pd.DataFrame()\n",
    "best_rmse = float('inf')\n",
    "round = 0\n",
    "added_feats = []\n",
    "improved = True\n",
    "results = pd.DataFrame()\n",
    "train_feats = train_feats.sample(frac=1).reset_index(drop=True)\n",
    "list_train_feats = [feat for feat in feat_list if feat.startswith('train_')]\n",
    "\n",
    "while improved:\n",
    "    print(f'Starting round {round} of training feats')\n",
    "    improved = False\n",
    "    list_train_feats = [feat for feat in list_train_feats if feat not in added_feats]\n",
    "\n",
    "    for tr_feats_cand in list_train_feats:\n",
    "        ts_feats_cand = tr_feats_cand.replace('train', 'test')\n",
    "\n",
    "        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{tr_feats_cand}')\n",
    "        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_feats_cand}')\n",
    "\n",
    "        existing_train_columns = set(train_feats.columns)\n",
    "        existing_test_columns = set(test_feats.columns)\n",
    "\n",
    "        if not(train_feats.empty & test_feats.empty):\n",
    "\n",
    "            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "\n",
    "            if 'score' not in train_feats.columns:\n",
    "                train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "                \n",
    "            assert train_feats.shape[1] == test_feats.shape[1] + 1\n",
    "        else:\n",
    "            #print(f'feats empty - setting up train_feats')\n",
    "            train_feats = tr_feats\n",
    "            test_feats = ts_feats\n",
    "            train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "        \n",
    "        # print(f'Train feats cols {train_feats.columns}')\n",
    "        tr_cols = tr_feats.drop(columns=['id']).columns\n",
    "        ts_cols = ts_feats.drop(columns=['id']).columns\n",
    "        train_feats = train_feats.sample(frac=1).reset_index(drop=True)\n",
    "        mean_rmse = []\n",
    "\n",
    "        for i in range(15):\n",
    "            train_feats = train_feats.sample(frac=1).reset_index(drop=True)\n",
    "            test_preds, valid_preds, final_rmse, cv_rm = lgb_pipeline(train_feats, test_feats, param)\n",
    "            mean_rmse.append(final_rmse)\n",
    "\n",
    "        print(f'Training... {tr_feats_cand}. Score: {np.mean(mean_rmse):.4f}')\n",
    "        temp_res = {'feat_name': tr_feats_cand, 'RMSE': np.mean(mean_rmse)}\n",
    "        results = pd.concat([results, pd.DataFrame([temp_res])])\n",
    "\n",
    "        train_feats.drop(columns=tr_cols, inplace=True)\n",
    "        test_feats.drop(columns=ts_cols, inplace=True)\n",
    "\n",
    "    results = results.sort_values('RMSE', ascending=True)\n",
    "    top_score = results.head(1).RMSE.values[0]\n",
    "    top_feat = results.head(1).feat_name.values[0]\n",
    "\n",
    "    if top_score < best_rmse:\n",
    "        best_rmse = top_score\n",
    "        best_feat = top_feat\n",
    "        improved = True\n",
    "        print(f'Results improved!: Selected feat {top_feat} - score {top_score:.4f}')\n",
    "\n",
    "        ts_top_feat = top_feat.replace('train', 'test')\n",
    "        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{top_feat}')\n",
    "        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_top_feat}')\n",
    "\n",
    "        if round > 0:\n",
    "            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "        else:\n",
    "            train_feats = tr_feats\n",
    "            test_feats = ts_feats\n",
    "\n",
    "        added_feats.append(top_feat)\n",
    "        round += 1\n",
    "    else:\n",
    "        print('Training Over!')\n",
    "\n",
    "    list_train_feats = [feat for feat in list_train_feats if feat not in added_feats]\n",
    "    print(f'list_train_feats: {list_train_feats}')\n",
    "    print(f'added_feats_list: {added_feats}')\n",
    "    print(f'best feat: {top_feat}')\n",
    "\n",
    "print(f\"Best RMSE: {best_rmse:.4f}\")\n",
    "print(f\"Best Feature Set: {added_feats}\")\n",
    "best_feats.append(added_feats)\n",
    "added_feats = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
