{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import tensor\n",
    "import pandas as pd\n",
    "from torch.nn.functional import relu\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_feats(feats, scaler=StandardScaler()):\n",
    "    feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    feats.fillna(-1e10, inplace=True)\n",
    "    feats_columns = feats.columns\n",
    "    feats.loc[:, feats_columns != 'id'] = scaler.fit_transform(feats.loc[:, feats_columns != 'id'])\n",
    "    return feats\n",
    "\n",
    "def train_valid_split(data_x, data_y, train_idx, valid_idx):\n",
    "    x_train = data_x.iloc[train_idx]\n",
    "    y_train = data_y[train_idx]\n",
    "    x_valid = data_x.iloc[valid_idx]\n",
    "    y_valid = data_y[valid_idx]\n",
    "    return x_train, y_train, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, feat_dim) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feat_dim = feat_dim\n",
    "        self.input = nn.Linear(feat_dim, 64)\n",
    "        self.linear = nn.Linear(64,1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (self.input(x))\n",
    "        x = relu(self.linear(x))\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.read_pickle('feature_selection/train_feats.pkl')\n",
    "train_feats.iloc[:,:-1] = preprocess_feats(train_feats.iloc[:,:-1])\n",
    "\n",
    "x = tensor(train_feats.drop(['id','score'], axis=1).values.astype(np.float32))\n",
    "y = tensor(train_feats['score'].values.astype(np.float32))\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "model = MLPModel(x.shape[1])\n",
    "# Convert your data to TensorDataset for DataLoader\n",
    "train_data = TensorDataset(train_x, train_y)\n",
    "valid_data = TensorDataset(valid_x, valid_y)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "batch_size = 64  # You can adjust this\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Train RMSE: 0.6829, Valid RMSE: 0.4473\n",
      "Epoch 2/500, Train RMSE: 0.6720, Valid RMSE: 0.4403\n",
      "Epoch 3/500, Train RMSE: 0.6773, Valid RMSE: 0.4638\n",
      "Epoch 4/500, Train RMSE: 0.6829, Valid RMSE: 0.4477\n",
      "Epoch 5/500, Train RMSE: 0.6751, Valid RMSE: 0.4558\n",
      "Epoch 6/500, Train RMSE: 0.6912, Valid RMSE: 0.4450\n",
      "Epoch 7/500, Train RMSE: 0.6810, Valid RMSE: 0.4634\n",
      "Epoch 8/500, Train RMSE: 0.6771, Valid RMSE: 0.4533\n",
      "Epoch 9/500, Train RMSE: 0.6858, Valid RMSE: 0.4433\n",
      "Epoch 10/500, Train RMSE: 0.6780, Valid RMSE: 0.4341\n",
      "Epoch 11/500, Train RMSE: 0.6775, Valid RMSE: 0.4403\n",
      "Epoch 12/500, Train RMSE: 0.6776, Valid RMSE: 0.4358\n",
      "Epoch 13/500, Train RMSE: 0.6773, Valid RMSE: 0.4506\n",
      "Epoch 14/500, Train RMSE: 0.6849, Valid RMSE: 0.4593\n",
      "Epoch 15/500, Train RMSE: 0.6816, Valid RMSE: 0.4641\n",
      "Epoch 16/500, Train RMSE: 0.6955, Valid RMSE: 0.5595\n",
      "Epoch 17/500, Train RMSE: 0.6916, Valid RMSE: 0.4602\n",
      "Epoch 18/500, Train RMSE: 0.6781, Valid RMSE: 0.4545\n",
      "Epoch 19/500, Train RMSE: 0.6722, Valid RMSE: 0.4401\n",
      "Epoch 20/500, Train RMSE: 0.6830, Valid RMSE: 0.4511\n",
      "Epoch 21/500, Train RMSE: 0.6810, Valid RMSE: 0.4379\n",
      "Epoch 22/500, Train RMSE: 0.6748, Valid RMSE: 0.4387\n",
      "Epoch 23/500, Train RMSE: 0.6819, Valid RMSE: 0.4536\n",
      "Epoch 24/500, Train RMSE: 0.6848, Valid RMSE: 0.4500\n",
      "Epoch 25/500, Train RMSE: 0.6741, Valid RMSE: 0.4587\n",
      "Epoch 26/500, Train RMSE: 0.6751, Valid RMSE: 0.4779\n",
      "Epoch 27/500, Train RMSE: 0.6771, Valid RMSE: 0.4367\n",
      "Epoch 28/500, Train RMSE: 0.6776, Valid RMSE: 0.4356\n",
      "Epoch 29/500, Train RMSE: 0.6868, Valid RMSE: 0.4446\n",
      "Epoch 30/500, Train RMSE: 0.6904, Valid RMSE: 0.4434\n",
      "Epoch 31/500, Train RMSE: 0.6768, Valid RMSE: 0.4481\n",
      "Epoch 32/500, Train RMSE: 0.6777, Valid RMSE: 0.4508\n",
      "Epoch 33/500, Train RMSE: 0.6970, Valid RMSE: 0.5231\n",
      "Epoch 34/500, Train RMSE: 0.6859, Valid RMSE: 0.4586\n",
      "Epoch 35/500, Train RMSE: 0.6756, Valid RMSE: 0.4355\n",
      "Epoch 36/500, Train RMSE: 0.6837, Valid RMSE: 0.4487\n",
      "Epoch 37/500, Train RMSE: 0.6770, Valid RMSE: 0.4352\n",
      "Epoch 38/500, Train RMSE: 0.6769, Valid RMSE: 0.4604\n",
      "Epoch 39/500, Train RMSE: 0.6779, Valid RMSE: 0.4352\n",
      "Epoch 40/500, Train RMSE: 0.6769, Valid RMSE: 0.4425\n",
      "Epoch 41/500, Train RMSE: 0.6800, Valid RMSE: 0.4548\n",
      "Epoch 42/500, Train RMSE: 0.6779, Valid RMSE: 0.4480\n",
      "Epoch 43/500, Train RMSE: 0.6719, Valid RMSE: 0.4631\n",
      "Epoch 44/500, Train RMSE: 0.6765, Valid RMSE: 0.4503\n",
      "Epoch 45/500, Train RMSE: 0.6936, Valid RMSE: 0.4729\n",
      "Epoch 46/500, Train RMSE: 0.6761, Valid RMSE: 0.4370\n",
      "Epoch 47/500, Train RMSE: 0.6762, Valid RMSE: 0.4364\n",
      "Epoch 48/500, Train RMSE: 0.6792, Valid RMSE: 0.4632\n",
      "Epoch 49/500, Train RMSE: 0.6775, Valid RMSE: 0.4629\n",
      "Epoch 50/500, Train RMSE: 0.6781, Valid RMSE: 0.4496\n",
      "Epoch 51/500, Train RMSE: 0.6740, Valid RMSE: 0.4668\n",
      "Epoch 52/500, Train RMSE: 0.6919, Valid RMSE: 0.4407\n",
      "Epoch 53/500, Train RMSE: 0.6720, Valid RMSE: 0.4647\n",
      "Epoch 54/500, Train RMSE: 0.6772, Valid RMSE: 0.4479\n",
      "Epoch 55/500, Train RMSE: 0.6809, Valid RMSE: 0.4520\n",
      "Epoch 56/500, Train RMSE: 0.6752, Valid RMSE: 0.4550\n",
      "Epoch 57/500, Train RMSE: 0.6918, Valid RMSE: 0.4731\n",
      "Epoch 58/500, Train RMSE: 0.6736, Valid RMSE: 0.4526\n",
      "Epoch 59/500, Train RMSE: 0.6752, Valid RMSE: 0.4380\n",
      "Epoch 60/500, Train RMSE: 0.6759, Valid RMSE: 0.4826\n",
      "Epoch 61/500, Train RMSE: 0.6774, Valid RMSE: 0.4381\n",
      "Epoch 62/500, Train RMSE: 0.6845, Valid RMSE: 0.4637\n",
      "Epoch 63/500, Train RMSE: 0.6735, Valid RMSE: 0.4624\n",
      "Epoch 64/500, Train RMSE: 0.6725, Valid RMSE: 0.4331\n",
      "Epoch 65/500, Train RMSE: 0.6734, Valid RMSE: 0.4456\n",
      "Epoch 66/500, Train RMSE: 0.6732, Valid RMSE: 0.4330\n",
      "Epoch 67/500, Train RMSE: 0.6736, Valid RMSE: 0.4422\n",
      "Epoch 68/500, Train RMSE: 0.6764, Valid RMSE: 0.4401\n",
      "Epoch 69/500, Train RMSE: 0.6700, Valid RMSE: 0.4340\n",
      "Epoch 70/500, Train RMSE: 0.6673, Valid RMSE: 0.4495\n",
      "Epoch 71/500, Train RMSE: 0.6725, Valid RMSE: 0.4405\n",
      "Epoch 72/500, Train RMSE: 0.6656, Valid RMSE: 0.4512\n",
      "Epoch 73/500, Train RMSE: 0.6560, Valid RMSE: 0.4361\n",
      "Epoch 74/500, Train RMSE: 0.6540, Valid RMSE: 0.4484\n",
      "Epoch 75/500, Train RMSE: 0.6629, Valid RMSE: 0.4381\n",
      "Epoch 76/500, Train RMSE: 0.6551, Valid RMSE: 0.4374\n",
      "Epoch 77/500, Train RMSE: 0.6523, Valid RMSE: 0.4481\n",
      "Epoch 78/500, Train RMSE: 0.6570, Valid RMSE: 0.4394\n",
      "Epoch 79/500, Train RMSE: 0.6524, Valid RMSE: 0.4409\n",
      "Epoch 80/500, Train RMSE: 0.6583, Valid RMSE: 0.4425\n",
      "Epoch 81/500, Train RMSE: 0.6519, Valid RMSE: 0.4350\n",
      "Epoch 82/500, Train RMSE: 0.6535, Valid RMSE: 0.4365\n",
      "Epoch 83/500, Train RMSE: 0.6528, Valid RMSE: 0.4318\n",
      "Epoch 84/500, Train RMSE: 0.6486, Valid RMSE: 0.4360\n",
      "Epoch 85/500, Train RMSE: 0.6577, Valid RMSE: 0.4432\n",
      "Epoch 86/500, Train RMSE: 0.6546, Valid RMSE: 0.4499\n",
      "Epoch 87/500, Train RMSE: 0.6645, Valid RMSE: 0.4609\n",
      "Epoch 88/500, Train RMSE: 0.6578, Valid RMSE: 0.4556\n",
      "Epoch 89/500, Train RMSE: 0.6526, Valid RMSE: 0.4684\n",
      "Epoch 90/500, Train RMSE: 0.6575, Valid RMSE: 0.4358\n",
      "Epoch 91/500, Train RMSE: 0.6495, Valid RMSE: 0.4264\n",
      "Epoch 92/500, Train RMSE: 0.6514, Valid RMSE: 0.4349\n",
      "Epoch 93/500, Train RMSE: 0.6547, Valid RMSE: 0.4334\n",
      "Epoch 94/500, Train RMSE: 0.6499, Valid RMSE: 0.4447\n",
      "Epoch 95/500, Train RMSE: 0.6555, Valid RMSE: 0.4443\n",
      "Epoch 96/500, Train RMSE: 0.6511, Valid RMSE: 0.4289\n",
      "Epoch 97/500, Train RMSE: 0.6508, Valid RMSE: 0.4336\n",
      "Epoch 98/500, Train RMSE: 0.6560, Valid RMSE: 0.4340\n",
      "Epoch 99/500, Train RMSE: 0.6503, Valid RMSE: 0.4338\n",
      "Epoch 100/500, Train RMSE: 0.6566, Valid RMSE: 0.4501\n",
      "Epoch 101/500, Train RMSE: 0.6603, Valid RMSE: 0.4402\n",
      "Epoch 102/500, Train RMSE: 0.6521, Valid RMSE: 0.4528\n",
      "Epoch 103/500, Train RMSE: 0.6575, Valid RMSE: 0.4625\n",
      "Epoch 104/500, Train RMSE: 0.6530, Valid RMSE: 0.4515\n",
      "Epoch 105/500, Train RMSE: 0.6551, Valid RMSE: 0.4389\n",
      "Epoch 106/500, Train RMSE: 0.6582, Valid RMSE: 0.4454\n",
      "Epoch 107/500, Train RMSE: 0.6502, Valid RMSE: 0.4780\n",
      "Epoch 108/500, Train RMSE: 0.6589, Valid RMSE: 0.4396\n",
      "Epoch 109/500, Train RMSE: 0.6589, Valid RMSE: 0.4597\n",
      "Epoch 110/500, Train RMSE: 0.6513, Valid RMSE: 0.4404\n",
      "Epoch 111/500, Train RMSE: 0.6563, Valid RMSE: 0.4337\n",
      "Epoch 112/500, Train RMSE: 0.6512, Valid RMSE: 0.4284\n",
      "Epoch 113/500, Train RMSE: 0.6586, Valid RMSE: 0.4417\n",
      "Epoch 114/500, Train RMSE: 0.6581, Valid RMSE: 0.4507\n",
      "Epoch 115/500, Train RMSE: 0.6524, Valid RMSE: 0.4378\n",
      "Epoch 116/500, Train RMSE: 0.6554, Valid RMSE: 0.4408\n",
      "Epoch 117/500, Train RMSE: 0.6632, Valid RMSE: 0.4671\n",
      "Epoch 118/500, Train RMSE: 0.6599, Valid RMSE: 0.4558\n",
      "Epoch 119/500, Train RMSE: 0.6560, Valid RMSE: 0.4424\n",
      "Epoch 120/500, Train RMSE: 0.6555, Valid RMSE: 0.4375\n",
      "Epoch 121/500, Train RMSE: 0.6510, Valid RMSE: 0.4397\n",
      "Epoch 122/500, Train RMSE: 0.6539, Valid RMSE: 0.4381\n",
      "Epoch 123/500, Train RMSE: 0.6669, Valid RMSE: 0.4820\n",
      "Epoch 124/500, Train RMSE: 0.6619, Valid RMSE: 0.4354\n",
      "Epoch 125/500, Train RMSE: 0.6565, Valid RMSE: 0.4480\n",
      "Epoch 126/500, Train RMSE: 0.6523, Valid RMSE: 0.4542\n",
      "Epoch 127/500, Train RMSE: 0.6601, Valid RMSE: 0.4392\n",
      "Epoch 128/500, Train RMSE: 0.6502, Valid RMSE: 0.4472\n",
      "Epoch 129/500, Train RMSE: 0.6566, Valid RMSE: 0.4458\n",
      "Epoch 130/500, Train RMSE: 0.6516, Valid RMSE: 0.4311\n",
      "Epoch 131/500, Train RMSE: 0.6511, Valid RMSE: 0.4410\n",
      "Epoch 132/500, Train RMSE: 0.6556, Valid RMSE: 0.4467\n",
      "Epoch 133/500, Train RMSE: 0.6572, Valid RMSE: 0.4468\n",
      "Epoch 134/500, Train RMSE: 0.6528, Valid RMSE: 0.4454\n",
      "Epoch 135/500, Train RMSE: 0.6511, Valid RMSE: 0.4326\n",
      "Epoch 136/500, Train RMSE: 0.6492, Valid RMSE: 0.4414\n",
      "Epoch 137/500, Train RMSE: 0.6503, Valid RMSE: 0.4304\n",
      "Epoch 138/500, Train RMSE: 0.6513, Valid RMSE: 0.4472\n",
      "Epoch 139/500, Train RMSE: 0.6547, Valid RMSE: 0.4328\n",
      "Epoch 140/500, Train RMSE: 0.6574, Valid RMSE: 0.4492\n",
      "Epoch 141/500, Train RMSE: 0.6514, Valid RMSE: 0.4420\n",
      "Epoch 142/500, Train RMSE: 0.6570, Valid RMSE: 0.4473\n",
      "Epoch 143/500, Train RMSE: 0.6594, Valid RMSE: 0.4398\n",
      "Epoch 144/500, Train RMSE: 0.6620, Valid RMSE: 0.4394\n",
      "Epoch 145/500, Train RMSE: 0.6506, Valid RMSE: 0.4339\n",
      "Epoch 146/500, Train RMSE: 0.6507, Valid RMSE: 0.4622\n",
      "Epoch 147/500, Train RMSE: 0.6511, Valid RMSE: 0.4351\n",
      "Epoch 148/500, Train RMSE: 0.6519, Valid RMSE: 0.4380\n",
      "Epoch 149/500, Train RMSE: 0.6541, Valid RMSE: 0.4431\n",
      "Epoch 150/500, Train RMSE: 0.6531, Valid RMSE: 0.4460\n",
      "Epoch 151/500, Train RMSE: 0.6544, Valid RMSE: 0.4285\n",
      "Epoch 152/500, Train RMSE: 0.6555, Valid RMSE: 0.4389\n",
      "Epoch 153/500, Train RMSE: 0.6513, Valid RMSE: 0.4502\n",
      "Epoch 154/500, Train RMSE: 0.6483, Valid RMSE: 0.4376\n",
      "Epoch 155/500, Train RMSE: 0.6551, Valid RMSE: 0.4345\n",
      "Epoch 156/500, Train RMSE: 0.6489, Valid RMSE: 0.4400\n",
      "Epoch 157/500, Train RMSE: 0.6506, Valid RMSE: 0.4369\n",
      "Epoch 158/500, Train RMSE: 0.6501, Valid RMSE: 0.4435\n",
      "Epoch 159/500, Train RMSE: 0.6502, Valid RMSE: 0.4528\n",
      "Epoch 160/500, Train RMSE: 0.6580, Valid RMSE: 0.4347\n",
      "Epoch 161/500, Train RMSE: 0.6518, Valid RMSE: 0.4461\n",
      "Epoch 162/500, Train RMSE: 0.6563, Valid RMSE: 0.4744\n",
      "Epoch 163/500, Train RMSE: 0.6487, Valid RMSE: 0.4374\n",
      "Epoch 164/500, Train RMSE: 0.6519, Valid RMSE: 0.4415\n",
      "Epoch 165/500, Train RMSE: 0.6522, Valid RMSE: 0.4320\n",
      "Epoch 166/500, Train RMSE: 0.6543, Valid RMSE: 0.4352\n",
      "Epoch 167/500, Train RMSE: 0.6499, Valid RMSE: 0.4297\n",
      "Epoch 168/500, Train RMSE: 0.6496, Valid RMSE: 0.4391\n",
      "Epoch 169/500, Train RMSE: 0.6516, Valid RMSE: 0.4518\n",
      "Epoch 170/500, Train RMSE: 0.6518, Valid RMSE: 0.4559\n",
      "Epoch 171/500, Train RMSE: 0.6539, Valid RMSE: 0.4482\n",
      "Epoch 172/500, Train RMSE: 0.6652, Valid RMSE: 0.4545\n",
      "Epoch 173/500, Train RMSE: 0.6574, Valid RMSE: 0.4566\n",
      "Epoch 174/500, Train RMSE: 0.6533, Valid RMSE: 0.4327\n",
      "Epoch 175/500, Train RMSE: 0.6515, Valid RMSE: 0.4330\n",
      "Epoch 176/500, Train RMSE: 0.6476, Valid RMSE: 0.4431\n",
      "Epoch 177/500, Train RMSE: 0.6566, Valid RMSE: 0.4407\n",
      "Epoch 178/500, Train RMSE: 0.6507, Valid RMSE: 0.4489\n",
      "Epoch 179/500, Train RMSE: 0.6520, Valid RMSE: 0.4389\n",
      "Epoch 180/500, Train RMSE: 0.6508, Valid RMSE: 0.4422\n",
      "Epoch 181/500, Train RMSE: 0.6542, Valid RMSE: 0.4531\n",
      "Epoch 182/500, Train RMSE: 0.6515, Valid RMSE: 0.4413\n",
      "Epoch 183/500, Train RMSE: 0.6496, Valid RMSE: 0.4309\n",
      "Epoch 184/500, Train RMSE: 0.6507, Valid RMSE: 0.4321\n",
      "Epoch 185/500, Train RMSE: 0.6487, Valid RMSE: 0.4399\n",
      "Epoch 186/500, Train RMSE: 0.6509, Valid RMSE: 0.4328\n",
      "Epoch 187/500, Train RMSE: 0.6524, Valid RMSE: 0.4503\n",
      "Epoch 188/500, Train RMSE: 0.6561, Valid RMSE: 0.4417\n",
      "Epoch 189/500, Train RMSE: 0.6483, Valid RMSE: 0.4389\n",
      "Epoch 190/500, Train RMSE: 0.6536, Valid RMSE: 0.4616\n",
      "Epoch 191/500, Train RMSE: 0.6578, Valid RMSE: 0.4319\n",
      "Epoch 192/500, Train RMSE: 0.6505, Valid RMSE: 0.4331\n",
      "Epoch 193/500, Train RMSE: 0.6526, Valid RMSE: 0.4466\n",
      "Epoch 194/500, Train RMSE: 0.6501, Valid RMSE: 0.4563\n",
      "Epoch 195/500, Train RMSE: 0.6541, Valid RMSE: 0.4681\n",
      "Epoch 196/500, Train RMSE: 0.6537, Valid RMSE: 0.4429\n",
      "Epoch 197/500, Train RMSE: 0.6514, Valid RMSE: 0.4396\n",
      "Epoch 198/500, Train RMSE: 0.6526, Valid RMSE: 0.4440\n",
      "Epoch 199/500, Train RMSE: 0.6520, Valid RMSE: 0.4415\n",
      "Epoch 200/500, Train RMSE: 0.6498, Valid RMSE: 0.4409\n",
      "Epoch 201/500, Train RMSE: 0.6512, Valid RMSE: 0.4388\n",
      "Epoch 202/500, Train RMSE: 0.6570, Valid RMSE: 0.4348\n",
      "Epoch 203/500, Train RMSE: 0.6556, Valid RMSE: 0.4594\n",
      "Epoch 204/500, Train RMSE: 0.6528, Valid RMSE: 0.4472\n",
      "Epoch 205/500, Train RMSE: 0.6504, Valid RMSE: 0.4374\n",
      "Epoch 206/500, Train RMSE: 0.6551, Valid RMSE: 0.4365\n",
      "Epoch 207/500, Train RMSE: 0.6487, Valid RMSE: 0.4344\n",
      "Epoch 208/500, Train RMSE: 0.6449, Valid RMSE: 0.4445\n",
      "Epoch 209/500, Train RMSE: 0.6504, Valid RMSE: 0.4335\n",
      "Epoch 210/500, Train RMSE: 0.6471, Valid RMSE: 0.4316\n",
      "Epoch 211/500, Train RMSE: 0.6497, Valid RMSE: 0.4345\n",
      "Epoch 212/500, Train RMSE: 0.6470, Valid RMSE: 0.4529\n",
      "Epoch 213/500, Train RMSE: 0.6498, Valid RMSE: 0.4382\n",
      "Epoch 214/500, Train RMSE: 0.6461, Valid RMSE: 0.4511\n",
      "Epoch 215/500, Train RMSE: 0.6518, Valid RMSE: 0.4301\n",
      "Epoch 216/500, Train RMSE: 0.6531, Valid RMSE: 0.4359\n",
      "Epoch 217/500, Train RMSE: 0.6541, Valid RMSE: 0.4419\n",
      "Epoch 218/500, Train RMSE: 0.6537, Valid RMSE: 0.4352\n",
      "Epoch 219/500, Train RMSE: 0.6483, Valid RMSE: 0.4300\n",
      "Epoch 220/500, Train RMSE: 0.6511, Valid RMSE: 0.4342\n",
      "Epoch 221/500, Train RMSE: 0.6493, Valid RMSE: 0.4420\n",
      "Epoch 222/500, Train RMSE: 0.6498, Valid RMSE: 0.4337\n",
      "Epoch 223/500, Train RMSE: 0.6479, Valid RMSE: 0.4308\n",
      "Epoch 224/500, Train RMSE: 0.6487, Valid RMSE: 0.4487\n",
      "Epoch 225/500, Train RMSE: 0.6499, Valid RMSE: 0.4476\n",
      "Epoch 226/500, Train RMSE: 0.6532, Valid RMSE: 0.4515\n",
      "Epoch 227/500, Train RMSE: 0.6551, Valid RMSE: 0.4387\n",
      "Epoch 228/500, Train RMSE: 0.6543, Valid RMSE: 0.4389\n",
      "Epoch 229/500, Train RMSE: 0.6482, Valid RMSE: 0.4356\n",
      "Epoch 230/500, Train RMSE: 0.6492, Valid RMSE: 0.4285\n",
      "Epoch 231/500, Train RMSE: 0.6479, Valid RMSE: 0.4479\n",
      "Epoch 232/500, Train RMSE: 0.6494, Valid RMSE: 0.4366\n",
      "Epoch 233/500, Train RMSE: 0.6487, Valid RMSE: 0.4626\n",
      "Epoch 234/500, Train RMSE: 0.6577, Valid RMSE: 0.4370\n",
      "Epoch 235/500, Train RMSE: 0.6511, Valid RMSE: 0.4313\n",
      "Epoch 236/500, Train RMSE: 0.6486, Valid RMSE: 0.4399\n",
      "Epoch 237/500, Train RMSE: 0.6629, Valid RMSE: 0.4362\n",
      "Epoch 238/500, Train RMSE: 0.6521, Valid RMSE: 0.4451\n",
      "Epoch 239/500, Train RMSE: 0.6526, Valid RMSE: 0.4373\n",
      "Epoch 240/500, Train RMSE: 0.6459, Valid RMSE: 0.4429\n",
      "Epoch 241/500, Train RMSE: 0.6510, Valid RMSE: 0.4326\n",
      "Epoch 242/500, Train RMSE: 0.6536, Valid RMSE: 0.4335\n",
      "Epoch 243/500, Train RMSE: 0.6521, Valid RMSE: 0.4444\n",
      "Epoch 244/500, Train RMSE: 0.6492, Valid RMSE: 0.4375\n",
      "Epoch 245/500, Train RMSE: 0.6555, Valid RMSE: 0.4482\n",
      "Epoch 246/500, Train RMSE: 0.6520, Valid RMSE: 0.4346\n",
      "Epoch 247/500, Train RMSE: 0.6486, Valid RMSE: 0.4393\n",
      "Epoch 248/500, Train RMSE: 0.6516, Valid RMSE: 0.4412\n",
      "Epoch 249/500, Train RMSE: 0.6507, Valid RMSE: 0.4422\n",
      "Epoch 250/500, Train RMSE: 0.6513, Valid RMSE: 0.4479\n",
      "Epoch 251/500, Train RMSE: 0.6490, Valid RMSE: 0.4368\n",
      "Epoch 252/500, Train RMSE: 0.6476, Valid RMSE: 0.4313\n",
      "Epoch 253/500, Train RMSE: 0.6483, Valid RMSE: 0.4453\n",
      "Epoch 254/500, Train RMSE: 0.6483, Valid RMSE: 0.4411\n",
      "Epoch 255/500, Train RMSE: 0.6646, Valid RMSE: 0.4418\n",
      "Epoch 256/500, Train RMSE: 0.6505, Valid RMSE: 0.4369\n",
      "Epoch 257/500, Train RMSE: 0.6494, Valid RMSE: 0.4332\n",
      "Epoch 258/500, Train RMSE: 0.6518, Valid RMSE: 0.4348\n",
      "Epoch 259/500, Train RMSE: 0.6518, Valid RMSE: 0.4444\n",
      "Epoch 260/500, Train RMSE: 0.6518, Valid RMSE: 0.4351\n",
      "Epoch 261/500, Train RMSE: 0.6511, Valid RMSE: 0.4422\n",
      "Epoch 262/500, Train RMSE: 0.6501, Valid RMSE: 0.4347\n",
      "Epoch 263/500, Train RMSE: 0.6468, Valid RMSE: 0.4325\n",
      "Epoch 264/500, Train RMSE: 0.6519, Valid RMSE: 0.4391\n",
      "Epoch 265/500, Train RMSE: 0.6524, Valid RMSE: 0.4376\n",
      "Epoch 266/500, Train RMSE: 0.6480, Valid RMSE: 0.4392\n",
      "Epoch 267/500, Train RMSE: 0.6507, Valid RMSE: 0.4456\n",
      "Epoch 268/500, Train RMSE: 0.6535, Valid RMSE: 0.4418\n",
      "Epoch 269/500, Train RMSE: 0.6475, Valid RMSE: 0.4342\n",
      "Epoch 270/500, Train RMSE: 0.6491, Valid RMSE: 0.4576\n",
      "Epoch 271/500, Train RMSE: 0.6500, Valid RMSE: 0.4386\n",
      "Epoch 272/500, Train RMSE: 0.6438, Valid RMSE: 0.4337\n",
      "Epoch 273/500, Train RMSE: 0.6490, Valid RMSE: 0.4349\n",
      "Epoch 274/500, Train RMSE: 0.6491, Valid RMSE: 0.4498\n",
      "Epoch 275/500, Train RMSE: 0.6483, Valid RMSE: 0.4393\n",
      "Epoch 276/500, Train RMSE: 0.6504, Valid RMSE: 0.4346\n",
      "Epoch 277/500, Train RMSE: 0.6531, Valid RMSE: 0.4286\n",
      "Epoch 278/500, Train RMSE: 0.6479, Valid RMSE: 0.4598\n",
      "Epoch 279/500, Train RMSE: 0.6628, Valid RMSE: 0.4412\n",
      "Epoch 280/500, Train RMSE: 0.6506, Valid RMSE: 0.4331\n",
      "Epoch 281/500, Train RMSE: 0.6511, Valid RMSE: 0.4391\n",
      "Epoch 282/500, Train RMSE: 0.6478, Valid RMSE: 0.4481\n",
      "Epoch 283/500, Train RMSE: 0.6509, Valid RMSE: 0.4399\n",
      "Epoch 284/500, Train RMSE: 0.6484, Valid RMSE: 0.4416\n",
      "Epoch 285/500, Train RMSE: 0.6468, Valid RMSE: 0.4378\n",
      "Epoch 286/500, Train RMSE: 0.6556, Valid RMSE: 0.4619\n",
      "Epoch 287/500, Train RMSE: 0.6497, Valid RMSE: 0.4328\n",
      "Epoch 288/500, Train RMSE: 0.6468, Valid RMSE: 0.4484\n",
      "Epoch 289/500, Train RMSE: 0.6488, Valid RMSE: 0.4571\n",
      "Epoch 290/500, Train RMSE: 0.6535, Valid RMSE: 0.4396\n",
      "Epoch 291/500, Train RMSE: 0.6500, Valid RMSE: 0.4475\n",
      "Epoch 292/500, Train RMSE: 0.6479, Valid RMSE: 0.4337\n",
      "Epoch 293/500, Train RMSE: 0.6524, Valid RMSE: 0.4537\n",
      "Epoch 294/500, Train RMSE: 0.6503, Valid RMSE: 0.4423\n",
      "Epoch 295/500, Train RMSE: 0.6515, Valid RMSE: 0.4327\n",
      "Epoch 296/500, Train RMSE: 0.6484, Valid RMSE: 0.4353\n",
      "Epoch 297/500, Train RMSE: 0.6497, Valid RMSE: 0.4350\n",
      "Epoch 298/500, Train RMSE: 0.6519, Valid RMSE: 0.4393\n",
      "Epoch 299/500, Train RMSE: 0.6491, Valid RMSE: 0.4458\n",
      "Epoch 300/500, Train RMSE: 0.6529, Valid RMSE: 0.4457\n",
      "Epoch 301/500, Train RMSE: 0.6455, Valid RMSE: 0.4408\n",
      "Epoch 302/500, Train RMSE: 0.6521, Valid RMSE: 0.4391\n",
      "Epoch 303/500, Train RMSE: 0.6510, Valid RMSE: 0.4390\n",
      "Epoch 304/500, Train RMSE: 0.6560, Valid RMSE: 0.4407\n",
      "Epoch 305/500, Train RMSE: 0.6514, Valid RMSE: 0.4440\n",
      "Epoch 306/500, Train RMSE: 0.6504, Valid RMSE: 0.4320\n",
      "Epoch 307/500, Train RMSE: 0.6457, Valid RMSE: 0.4372\n",
      "Epoch 308/500, Train RMSE: 0.6494, Valid RMSE: 0.4384\n",
      "Epoch 309/500, Train RMSE: 0.6509, Valid RMSE: 0.4331\n",
      "Epoch 310/500, Train RMSE: 0.6552, Valid RMSE: 0.4533\n",
      "Epoch 311/500, Train RMSE: 0.6492, Valid RMSE: 0.4375\n",
      "Epoch 312/500, Train RMSE: 0.6501, Valid RMSE: 0.4352\n",
      "Epoch 313/500, Train RMSE: 0.6479, Valid RMSE: 0.4314\n",
      "Epoch 314/500, Train RMSE: 0.6482, Valid RMSE: 0.4369\n",
      "Epoch 315/500, Train RMSE: 0.6472, Valid RMSE: 0.4280\n",
      "Epoch 316/500, Train RMSE: 0.6492, Valid RMSE: 0.4356\n",
      "Epoch 317/500, Train RMSE: 0.6504, Valid RMSE: 0.4320\n",
      "Epoch 318/500, Train RMSE: 0.6550, Valid RMSE: 0.4512\n",
      "Epoch 319/500, Train RMSE: 0.6503, Valid RMSE: 0.4337\n",
      "Epoch 320/500, Train RMSE: 0.6529, Valid RMSE: 0.4494\n",
      "Epoch 321/500, Train RMSE: 0.6469, Valid RMSE: 0.4348\n",
      "Epoch 322/500, Train RMSE: 0.6473, Valid RMSE: 0.4346\n",
      "Epoch 323/500, Train RMSE: 0.6503, Valid RMSE: 0.4340\n",
      "Epoch 324/500, Train RMSE: 0.6469, Valid RMSE: 0.4336\n",
      "Epoch 325/500, Train RMSE: 0.6462, Valid RMSE: 0.4355\n",
      "Epoch 326/500, Train RMSE: 0.6522, Valid RMSE: 0.4298\n",
      "Epoch 327/500, Train RMSE: 0.6505, Valid RMSE: 0.4325\n",
      "Epoch 328/500, Train RMSE: 0.6481, Valid RMSE: 0.4303\n",
      "Epoch 329/500, Train RMSE: 0.6497, Valid RMSE: 0.4362\n",
      "Epoch 330/500, Train RMSE: 0.6548, Valid RMSE: 0.4437\n",
      "Epoch 331/500, Train RMSE: 0.6564, Valid RMSE: 0.4363\n",
      "Epoch 332/500, Train RMSE: 0.6504, Valid RMSE: 0.4346\n",
      "Epoch 333/500, Train RMSE: 0.6485, Valid RMSE: 0.4362\n",
      "Epoch 334/500, Train RMSE: 0.6477, Valid RMSE: 0.4323\n",
      "Epoch 335/500, Train RMSE: 0.6467, Valid RMSE: 0.4378\n",
      "Epoch 336/500, Train RMSE: 0.6514, Valid RMSE: 0.4481\n",
      "Epoch 337/500, Train RMSE: 0.6486, Valid RMSE: 0.4367\n",
      "Epoch 338/500, Train RMSE: 0.6505, Valid RMSE: 0.4599\n",
      "Epoch 339/500, Train RMSE: 0.6502, Valid RMSE: 0.4319\n",
      "Epoch 340/500, Train RMSE: 0.6498, Valid RMSE: 0.4378\n",
      "Epoch 341/500, Train RMSE: 0.6512, Valid RMSE: 0.4486\n",
      "Epoch 342/500, Train RMSE: 0.6470, Valid RMSE: 0.4313\n",
      "Epoch 343/500, Train RMSE: 0.6487, Valid RMSE: 0.4356\n",
      "Epoch 344/500, Train RMSE: 0.6469, Valid RMSE: 0.4341\n",
      "Epoch 345/500, Train RMSE: 0.6487, Valid RMSE: 0.4407\n",
      "Epoch 346/500, Train RMSE: 0.6461, Valid RMSE: 0.4341\n",
      "Epoch 347/500, Train RMSE: 0.6456, Valid RMSE: 0.4340\n",
      "Epoch 348/500, Train RMSE: 0.6460, Valid RMSE: 0.4358\n",
      "Epoch 349/500, Train RMSE: 0.6489, Valid RMSE: 0.4447\n",
      "Epoch 350/500, Train RMSE: 0.6495, Valid RMSE: 0.4359\n",
      "Epoch 351/500, Train RMSE: 0.6547, Valid RMSE: 0.4439\n",
      "Epoch 352/500, Train RMSE: 0.6484, Valid RMSE: 0.4362\n",
      "Epoch 353/500, Train RMSE: 0.6472, Valid RMSE: 0.4301\n",
      "Epoch 354/500, Train RMSE: 0.6479, Valid RMSE: 0.4328\n",
      "Epoch 355/500, Train RMSE: 0.6470, Valid RMSE: 0.4449\n",
      "Epoch 356/500, Train RMSE: 0.6482, Valid RMSE: 0.4344\n",
      "Epoch 357/500, Train RMSE: 0.6548, Valid RMSE: 0.4378\n",
      "Epoch 358/500, Train RMSE: 0.6498, Valid RMSE: 0.4399\n",
      "Epoch 359/500, Train RMSE: 0.6480, Valid RMSE: 0.4310\n",
      "Epoch 360/500, Train RMSE: 0.6466, Valid RMSE: 0.4467\n",
      "Epoch 361/500, Train RMSE: 0.6504, Valid RMSE: 0.4330\n",
      "Epoch 362/500, Train RMSE: 0.6495, Valid RMSE: 0.4299\n",
      "Epoch 363/500, Train RMSE: 0.6455, Valid RMSE: 0.4405\n",
      "Epoch 364/500, Train RMSE: 0.6483, Valid RMSE: 0.4373\n",
      "Epoch 365/500, Train RMSE: 0.6507, Valid RMSE: 0.4352\n",
      "Epoch 366/500, Train RMSE: 0.6503, Valid RMSE: 0.4343\n",
      "Epoch 367/500, Train RMSE: 0.6488, Valid RMSE: 0.4399\n",
      "Epoch 368/500, Train RMSE: 0.6537, Valid RMSE: 0.4389\n",
      "Epoch 369/500, Train RMSE: 0.6529, Valid RMSE: 0.4765\n",
      "Epoch 370/500, Train RMSE: 0.6509, Valid RMSE: 0.4404\n",
      "Epoch 371/500, Train RMSE: 0.6485, Valid RMSE: 0.4302\n",
      "Epoch 372/500, Train RMSE: 0.6478, Valid RMSE: 0.4345\n",
      "Epoch 373/500, Train RMSE: 0.6457, Valid RMSE: 0.4375\n",
      "Epoch 374/500, Train RMSE: 0.6435, Valid RMSE: 0.4415\n",
      "Epoch 375/500, Train RMSE: 0.6487, Valid RMSE: 0.4378\n",
      "Epoch 376/500, Train RMSE: 0.6471, Valid RMSE: 0.4322\n",
      "Epoch 377/500, Train RMSE: 0.6452, Valid RMSE: 0.4343\n",
      "Epoch 378/500, Train RMSE: 0.6463, Valid RMSE: 0.4431\n",
      "Epoch 379/500, Train RMSE: 0.6463, Valid RMSE: 0.4396\n",
      "Epoch 380/500, Train RMSE: 0.6482, Valid RMSE: 0.4481\n",
      "Epoch 381/500, Train RMSE: 0.6457, Valid RMSE: 0.4424\n",
      "Epoch 382/500, Train RMSE: 0.6445, Valid RMSE: 0.4419\n",
      "Epoch 383/500, Train RMSE: 0.6522, Valid RMSE: 0.4382\n",
      "Epoch 384/500, Train RMSE: 0.6475, Valid RMSE: 0.4532\n",
      "Epoch 385/500, Train RMSE: 0.6515, Valid RMSE: 0.4327\n",
      "Epoch 386/500, Train RMSE: 0.6467, Valid RMSE: 0.4350\n",
      "Epoch 387/500, Train RMSE: 0.6500, Valid RMSE: 0.4304\n",
      "Epoch 388/500, Train RMSE: 0.6462, Valid RMSE: 0.4329\n",
      "Epoch 389/500, Train RMSE: 0.6421, Valid RMSE: 0.4336\n",
      "Epoch 390/500, Train RMSE: 0.6450, Valid RMSE: 0.4337\n",
      "Epoch 391/500, Train RMSE: 0.6462, Valid RMSE: 0.4386\n",
      "Epoch 392/500, Train RMSE: 0.6481, Valid RMSE: 0.4490\n",
      "Epoch 393/500, Train RMSE: 0.6528, Valid RMSE: 0.4420\n",
      "Epoch 394/500, Train RMSE: 0.6494, Valid RMSE: 0.4310\n",
      "Epoch 395/500, Train RMSE: 0.6479, Valid RMSE: 0.4345\n",
      "Epoch 396/500, Train RMSE: 0.6470, Valid RMSE: 0.4411\n",
      "Epoch 397/500, Train RMSE: 0.6459, Valid RMSE: 0.4353\n",
      "Epoch 398/500, Train RMSE: 0.6494, Valid RMSE: 0.4443\n",
      "Epoch 399/500, Train RMSE: 0.6501, Valid RMSE: 0.4326\n",
      "Epoch 400/500, Train RMSE: 0.6465, Valid RMSE: 0.4459\n",
      "Epoch 401/500, Train RMSE: 0.6462, Valid RMSE: 0.4342\n",
      "Epoch 402/500, Train RMSE: 0.6506, Valid RMSE: 0.4418\n",
      "Epoch 403/500, Train RMSE: 0.6473, Valid RMSE: 0.4365\n",
      "Epoch 404/500, Train RMSE: 0.6496, Valid RMSE: 0.4353\n",
      "Epoch 405/500, Train RMSE: 0.6480, Valid RMSE: 0.4337\n",
      "Epoch 406/500, Train RMSE: 0.6476, Valid RMSE: 0.4344\n",
      "Epoch 407/500, Train RMSE: 0.6469, Valid RMSE: 0.4382\n",
      "Epoch 408/500, Train RMSE: 0.6544, Valid RMSE: 0.4433\n",
      "Epoch 409/500, Train RMSE: 0.6461, Valid RMSE: 0.4314\n",
      "Epoch 410/500, Train RMSE: 0.6463, Valid RMSE: 0.4436\n",
      "Epoch 411/500, Train RMSE: 0.6525, Valid RMSE: 0.4379\n",
      "Epoch 412/500, Train RMSE: 0.6469, Valid RMSE: 0.4355\n",
      "Epoch 413/500, Train RMSE: 0.6480, Valid RMSE: 0.4595\n",
      "Epoch 414/500, Train RMSE: 0.6501, Valid RMSE: 0.4502\n",
      "Epoch 415/500, Train RMSE: 0.6474, Valid RMSE: 0.4342\n",
      "Epoch 416/500, Train RMSE: 0.6497, Valid RMSE: 0.4457\n",
      "Epoch 417/500, Train RMSE: 0.6488, Valid RMSE: 0.4381\n",
      "Epoch 418/500, Train RMSE: 0.6482, Valid RMSE: 0.4350\n",
      "Epoch 419/500, Train RMSE: 0.6493, Valid RMSE: 0.4354\n",
      "Epoch 420/500, Train RMSE: 0.6450, Valid RMSE: 0.4554\n",
      "Epoch 421/500, Train RMSE: 0.6505, Valid RMSE: 0.4390\n",
      "Epoch 422/500, Train RMSE: 0.6475, Valid RMSE: 0.4335\n",
      "Epoch 423/500, Train RMSE: 0.6470, Valid RMSE: 0.4393\n",
      "Epoch 424/500, Train RMSE: 0.6484, Valid RMSE: 0.4447\n",
      "Epoch 425/500, Train RMSE: 0.6494, Valid RMSE: 0.4327\n",
      "Epoch 426/500, Train RMSE: 0.6502, Valid RMSE: 0.4364\n",
      "Epoch 427/500, Train RMSE: 0.6469, Valid RMSE: 0.4396\n",
      "Epoch 428/500, Train RMSE: 0.6479, Valid RMSE: 0.4317\n",
      "Epoch 429/500, Train RMSE: 0.6468, Valid RMSE: 0.4586\n",
      "Epoch 430/500, Train RMSE: 0.6509, Valid RMSE: 0.4300\n",
      "Epoch 431/500, Train RMSE: 0.6447, Valid RMSE: 0.4472\n",
      "Epoch 432/500, Train RMSE: 0.6501, Valid RMSE: 0.4413\n",
      "Epoch 433/500, Train RMSE: 0.6503, Valid RMSE: 0.4379\n",
      "Epoch 434/500, Train RMSE: 0.6469, Valid RMSE: 0.4398\n",
      "Epoch 435/500, Train RMSE: 0.6502, Valid RMSE: 0.4342\n",
      "Epoch 436/500, Train RMSE: 0.6488, Valid RMSE: 0.4359\n",
      "Epoch 437/500, Train RMSE: 0.6479, Valid RMSE: 0.4409\n",
      "Epoch 438/500, Train RMSE: 0.6475, Valid RMSE: 0.4322\n",
      "Epoch 439/500, Train RMSE: 0.6474, Valid RMSE: 0.4343\n",
      "Epoch 440/500, Train RMSE: 0.6486, Valid RMSE: 0.4352\n",
      "Epoch 441/500, Train RMSE: 0.6515, Valid RMSE: 0.4434\n",
      "Epoch 442/500, Train RMSE: 0.6481, Valid RMSE: 0.4452\n",
      "Epoch 443/500, Train RMSE: 0.6439, Valid RMSE: 0.4396\n",
      "Epoch 444/500, Train RMSE: 0.6448, Valid RMSE: 0.4350\n",
      "Epoch 445/500, Train RMSE: 0.6438, Valid RMSE: 0.4519\n",
      "Epoch 446/500, Train RMSE: 0.6512, Valid RMSE: 0.4507\n",
      "Epoch 447/500, Train RMSE: 0.6468, Valid RMSE: 0.4315\n",
      "Epoch 448/500, Train RMSE: 0.6459, Valid RMSE: 0.4441\n",
      "Epoch 449/500, Train RMSE: 0.6567, Valid RMSE: 0.4459\n",
      "Epoch 450/500, Train RMSE: 0.6481, Valid RMSE: 0.4464\n",
      "Epoch 451/500, Train RMSE: 0.6478, Valid RMSE: 0.4367\n",
      "Epoch 452/500, Train RMSE: 0.6485, Valid RMSE: 0.4311\n",
      "Epoch 453/500, Train RMSE: 0.6474, Valid RMSE: 0.4375\n",
      "Epoch 454/500, Train RMSE: 0.6482, Valid RMSE: 0.4454\n",
      "Epoch 455/500, Train RMSE: 0.6450, Valid RMSE: 0.4360\n",
      "Epoch 456/500, Train RMSE: 0.6455, Valid RMSE: 0.4323\n",
      "Epoch 457/500, Train RMSE: 0.6464, Valid RMSE: 0.4306\n",
      "Epoch 458/500, Train RMSE: 0.6506, Valid RMSE: 0.4387\n",
      "Epoch 459/500, Train RMSE: 0.6488, Valid RMSE: 0.4352\n",
      "Epoch 460/500, Train RMSE: 0.6447, Valid RMSE: 0.4389\n",
      "Epoch 461/500, Train RMSE: 0.6438, Valid RMSE: 0.4328\n",
      "Epoch 462/500, Train RMSE: 0.6506, Valid RMSE: 0.4386\n",
      "Epoch 463/500, Train RMSE: 0.6501, Valid RMSE: 0.4317\n",
      "Epoch 464/500, Train RMSE: 0.6490, Valid RMSE: 0.4311\n",
      "Epoch 465/500, Train RMSE: 0.6466, Valid RMSE: 0.4312\n",
      "Epoch 466/500, Train RMSE: 0.6456, Valid RMSE: 0.4320\n",
      "Epoch 467/500, Train RMSE: 0.6540, Valid RMSE: 0.4473\n",
      "Epoch 468/500, Train RMSE: 0.6468, Valid RMSE: 0.4337\n",
      "Epoch 469/500, Train RMSE: 0.6448, Valid RMSE: 0.4380\n",
      "Epoch 470/500, Train RMSE: 0.6479, Valid RMSE: 0.4319\n",
      "Epoch 471/500, Train RMSE: 0.6431, Valid RMSE: 0.4406\n",
      "Epoch 472/500, Train RMSE: 0.6451, Valid RMSE: 0.4403\n",
      "Epoch 473/500, Train RMSE: 0.6449, Valid RMSE: 0.4381\n",
      "Epoch 474/500, Train RMSE: 0.6436, Valid RMSE: 0.4480\n",
      "Epoch 475/500, Train RMSE: 0.6453, Valid RMSE: 0.4310\n",
      "Epoch 476/500, Train RMSE: 0.6474, Valid RMSE: 0.4341\n",
      "Epoch 477/500, Train RMSE: 0.6483, Valid RMSE: 0.4359\n",
      "Epoch 478/500, Train RMSE: 0.6478, Valid RMSE: 0.4338\n",
      "Epoch 479/500, Train RMSE: 0.6481, Valid RMSE: 0.4398\n",
      "Epoch 480/500, Train RMSE: 0.6482, Valid RMSE: 0.4422\n",
      "Epoch 481/500, Train RMSE: 0.6468, Valid RMSE: 0.4315\n",
      "Epoch 482/500, Train RMSE: 0.6471, Valid RMSE: 0.4321\n",
      "Epoch 483/500, Train RMSE: 0.6483, Valid RMSE: 0.4405\n",
      "Epoch 484/500, Train RMSE: 0.6476, Valid RMSE: 0.4358\n",
      "Epoch 485/500, Train RMSE: 0.6479, Valid RMSE: 0.4323\n",
      "Epoch 486/500, Train RMSE: 0.6444, Valid RMSE: 0.4306\n",
      "Epoch 487/500, Train RMSE: 0.6483, Valid RMSE: 0.4399\n",
      "Epoch 488/500, Train RMSE: 0.6476, Valid RMSE: 0.4315\n",
      "Epoch 489/500, Train RMSE: 0.6445, Valid RMSE: 0.4375\n",
      "Epoch 490/500, Train RMSE: 0.6441, Valid RMSE: 0.4358\n",
      "Epoch 491/500, Train RMSE: 0.6490, Valid RMSE: 0.4324\n",
      "Epoch 492/500, Train RMSE: 0.6473, Valid RMSE: 0.4417\n",
      "Epoch 493/500, Train RMSE: 0.6494, Valid RMSE: 0.4306\n",
      "Epoch 494/500, Train RMSE: 0.6449, Valid RMSE: 0.4404\n",
      "Epoch 495/500, Train RMSE: 0.6457, Valid RMSE: 0.4363\n",
      "Epoch 496/500, Train RMSE: 0.6470, Valid RMSE: 0.4389\n",
      "Epoch 497/500, Train RMSE: 0.6465, Valid RMSE: 0.4317\n",
      "Epoch 498/500, Train RMSE: 0.6446, Valid RMSE: 0.4328\n",
      "Epoch 499/500, Train RMSE: 0.6486, Valid RMSE: 0.4296\n",
      "Epoch 500/500, Train RMSE: 0.6498, Valid RMSE: 0.4479\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 500  # You can adjust this\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = torch.sqrt(criterion(outputs.squeeze(), targets))  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for inputs, targets in valid_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    # Average losses and print RMSE\n",
    "    avg_train_loss =torch.tensor(total_loss / len(train_loader))\n",
    "    avg_val_loss = torch.tensor(total_val_loss / len(valid_loader))\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train RMSE: {avg_train_loss:.4f}, Valid RMSE: {avg_val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "def calculate_rmse(y, yhat):\n",
    "    return mean_squared_error(y, yhat, squared=False)\n",
    "\n",
    "def nn_pipeline(train, test, model_class, param, n_splits=10, iterations=5, batch_size=64):\n",
    "    # Ensure inputs are tensors\n",
    "    train_x = torch.tensor(train, dtype=torch.float32)\n",
    "    train_y = torch.tensor(test, dtype=torch.float32)\n",
    "\n",
    "    test_preds = []\n",
    "    valid_preds = pd.DataFrame()\n",
    "    criterion = nn.MSELoss()\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    for iter in range(iterations):\n",
    "        for i, (train_index, valid_index) in enumerate(skf.split(train_x.numpy(), train_y.numpy().astype(str))):\n",
    "            # Splitting data\n",
    "            x_train, y_train = train_x[train_index], train_y[train_index]\n",
    "            x_valid, y_valid = train_x[valid_index], train_y[valid_index]\n",
    "\n",
    "            # DataLoader for batch processing\n",
    "            train_data = TensorDataset(x_train, y_train)\n",
    "            valid_data = TensorDataset(x_valid, y_valid)\n",
    "            train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "            valid_loader = DataLoader(valid_data, batch_size=batch_size)\n",
    "\n",
    "            # Model setup\n",
    "            model = model_class(**param)\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                for inputs, targets in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = torch.sqrt(criterion(outputs.squeeze(), targets))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # Validation predictions\n",
    "            model.eval()\n",
    "            valid_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, _ in valid_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    valid_predictions.extend(outputs.squeeze().tolist())\n",
    "\n",
    "            tmp_df = pd.DataFrame({'id': valid_index, 'score': y_valid.numpy(), 'preds': valid_predictions})\n",
    "            tmp_df['iteration'] = i + 1\n",
    "            valid_preds = pd.concat([valid_preds, tmp_df])\n",
    "\n",
    "    final_rmse = np.sqrt(mean_squared_error(valid_preds['score'], valid_preds['preds']))\n",
    "    cv_rmse = valid_preds.groupby('iteration').apply(lambda g: np.sqrt(mean_squared_error(g['score'], g['preds'])))\n",
    "\n",
    "    return valid_preds, final_rmse, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.6952714319192461\n"
     ]
    }
   ],
   "source": [
    "param = {'feat_dim': train_x.shape[1]}\n",
    "\n",
    "# Using the nn_pipeline function\n",
    "valid_preds, final_rmse, trained_model = nn_pipeline(\n",
    "    train_x=train_x.numpy(),  \n",
    "    train_y=train_y.numpy(),\n",
    "    model_class=MLPModel,\n",
    "    param=param,\n",
    "    n_splits=5,  \n",
    "    iterations=3  \n",
    ")\n",
    "\n",
    "print(f\"Final RMSE: {final_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
