{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56512d1a",
   "metadata": {
    "papermill": {
     "duration": 0.004254,
     "end_time": "2023-12-06T06:43:52.235251",
     "exception": false,
     "start_time": "2023-12-06T06:43:52.230997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3303c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T06:43:52.246483Z",
     "iopub.status.busy": "2023-12-06T06:43:52.246011Z",
     "iopub.status.idle": "2023-12-06T06:43:56.282602Z",
     "shell.execute_reply": "2023-12-06T06:43:56.281389Z"
    },
    "papermill": {
     "duration": 4.045816,
     "end_time": "2023-12-06T06:43:56.285512",
     "exception": false,
     "start_time": "2023-12-06T06:43:52.239696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import skew, kurtosis\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b0dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(data_path + 'train_logs.csv')\n",
    "# train_feats   = dev_feats(train_logs)\n",
    "# train_feats   = train_feats.collect().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f19b0",
   "metadata": {
    "papermill": {
     "duration": 0.004184,
     "end_time": "2023-12-06T06:43:56.294210",
     "exception": false,
     "start_time": "2023-12-06T06:43:56.290026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Polars FE & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc58732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T06:43:56.305392Z",
     "iopub.status.busy": "2023-12-06T06:43:56.304976Z",
     "iopub.status.idle": "2023-12-06T06:43:56.352851Z",
     "shell.execute_reply": "2023-12-06T06:43:56.351555Z"
    },
    "papermill": {
     "duration": 0.05663,
     "end_time": "2023-12-06T06:43:56.355334",
     "exception": false,
     "start_time": "2023-12-06T06:43:56.298704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cols = ['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']\n",
    "activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n",
    "events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', 'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "text_changes = ['q', ' ', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "\n",
    "\n",
    "def count_by_values(df, colname, values):\n",
    "    fts = df.select(pl.col('id').unique(maintain_order=True))\n",
    "    for i, value in enumerate(values):\n",
    "        tmp_df = df.group_by('id').agg(pl.col(colname).is_in([value]).sum().alias(f'{colname}_{i}_cnt'))\n",
    "        fts  = fts.join(tmp_df, on='id', how='left') \n",
    "    return fts\n",
    "\n",
    "\n",
    "def dev_feats(df):\n",
    "    \n",
    "    print(\"< Count by values features >\")\n",
    "    feats = count_by_values(df, 'activity', activities)\n",
    "    feats = feats.join(count_by_values(df, 'text_change', text_changes), on='id', how='left') \n",
    "    feats = feats.join(count_by_values(df, 'down_event', events), on='id', how='left') \n",
    "    feats = feats.join(count_by_values(df, 'up_event', events), on='id', how='left') \n",
    "\n",
    "    print(\"< Input words stats features >\")\n",
    "    temp = df.filter((~pl.col('text_change').str.contains('=>')) & (pl.col('text_change') != 'NoChange'))\n",
    "    temp = temp.group_by('id').agg(pl.col('text_change').str.concat('').str.extract_all(r'q+'))\n",
    "    temp = temp.with_columns(input_word_count = pl.col('text_change').list.lengths(),\n",
    "                             input_word_length_mean = pl.col('text_change').apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_max = pl.col('text_change').apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_std = pl.col('text_change').apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_median = pl.col('text_change').apply(lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_skew = pl.col('text_change').apply(lambda x: skew([len(i) for i in x] if len(x) > 0 else 0)))\n",
    "    temp = temp.drop('text_change')\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "\n",
    "    print(\"< Numerical columns features >\")\n",
    "    temp = df.group_by(\"id\").agg(pl.sum('action_time').suffix('_sum'), pl.mean(num_cols).suffix('_mean'), pl.std(num_cols).suffix('_std'),\n",
    "                                 pl.median(num_cols).suffix('_median'), pl.min(num_cols).suffix('_min'), pl.max(num_cols).suffix('_max'),\n",
    "                                 pl.quantile(num_cols, 0.5).suffix('_quantile'))\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "\n",
    "    print(\"< Categorical columns features >\")\n",
    "    temp  = df.group_by(\"id\").agg(pl.n_unique(['activity', 'down_event', 'up_event', 'text_change']))\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "\n",
    "    \n",
    "    print(\"< Idle time features >\")\n",
    "    temp = df.with_columns(pl.col('up_time').shift().over('id').alias('up_time_lagged'))\n",
    "    temp = temp.with_columns((abs(pl.col('down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "    temp = temp.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.group_by(\"id\").agg(inter_key_largest_lantency = pl.max('time_diff'),\n",
    "                                   inter_key_median_lantency = pl.median('time_diff'),\n",
    "                                   mean_pause_time = pl.mean('time_diff'),\n",
    "                                   std_pause_time = pl.std('time_diff'),\n",
    "                                   total_pause_time = pl.sum('time_diff'),\n",
    "                                   pauses_half_sec = pl.col('time_diff').filter((pl.col('time_diff') > 0.5) & (pl.col('time_diff') < 1)).count(),\n",
    "                                   pauses_1_sec = pl.col('time_diff').filter((pl.col('time_diff') > 1) & (pl.col('time_diff') < 1.5)).count(),\n",
    "                                   pauses_1_half_sec = pl.col('time_diff').filter((pl.col('time_diff') > 1.5) & (pl.col('time_diff') < 2)).count(),\n",
    "                                   pauses_2_sec = pl.col('time_diff').filter((pl.col('time_diff') > 2) & (pl.col('time_diff') < 3)).count(),\n",
    "                                   pauses_3_sec = pl.col('time_diff').filter(pl.col('time_diff') > 3).count(),)\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "    \n",
    "    print(\"< P-bursts features >\")\n",
    "    temp = df.with_columns(pl.col('up_time').shift().over('id').alias('up_time_lagged'))\n",
    "    temp = temp.with_columns((abs(pl.col('down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "    temp = temp.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.col('time_diff')<2)\n",
    "    temp = temp.with_columns(pl.when(pl.col(\"time_diff\") & pl.col(\"time_diff\").is_last()).then(pl.count()).over(pl.col(\"time_diff\").rle_id()).alias('P-bursts'))\n",
    "    temp = temp.drop_nulls()\n",
    "    temp = temp.group_by(\"id\").agg(pl.mean('P-bursts').suffix('_mean'), pl.std('P-bursts').suffix('_std'), pl.count('P-bursts').suffix('_count'),\n",
    "                                   pl.median('P-bursts').suffix('_median'), pl.max('P-bursts').suffix('_max'),\n",
    "                                   pl.first('P-bursts').suffix('_first'), pl.last('P-bursts').suffix('_last'))\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "\n",
    "\n",
    "    print(\"< R-bursts features >\")\n",
    "    temp = df.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.col('activity').is_in(['Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.when(pl.col(\"activity\") & pl.col(\"activity\").is_last()).then(pl.count()).over(pl.col(\"activity\").rle_id()).alias('R-bursts'))\n",
    "    temp = temp.drop_nulls()\n",
    "    temp = temp.group_by(\"id\").agg(pl.mean('R-bursts').suffix('_mean'), pl.std('R-bursts').suffix('_std'), \n",
    "                                   pl.median('R-bursts').suffix('_median'), pl.max('R-bursts').suffix('_max'),\n",
    "                                   pl.first('R-bursts').suffix('_first'), pl.last('R-bursts').suffix('_last'))\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "    \n",
    "    return feats\n",
    "\n",
    "def train_valid_split(data_x, data_y, train_idx, valid_idx):\n",
    "    x_train = data_x.iloc[train_idx]\n",
    "    y_train = data_y[train_idx]\n",
    "    x_valid = data_x.iloc[valid_idx]\n",
    "    y_valid = data_y[valid_idx]\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "\n",
    "def evaluate(data_x, data_y, model, random_state=42, n_splits=5, test_x=None):\n",
    "    skf    = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "    test_y = np.zeros(len(data_x)) if (test_x is None) else np.zeros((len(test_x), n_splits))\n",
    "\n",
    "    valid_preds = pd.DataFrame()\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(data_x, data_y.astype(str))):\n",
    "        train_x, train_y, valid_x, valid_y = train_valid_split(data_x, data_y, train_index, valid_index)\n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "        # valid\n",
    "        valid_preds = pd.concat([valid_x[['score','id']]])\n",
    "        valid_preds['preds'] = model.predict(valid_x)\n",
    "    \n",
    "        test_y[:, i] = model.predict(test_x)\n",
    "\n",
    "    return valid_preds, test_y\n",
    "\n",
    "def calculate_rmse(y, yhat):\n",
    "    return mean_squared_error(y, yhat, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f30406",
   "metadata": {
    "papermill": {
     "duration": 0.004928,
     "end_time": "2023-12-06T06:43:56.365164",
     "exception": false,
     "start_time": "2023-12-06T06:43:56.360236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pandas FE & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4388e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T06:43:56.377351Z",
     "iopub.status.busy": "2023-12-06T06:43:56.376884Z",
     "iopub.status.idle": "2023-12-06T06:43:56.414869Z",
     "shell.execute_reply": "2023-12-06T06:43:56.413655Z"
    },
    "papermill": {
     "duration": 0.047589,
     "end_time": "2023-12-06T06:43:56.417466",
     "exception": false,
     "start_time": "2023-12-06T06:43:56.369877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "AGGREGATIONS = ['count', 'mean', 'min', 'max', 'first', 'last', q1, 'median', q3, 'sum']\n",
    "\n",
    "def reconstruct_essay(currTextInput):\n",
    "    essayText = \"\"\n",
    "    for Input in currTextInput.values:\n",
    "        if Input[0] == 'Replace':\n",
    "            replaceTxt = Input[2].split(' => ')\n",
    "            essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] + essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n",
    "            continue\n",
    "        if Input[0] == 'Paste':\n",
    "            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "            continue\n",
    "        if Input[0] == 'Remove/Cut':\n",
    "            essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n",
    "            continue\n",
    "        if \"M\" in Input[0]:\n",
    "            croppedTxt = Input[0][10:]\n",
    "            splitTxt = croppedTxt.split(' To ')\n",
    "            valueArr = [item.split(', ') for item in splitTxt]\n",
    "            moveData = (int(valueArr[0][0][1:]), int(valueArr[0][1][:-1]), int(valueArr[1][0][1:]), int(valueArr[1][1][:-1]))\n",
    "            if moveData[0] != moveData[2]:\n",
    "                if moveData[0] < moveData[2]:\n",
    "                    essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] + essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n",
    "                else:\n",
    "                    essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] + essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n",
    "            continue\n",
    "        essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "    return essayText\n",
    "\n",
    "\n",
    "def get_essay_df(df):\n",
    "    df       = df[df.activity != 'Nonproduction']\n",
    "    temp     = df.groupby('id').apply(lambda x: reconstruct_essay(x[['activity', 'cursor_position', 'text_change']]))\n",
    "    essay_df = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "    essay_df = essay_df.merge(temp.rename('essay'), on='id')\n",
    "    return essay_df\n",
    "\n",
    "\n",
    "def word_feats(df):\n",
    "    essay_df = df\n",
    "    df['word'] = df['essay'].apply(lambda x: re.split(' |\\\\n|\\\\.|\\\\?|\\\\!',x))\n",
    "    df = df.explode('word')\n",
    "    df['word_len'] = df['word'].apply(lambda x: len(x))\n",
    "    df = df[df['word_len'] != 0]\n",
    "    word_agg_df = df[['id','word_len']].groupby(['id']).agg(AGGREGATIONS)\n",
    "    word_agg_df.columns = ['_'.join(x) for x in word_agg_df.columns]\n",
    "    word_agg_df['id'] = word_agg_df.index\n",
    "    word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "    return word_agg_df\n",
    "\n",
    "\n",
    "def sent_feats(df):\n",
    "    df['sent'] = df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n",
    "    df = df.explode('sent')\n",
    "    df['sent'] = df['sent'].apply(lambda x: x.replace('\\n','').strip())\n",
    "    # Number of characters in sentences\n",
    "    df['sent_len'] = df['sent'].apply(lambda x: len(x))\n",
    "    # Number of words in sentences\n",
    "    df['sent_word_count'] = df['sent'].apply(lambda x: len(x.split(' ')))\n",
    "    df = df[df.sent_len!=0].reset_index(drop=True)\n",
    "\n",
    "    sent_agg_df = pd.concat([df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), \n",
    "                             df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1)\n",
    "    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n",
    "    sent_agg_df['id'] = sent_agg_df.index\n",
    "    sent_agg_df = sent_agg_df.reset_index(drop=True)\n",
    "    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n",
    "    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n",
    "    return sent_agg_df\n",
    "\n",
    "\n",
    "def parag_feats(df):\n",
    "    df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n",
    "    df = df.explode('paragraph')\n",
    "    # Number of characters in paragraphs\n",
    "    df['paragraph_len'] = df['paragraph'].apply(lambda x: len(x)) \n",
    "    # Number of words in paragraphs\n",
    "    df['paragraph_word_count'] = df['paragraph'].apply(lambda x: len(x.split(' ')))\n",
    "    df = df[df.paragraph_len!=0].reset_index(drop=True)\n",
    "    \n",
    "    paragraph_agg_df = pd.concat([df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), \n",
    "                                  df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1) \n",
    "    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n",
    "    paragraph_agg_df['id'] = paragraph_agg_df.index\n",
    "    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n",
    "    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n",
    "    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n",
    "    return paragraph_agg_df\n",
    "\n",
    "def product_to_keys(logs, essays):\n",
    "    essays['product_len'] = essays.essay.str.len()\n",
    "    tmp_df = logs[logs.activity.isin(['Input', 'Remove/Cut'])].groupby(['id']).agg({'activity': 'count'}).reset_index().rename(columns={'activity': 'keys_pressed'})\n",
    "    essays = essays.merge(tmp_df, on='id', how='left')\n",
    "    essays['product_to_keys'] = essays['product_len'] / essays['keys_pressed']\n",
    "    return essays[['id', 'product_to_keys']]\n",
    "\n",
    "def get_keys_pressed_per_second(logs):\n",
    "    temp_df = logs[logs['activity'].isin(['Input', 'Remove/Cut'])].groupby(['id']).agg(keys_pressed=('event_id', 'count')).reset_index()\n",
    "    temp_df_2 = logs.groupby(['id']).agg(min_down_time=('down_time', 'min'), max_up_time=('up_time', 'max')).reset_index()\n",
    "    temp_df = temp_df.merge(temp_df_2, on='id', how='left')\n",
    "    temp_df['keys_per_second'] = temp_df['keys_pressed'] / ((temp_df['max_up_time'] - temp_df['min_down_time']) / 1000)\n",
    "    return temp_df[['id', 'keys_per_second']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813b7d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "< Essay Reconstruction >\n",
      "< Testing Data >\n",
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n"
     ]
    }
   ],
   "source": [
    "from m7_utils import preprocess_feats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(data_path + 'train_logs.csv')\n",
    "train_feats   = dev_feats(train_logs)\n",
    "train_feats   = train_feats.collect().to_pandas()\n",
    "\n",
    "print('< Essay Reconstruction >')\n",
    "train_logs             = train_logs.collect().to_pandas()\n",
    "train_essays           = get_essay_df(train_logs)\n",
    "train_feats            = train_feats.merge(word_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(get_keys_pressed_per_second(train_logs), on='id', how='left')\n",
    "train_feats            = train_feats.merge(product_to_keys(train_logs, train_essays), on='id', how='left')\n",
    "\n",
    "\n",
    "print('< Testing Data >')\n",
    "test_logs   = pl.scan_csv(data_path + 'test_logs.csv')\n",
    "test_feats  = dev_feats(test_logs)\n",
    "test_feats  = test_feats.collect().to_pandas()\n",
    "\n",
    "test_logs             = test_logs.collect().to_pandas()\n",
    "test_essays           = get_essay_df(test_logs)\n",
    "test_feats            = test_feats.merge(word_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(get_keys_pressed_per_second(test_logs), on='id', how='left')\n",
    "test_feats            = test_feats.merge(product_to_keys(test_logs, test_essays), on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee24a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATS_DIR = 'silver_bullet'\n",
    "# \n",
    "# train_feats.to_pickle(f'{FEATS_DIR}/train_feats.pkl')\n",
    "# test_feats.to_pickle(f'{FEATS_DIR}/test_feats.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b800b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS_DIR = 'silver_bullet'\n",
    " \n",
    "train_feats= pd.read_pickle(f'{FEATS_DIR}/train_feats.pkl')\n",
    "test_feats = pd.read_pickle(f'{FEATS_DIR}/test_feats.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2cb414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def word_change_stats(train_logs, test_logs):\n",
    "\n",
    "    data = []\n",
    "    for logs in [train_logs, test_logs]:\n",
    "\n",
    "        logs = logs.with_columns(\n",
    "            pl.col('word_count').diff().over('id').fill_nan(0).alias('wc_diff')\n",
    "        )\n",
    "\n",
    "        pref = 'wc_diff'\n",
    "\n",
    "        x = logs.group_by('id').agg([\n",
    "            pl.col('wc_diff').mean().alias(f'{pref}_mean'),\n",
    "            pl.col('wc_diff').std().alias(f'{pref}_std'),\n",
    "            pl.col('wc_diff').kurtosis().alias(f'{pref}_kurt'),\n",
    "            pl.col('wc_diff').skew().alias(f'{pref}_skew')\n",
    "        ])\n",
    "        data.append(x)\n",
    "\n",
    "    return data[0].collect().to_pandas(), data[1].collect().to_pandas()\n",
    "\n",
    "train_logs   = pl.scan_csv(data_path + 'train_logs.csv')\n",
    "test_logs   = pl.scan_csv(data_path + 'test_logs.csv')\n",
    "\n",
    "tr_feats, ts_feats = word_change_stats(train_logs, test_logs)\n",
    "\n",
    "\n",
    "train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "test_feats = test_feats.merge(ts_feats, on='id', how='left') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9310f3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" from sklearn.feature_extraction.text import CountVectorizer\\nfrom m4_feats_functions import getEssays\\n\\ndef countvectorize_one_one(train_logs, test_logs):\\n\\n    data = []\\n\\n    for logs in [train_logs, test_logs]:\\n\\n        ids = logs.id.unique()\\n        essays = getEssays(logs)\\n        c_vect = CountVectorizer(ngram_range=(1, 1))\\n        toks = c_vect.fit_transform(essays['essay']).todense()\\n        toks = toks[:,:16]\\n        toks_df = pd.DataFrame(columns = [f'tok_{i}' for i in range(toks.shape[1])], data=toks)\\n        toks_df['id'] = ids\\n        toks_df.reset_index(drop=True, inplace=True)\\n        data.append(toks_df)\\n\\n    return data[0], data[1]\\n\\ntest_logs   = pl.scan_csv(data_path + 'test_logs.csv').collect().to_pandas()\\ntr_feats, ts_feats = countvectorize_one_one(train_logs, test_logs)\\n\\ntrain_feats = train_feats.merge(tr_feats, on='id', how='left')\\ntest_feats = test_feats.merge(ts_feats, on='id', how='left')\\nmissing_cols = set(tr_feats.columns) - set(ts_feats.columns)\\n\\nfor col in missing_cols:\\n    test_feats[col] = np.nan \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from sklearn.feature_extraction.text import CountVectorizer\n",
    "from m4_feats_functions import getEssays\n",
    "\n",
    "def countvectorize_one_one(train_logs, test_logs):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for logs in [train_logs, test_logs]:\n",
    "\n",
    "        ids = logs.id.unique()\n",
    "        essays = getEssays(logs)\n",
    "        c_vect = CountVectorizer(ngram_range=(1, 1))\n",
    "        toks = c_vect.fit_transform(essays['essay']).todense()\n",
    "        toks = toks[:,:16]\n",
    "        toks_df = pd.DataFrame(columns = [f'tok_{i}' for i in range(toks.shape[1])], data=toks)\n",
    "        toks_df['id'] = ids\n",
    "        toks_df.reset_index(drop=True, inplace=True)\n",
    "        data.append(toks_df)\n",
    "\n",
    "    return data[0], data[1]\n",
    "\n",
    "test_logs   = pl.scan_csv(data_path + 'test_logs.csv').collect().to_pandas()\n",
    "tr_feats, ts_feats = countvectorize_one_one(train_logs, test_logs)\n",
    "\n",
    "train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "missing_cols = set(tr_feats.columns) - set(ts_feats.columns)\n",
    "\n",
    "for col in missing_cols:\n",
    "    test_feats[col] = np.nan \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5badc745",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LazyFrame' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/Silver Bullet.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m train_action_time_gap_feats, test_action_time_gap_feats\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m test_logs   \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mscan_csv(data_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest_logs.csv\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcollect()\u001b[39m.\u001b[39mto_pandas()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m tr_feats, ts_feats \u001b[39m=\u001b[39m process_feats_action_time_gap(train_logs, test_logs)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m train_feats \u001b[39m=\u001b[39m train_feats\u001b[39m.\u001b[39mmerge(tr_feats, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m test_feats \u001b[39m=\u001b[39m test_feats\u001b[39m.\u001b[39mmerge(ts_feats, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/Silver Bullet.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     grouped \u001b[39m=\u001b[39m action_time_gap_df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39maction_time_gap\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m grouped\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: diverse_stats(x, \u001b[39m'\u001b[39m\u001b[39maction_time_gap\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m train_action_time_gap_feats \u001b[39m=\u001b[39m calc_action_time_gap(train_logs)\u001b[39m.\u001b[39mpivot(index\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel_1\u001b[39m\u001b[39m'\u001b[39m, values\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maction_time_gap\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m test_action_time_gap_feats \u001b[39m=\u001b[39m calc_action_time_gap(test_logs)\u001b[39m.\u001b[39mpivot(index\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel_1\u001b[39m\u001b[39m'\u001b[39m, values\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maction_time_gap\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mreturn\u001b[39;00m train_action_time_gap_feats, test_action_time_gap_feats\n",
      "\u001b[1;32m/root/Projects/Kaggle/linking-writing/Silver Bullet.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc_action_time_gap\u001b[39m(comb_df):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     action_time_gap_df \u001b[39m=\u001b[39m comb_df\u001b[39m.\u001b[39;49mcopy()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     action_time_gap_df[\u001b[39m'\u001b[39m\u001b[39mup_time_shift1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m action_time_gap_df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mup_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshift(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/Silver%20Bullet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     action_time_gap_df[\u001b[39m'\u001b[39m\u001b[39maction_time_gap\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m action_time_gap_df[\u001b[39m'\u001b[39m\u001b[39mdown_time\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m action_time_gap_df[\u001b[39m'\u001b[39m\u001b[39mup_time_shift1\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LazyFrame' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "\"\"\" # WORD STATS ON ESSAY\n",
    "def diverse_stats(series, prefix):\n",
    "    if isinstance(series, list):\n",
    "        series = pd.Series([len(item) for item in series])\n",
    "\n",
    "    stats = {\n",
    "        # f'{prefix}_count': series.count(),\n",
    "        f'{prefix}_mean': series.mean(),\n",
    "        f'{prefix}_std': series.std(),\n",
    "        f'{prefix}_max': series.max(),\n",
    "        f'{prefix}_median': series.median(),\n",
    "        # f'{prefix}_sum': series.sum(),\n",
    "        # f'{prefix}_last': series.iloc[-1] if not series.empty else None,\n",
    "        # f'{prefix}_q1': series.quantile(0.25),\n",
    "        # f'{prefix}_q3': series.quantile(0.75),\n",
    "        # f'{prefix}_iqr': series.quantile(0.75) - series.quantile(0.25),\n",
    "        # f'{prefix}_min': series.min(),\n",
    "        # f'{prefix}_first': series.iloc[0] if not series.empty else None,\n",
    "        # f'{prefix}_sem': series.sem(),\n",
    "        f'{prefix}_skew': series.skew(),\n",
    "        f'{prefix}_kurt': series.kurtosis(),\n",
    "        # f'{prefix}_range': series.max() - series.min(),\n",
    "    }\n",
    "    return pd.Series(stats)\n",
    "\n",
    "\n",
    "def process_feats_action_time_gap(train_logs, test_logs):\n",
    "    def calc_action_time_gap(comb_df):\n",
    "        action_time_gap_df = comb_df.copy()\n",
    "        action_time_gap_df['up_time_shift1'] = action_time_gap_df.groupby('id')['up_time'].shift(1)\n",
    "        action_time_gap_df['action_time_gap'] = action_time_gap_df['down_time'] - action_time_gap_df['up_time_shift1']\n",
    "\n",
    "        grouped = action_time_gap_df.groupby('id')['action_time_gap']\n",
    "        return grouped.apply(lambda x: diverse_stats(x, 'action_time_gap')).reset_index()\n",
    "\n",
    "    train_action_time_gap_feats = calc_action_time_gap(train_logs).pivot(index='id', columns='level_1', values='action_time_gap').reset_index()\n",
    "    test_action_time_gap_feats = calc_action_time_gap(test_logs).pivot(index='id', columns='level_1', values='action_time_gap').reset_index()\n",
    "\n",
    "    return train_action_time_gap_feats, test_action_time_gap_feats\n",
    "\n",
    "test_logs   = pl.scan_csv(data_path + 'test_logs.csv').collect().to_pandas()\n",
    "tr_feats, ts_feats = process_feats_action_time_gap(train_logs, test_logs)\n",
    "\n",
    "train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "missing_cols = set(tr_feats.columns) - set(ts_feats.columns)\n",
    "\n",
    "for col in missing_cols:\n",
    "    test_feats[col] = np.nan \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f85ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Mapping >\n",
      "Final RMSE over 50: 0.616633.\n",
      "RMSE by fold 0.616477\n"
     ]
    }
   ],
   "source": [
    "from m5_sb_models import lgb_pipeline\n",
    "import pandas as pd\n",
    "\n",
    "FEATS_DIR = 'silver_bullet'\n",
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "\n",
    "train_feats= pd.read_pickle(f'{FEATS_DIR}/train_feats.pkl')\n",
    "test_feats = pd.read_pickle(f'{FEATS_DIR}/test_feats.pkl')\n",
    "\n",
    "print('< Mapping >')\n",
    "train_scores   = pd.read_csv(data_path + 'train_scores.csv')\n",
    "train = train_feats.merge(train_scores, on='id', how='left')\n",
    "test = test_feats.copy()\n",
    "\n",
    "test_preds, valid_preds, final_rmse, cv_rmse  = lgb_pipeline(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0c5cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(y, yhat):\n",
    "    return mean_squared_error([y], [yhat], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72e616b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds['rmse'] = valid_preds.apply(lambda row : calculate_rmse(row['score'], row['preds']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee3f780b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "      <th>iteration</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>315bdafd</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.627277</td>\n",
       "      <td>7</td>\n",
       "      <td>1.127277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>315bdafd</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.739659</td>\n",
       "      <td>7</td>\n",
       "      <td>1.239659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>c3663a2d</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.749850</td>\n",
       "      <td>8</td>\n",
       "      <td>1.249850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>315bdafd</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.776693</td>\n",
       "      <td>10</td>\n",
       "      <td>1.276693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>c3663a2d</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.798456</td>\n",
       "      <td>8</td>\n",
       "      <td>1.298456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1ebb9b74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.841998</td>\n",
       "      <td>9</td>\n",
       "      <td>1.341998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>40b28508</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.844910</td>\n",
       "      <td>9</td>\n",
       "      <td>1.344910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>40b28508</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.849344</td>\n",
       "      <td>1</td>\n",
       "      <td>1.349344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>40b28508</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.881667</td>\n",
       "      <td>8</td>\n",
       "      <td>1.381667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>315bdafd</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.884797</td>\n",
       "      <td>1</td>\n",
       "      <td>1.384797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>c3663a2d</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.906208</td>\n",
       "      <td>10</td>\n",
       "      <td>1.406208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>315bdafd</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.930541</td>\n",
       "      <td>1</td>\n",
       "      <td>1.430541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>40b28508</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.948536</td>\n",
       "      <td>7</td>\n",
       "      <td>1.448536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>c3663a2d</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.962983</td>\n",
       "      <td>7</td>\n",
       "      <td>1.462983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>40b28508</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.966732</td>\n",
       "      <td>9</td>\n",
       "      <td>1.466732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1ebb9b74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.978845</td>\n",
       "      <td>8</td>\n",
       "      <td>1.478845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>c3663a2d</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.041510</td>\n",
       "      <td>1</td>\n",
       "      <td>1.541510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1ebb9b74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.095466</td>\n",
       "      <td>8</td>\n",
       "      <td>1.595466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1ebb9b74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.102885</td>\n",
       "      <td>9</td>\n",
       "      <td>1.602885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1ebb9b74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.294197</td>\n",
       "      <td>10</td>\n",
       "      <td>1.794197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3bda31e6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.523931</td>\n",
       "      <td>10</td>\n",
       "      <td>2.023931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3bda31e6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.557131</td>\n",
       "      <td>7</td>\n",
       "      <td>2.057131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3bda31e6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.583078</td>\n",
       "      <td>10</td>\n",
       "      <td>2.083078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3bda31e6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.602459</td>\n",
       "      <td>9</td>\n",
       "      <td>2.102459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3bda31e6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.648418</td>\n",
       "      <td>1</td>\n",
       "      <td>2.148418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  score     preds  iteration      rmse\n",
       "469   315bdafd    0.5  1.627277          7  1.127277\n",
       "469   315bdafd    0.5  1.739659          7  1.239659\n",
       "1848  c3663a2d    0.5  1.749850          8  1.249850\n",
       "469   315bdafd    0.5  1.776693         10  1.276693\n",
       "1848  c3663a2d    0.5  1.798456          8  1.298456\n",
       "302   1ebb9b74    0.5  1.841998          9  1.341998\n",
       "606   40b28508    0.5  1.844910          9  1.344910\n",
       "606   40b28508    0.5  1.849344          1  1.349344\n",
       "606   40b28508    0.5  1.881667          8  1.381667\n",
       "469   315bdafd    0.5  1.884797          1  1.384797\n",
       "1848  c3663a2d    0.5  1.906208         10  1.406208\n",
       "469   315bdafd    0.5  1.930541          1  1.430541\n",
       "606   40b28508    0.5  1.948536          7  1.448536\n",
       "1848  c3663a2d    0.5  1.962983          7  1.462983\n",
       "606   40b28508    0.5  1.966732          9  1.466732\n",
       "302   1ebb9b74    0.5  1.978845          8  1.478845\n",
       "1848  c3663a2d    0.5  2.041510          1  1.541510\n",
       "302   1ebb9b74    0.5  2.095466          8  1.595466\n",
       "302   1ebb9b74    0.5  2.102885          9  1.602885\n",
       "302   1ebb9b74    0.5  2.294197         10  1.794197\n",
       "559   3bda31e6    0.5  2.523931         10  2.023931\n",
       "559   3bda31e6    0.5  2.557131          7  2.057131\n",
       "559   3bda31e6    0.5  2.583078         10  2.083078\n",
       "559   3bda31e6    0.5  2.602459          9  2.102459\n",
       "559   3bda31e6    0.5  2.648418          1  2.148418"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds[valid_preds['score']==0.5].sort_values('rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9855414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = valid_preds.groupby(['id', 'score'])['preds'].mean().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e87dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds.apply(lambda row : calculate_rmse(row['score'], row['preds']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55a7be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['rmse'] = x.apply(lambda row: calculate_rmse(row['score'], row['preds']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22ff5bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>69916fc0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.671835</td>\n",
       "      <td>2.671835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>e86a132d</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.066565</td>\n",
       "      <td>2.566565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>aac5ac07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.566223</td>\n",
       "      <td>2.566223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>68df1430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.555080</td>\n",
       "      <td>2.555080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>a04a32c3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.992352</td>\n",
       "      <td>2.492352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3402f8b4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.331402</td>\n",
       "      <td>2.331402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>b73648cf</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.771390</td>\n",
       "      <td>2.228610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1fbedb17</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.728096</td>\n",
       "      <td>2.228096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2717fdef</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.122466</td>\n",
       "      <td>2.122466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2f935a5c</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.621413</td>\n",
       "      <td>2.121413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>e817ec7a</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.597315</td>\n",
       "      <td>2.097315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3bda31e6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.583004</td>\n",
       "      <td>2.083004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>156afd16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.907681</td>\n",
       "      <td>1.907681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>8a021954</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.892636</td>\n",
       "      <td>1.892636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>71f872ee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.889137</td>\n",
       "      <td>1.889137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>ccdada4b</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.384663</td>\n",
       "      <td>1.884663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>ad5f7cbb</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.882027</td>\n",
       "      <td>1.882027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>66fed026</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.162206</td>\n",
       "      <td>1.837794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>aaf07101</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.336947</td>\n",
       "      <td>1.836947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>ecb4af9f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.834034</td>\n",
       "      <td>1.834034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>e74a7639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.827288</td>\n",
       "      <td>1.827288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>8294f230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.783410</td>\n",
       "      <td>1.783410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1343a4d2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.237566</td>\n",
       "      <td>1.762434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>38fd0668</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.248476</td>\n",
       "      <td>1.748476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>a3002e51</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.204492</td>\n",
       "      <td>1.704492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>ef754fae</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.687874</td>\n",
       "      <td>1.687874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>9dad44fc</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.172288</td>\n",
       "      <td>1.672288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>3e0aa9dd</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.162889</td>\n",
       "      <td>1.662889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>7a17e218</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.637899</td>\n",
       "      <td>1.637899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>ea735e2d</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.132539</td>\n",
       "      <td>1.632539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>5e048ae3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.620459</td>\n",
       "      <td>1.620459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>53ef14a4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.881056</td>\n",
       "      <td>1.618944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>3cffdc8a</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.113798</td>\n",
       "      <td>1.613798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>72298d29</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.090692</td>\n",
       "      <td>1.590692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>d9fec26b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.587737</td>\n",
       "      <td>1.587737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  score     preds      rmse\n",
       "1005  69916fc0    1.0  3.671835  2.671835\n",
       "2232  e86a132d    1.5  4.066565  2.566565\n",
       "1614  aac5ac07    1.0  3.566223  2.566223\n",
       "998   68df1430    1.0  3.555080  2.555080\n",
       "1513  a04a32c3    1.5  3.992352  2.492352\n",
       "497   3402f8b4    2.0  4.331402  2.331402\n",
       "1747  b73648cf    6.0  3.771390  2.228610\n",
       "306   1fbedb17    2.5  4.728096  2.228096\n",
       "378   2717fdef    1.0  3.122466  2.122466\n",
       "453   2f935a5c    2.5  4.621413  2.121413\n",
       "2231  e817ec7a    2.5  4.597315  2.097315\n",
       "559   3bda31e6    0.5  2.583004  2.083004\n",
       "215   156afd16    2.0  3.907681  1.907681\n",
       "1314  8a021954    1.0  2.892636  1.892636\n",
       "1079  71f872ee    1.0  2.889137  1.889137\n",
       "1948  ccdada4b    1.5  3.384663  1.884663\n",
       "1640  ad5f7cbb    3.0  4.882027  1.882027\n",
       "974   66fed026    6.0  4.162206  1.837794\n",
       "1616  aaf07101    3.5  5.336947  1.836947\n",
       "2273  ecb4af9f    3.0  4.834034  1.834034\n",
       "2221  e74a7639    1.0  2.827288  1.827288\n",
       "1236  8294f230    1.0  2.783410  1.783410\n",
       "186   1343a4d2    6.0  4.237566  1.762434\n",
       "532   38fd0668    3.5  5.248476  1.748476\n",
       "1539  a3002e51    1.5  3.204492  1.704492\n",
       "2303  ef754fae    1.0  2.687874  1.687874\n",
       "1488  9dad44fc    2.5  4.172288  1.672288\n",
       "578   3e0aa9dd    2.5  4.162889  1.662889\n",
       "1160  7a17e218    3.0  4.637899  1.637899\n",
       "2251  ea735e2d    1.5  3.132539  1.632539\n",
       "883   5e048ae3    1.0  2.620459  1.620459\n",
       "796   53ef14a4    5.5  3.881056  1.618944\n",
       "570   3cffdc8a    1.5  3.113798  1.613798\n",
       "1082  72298d29    2.5  4.090692  1.590692\n",
       "2091  d9fec26b    1.0  2.587737  1.587737"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sort_values(by='rmse', ascending=False).head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5fb5660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>activity_0_cnt</th>\n",
       "      <th>activity_1_cnt</th>\n",
       "      <th>activity_2_cnt</th>\n",
       "      <th>activity_3_cnt</th>\n",
       "      <th>activity_4_cnt</th>\n",
       "      <th>text_change_0_cnt</th>\n",
       "      <th>text_change_1_cnt</th>\n",
       "      <th>text_change_2_cnt</th>\n",
       "      <th>text_change_3_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>paragraph_word_count_min</th>\n",
       "      <th>paragraph_word_count_max</th>\n",
       "      <th>paragraph_word_count_first</th>\n",
       "      <th>paragraph_word_count_last</th>\n",
       "      <th>paragraph_word_count_q1</th>\n",
       "      <th>paragraph_word_count_median</th>\n",
       "      <th>paragraph_word_count_q3</th>\n",
       "      <th>paragraph_word_count_sum</th>\n",
       "      <th>keys_per_second</th>\n",
       "      <th>product_to_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>69916fc0</td>\n",
       "      <td>2063</td>\n",
       "      <td>301</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1923</td>\n",
       "      <td>389</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>98</td>\n",
       "      <td>71</td>\n",
       "      <td>98</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>82.25</td>\n",
       "      <td>305</td>\n",
       "      <td>1.560324</td>\n",
       "      <td>0.745347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  activity_0_cnt  activity_1_cnt  activity_2_cnt  \\\n",
       "1005  69916fc0            2063             301             503   \n",
       "\n",
       "      activity_3_cnt  activity_4_cnt  text_change_0_cnt  text_change_1_cnt  \\\n",
       "1005               0               0               1923                389   \n",
       "\n",
       "      text_change_2_cnt  text_change_3_cnt  ...  paragraph_word_count_min  \\\n",
       "1005                 14                 18  ...                        59   \n",
       "\n",
       "      paragraph_word_count_max  paragraph_word_count_first  \\\n",
       "1005                        98                          71   \n",
       "\n",
       "      paragraph_word_count_last  paragraph_word_count_q1  \\\n",
       "1005                         98                     68.0   \n",
       "\n",
       "      paragraph_word_count_median  paragraph_word_count_q3  \\\n",
       "1005                         74.0                    82.25   \n",
       "\n",
       "      paragraph_word_count_sum  keys_per_second  product_to_keys  \n",
       "1005                       305         1.560324         0.745347  \n",
       "\n",
       "[1 rows x 166 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats[train_feats['id']=='69916fc0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ace8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs.filter(pl.col('id')=='b73648cf').collect().to_pandas().to_csv('b73648cf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f87495de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "      <th>iteration</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>69916fc0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.748508</td>\n",
       "      <td>4</td>\n",
       "      <td>2.748508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>68df1430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.696622</td>\n",
       "      <td>7</td>\n",
       "      <td>2.696622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>69916fc0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.696166</td>\n",
       "      <td>4</td>\n",
       "      <td>2.696166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>69916fc0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.672941</td>\n",
       "      <td>3</td>\n",
       "      <td>2.672941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>69916fc0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.662965</td>\n",
       "      <td>10</td>\n",
       "      <td>2.662965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>e86a132d</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.148220</td>\n",
       "      <td>2</td>\n",
       "      <td>2.648220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>aac5ac07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.641690</td>\n",
       "      <td>5</td>\n",
       "      <td>2.641690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>e86a132d</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.136043</td>\n",
       "      <td>7</td>\n",
       "      <td>2.636043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1fbedb17</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.118027</td>\n",
       "      <td>7</td>\n",
       "      <td>2.618027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>e86a132d</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.105837</td>\n",
       "      <td>7</td>\n",
       "      <td>2.605837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>aac5ac07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.600332</td>\n",
       "      <td>5</td>\n",
       "      <td>2.600332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>68df1430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.590073</td>\n",
       "      <td>9</td>\n",
       "      <td>2.590073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>a04a32c3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.087373</td>\n",
       "      <td>2</td>\n",
       "      <td>2.587373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>69916fc0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.578596</td>\n",
       "      <td>10</td>\n",
       "      <td>2.578596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>68df1430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.567566</td>\n",
       "      <td>7</td>\n",
       "      <td>2.567566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>a04a32c3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.063790</td>\n",
       "      <td>6</td>\n",
       "      <td>2.563790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>aac5ac07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.546504</td>\n",
       "      <td>6</td>\n",
       "      <td>2.546504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>aac5ac07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.524397</td>\n",
       "      <td>2</td>\n",
       "      <td>2.524397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>aac5ac07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.518193</td>\n",
       "      <td>9</td>\n",
       "      <td>2.518193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>a04a32c3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.998531</td>\n",
       "      <td>10</td>\n",
       "      <td>2.498531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>68df1430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.493196</td>\n",
       "      <td>4</td>\n",
       "      <td>2.493196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>e86a132d</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.985116</td>\n",
       "      <td>10</td>\n",
       "      <td>2.485116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>a04a32c3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.967623</td>\n",
       "      <td>9</td>\n",
       "      <td>2.467623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>e86a132d</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.957606</td>\n",
       "      <td>7</td>\n",
       "      <td>2.457606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>68df1430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.427942</td>\n",
       "      <td>5</td>\n",
       "      <td>2.427942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3402f8b4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.354695</td>\n",
       "      <td>10</td>\n",
       "      <td>2.354695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>a04a32c3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.844441</td>\n",
       "      <td>4</td>\n",
       "      <td>2.344441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3402f8b4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.337176</td>\n",
       "      <td>10</td>\n",
       "      <td>2.337176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3402f8b4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.335674</td>\n",
       "      <td>6</td>\n",
       "      <td>2.335674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3402f8b4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.327718</td>\n",
       "      <td>10</td>\n",
       "      <td>2.327718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>b73648cf</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.691945</td>\n",
       "      <td>10</td>\n",
       "      <td>2.308055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3402f8b4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.301749</td>\n",
       "      <td>5</td>\n",
       "      <td>2.301749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>b73648cf</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.708327</td>\n",
       "      <td>1</td>\n",
       "      <td>2.291673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>b73648cf</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.721454</td>\n",
       "      <td>3</td>\n",
       "      <td>2.278546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>e817ec7a</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.771464</td>\n",
       "      <td>4</td>\n",
       "      <td>2.271464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  score     preds  iteration      rmse\n",
       "1005  69916fc0    1.0  3.748508          4  2.748508\n",
       "998   68df1430    1.0  3.696622          7  2.696622\n",
       "1005  69916fc0    1.0  3.696166          4  2.696166\n",
       "1005  69916fc0    1.0  3.672941          3  2.672941\n",
       "1005  69916fc0    1.0  3.662965         10  2.662965\n",
       "2232  e86a132d    1.5  4.148220          2  2.648220\n",
       "1614  aac5ac07    1.0  3.641690          5  2.641690\n",
       "2232  e86a132d    1.5  4.136043          7  2.636043\n",
       "306   1fbedb17    2.5  5.118027          7  2.618027\n",
       "2232  e86a132d    1.5  4.105837          7  2.605837\n",
       "1614  aac5ac07    1.0  3.600332          5  2.600332\n",
       "998   68df1430    1.0  3.590073          9  2.590073\n",
       "1513  a04a32c3    1.5  4.087373          2  2.587373\n",
       "1005  69916fc0    1.0  3.578596         10  2.578596\n",
       "998   68df1430    1.0  3.567566          7  2.567566\n",
       "1513  a04a32c3    1.5  4.063790          6  2.563790\n",
       "1614  aac5ac07    1.0  3.546504          6  2.546504\n",
       "1614  aac5ac07    1.0  3.524397          2  2.524397\n",
       "1614  aac5ac07    1.0  3.518193          9  2.518193\n",
       "1513  a04a32c3    1.5  3.998531         10  2.498531\n",
       "998   68df1430    1.0  3.493196          4  2.493196\n",
       "2232  e86a132d    1.5  3.985116         10  2.485116\n",
       "1513  a04a32c3    1.5  3.967623          9  2.467623\n",
       "2232  e86a132d    1.5  3.957606          7  2.457606\n",
       "998   68df1430    1.0  3.427942          5  2.427942\n",
       "497   3402f8b4    2.0  4.354695         10  2.354695\n",
       "1513  a04a32c3    1.5  3.844441          4  2.344441\n",
       "497   3402f8b4    2.0  4.337176         10  2.337176\n",
       "497   3402f8b4    2.0  4.335674          6  2.335674\n",
       "497   3402f8b4    2.0  4.327718         10  2.327718\n",
       "1747  b73648cf    6.0  3.691945         10  2.308055\n",
       "497   3402f8b4    2.0  4.301749          5  2.301749\n",
       "1747  b73648cf    6.0  3.708327          1  2.291673\n",
       "1747  b73648cf    6.0  3.721454          3  2.278546\n",
       "2231  e817ec7a    2.5  4.771464          4  2.271464"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds.sort_values(by='rmse', ascending=False).head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a9354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Mapping >\n",
      "Number of features: 165\n"
     ]
    }
   ],
   "source": [
    "# tr_ids = data.id\n",
    "# ts_ids = test_feats.id\n",
    "# \n",
    "# tr_ts_feats = pd.concat([data, test_feats])\n",
    "# tr_ts_feats.iloc[:,1:-1] = preprocess_feats(tr_ts_feats.iloc[:,1:-1], StandardScaler())\n",
    "# \n",
    "# data = tr_ts_feats[tr_ts_feats['id'].isin(tr_ids)]\n",
    "# test_feats = tr_ts_feats[tr_ts_feats['id'].isin(ts_ids)]\n",
    "\n",
    "print('< Mapping >')\n",
    "train_scores   = pd.read_csv(data_path + 'train_scores.csv')\n",
    "data           = train_feats.merge(train_scores, on='id', how='left')\n",
    "test_ids        = test_feats['id'].values\n",
    "testin_x        = test_feats.drop(['id'], axis=1)\n",
    "x               = data.drop(['id', 'score'], axis=1)\n",
    "y               = data['score'].values\n",
    "print(f'Number of features: {len(x.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce229de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Learning and Evaluation >\n",
      "Final RMSE over 50: 0.620546.\n",
      "RMSE by fold 0.620478\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "print('< Learning and Evaluation >')\n",
    "param = {'n_estimators': 1024,\n",
    "         'learning_rate': 0.005,\n",
    "         'metric': 'rmse',\n",
    "         'force_col_wise': True,\n",
    "         'verbosity': 0,}\n",
    "\n",
    "\n",
    "data_x = x.copy()\n",
    "data_y = y.copy()\n",
    "test_x=testin_x.copy()\n",
    "n_splits = 5\n",
    "iterations = 10\n",
    "valid_preds = pd.DataFrame(columns = ['id', 'score', 'preds', 'iteration'])\n",
    "test_preds = []\n",
    "\n",
    "for iter in range(iterations):\n",
    "    skf    = StratifiedKFold(n_splits=n_splits, random_state=42+iter, shuffle=True)\n",
    "    model = LGBMRegressor(**param, random_state=42+iter)\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(data_x, data_y.astype(str))):\n",
    "        train_x, train_y, valid_x, valid_y = train_valid_split(data_x, data_y, train_index, valid_index)\n",
    "        \n",
    "        model.fit(train_x, train_y)\n",
    "        valid_predictions = model.predict(valid_x)\n",
    "        test_predictions = model.predict(test_x)\n",
    "        test_preds.append(test_predictions)\n",
    "\n",
    "        tmp_df = data.loc[valid_index][['id','score']]\n",
    "        tmp_df['preds'] = valid_predictions\n",
    "        tmp_df['iteration'] = i + 1\n",
    "        valid_preds = pd.concat([valid_preds, tmp_df])\n",
    "\n",
    "    final_rmse = mean_squared_error(valid_preds['score'], valid_preds['preds'], squared=False)\n",
    "    cv_rmse = valid_preds.groupby(['iteration']).apply(lambda g: calculate_rmse(g['score'], g['preds']))\n",
    "\n",
    "print(f'Final RMSE over {n_splits * iterations}: {final_rmse:.6f}.')\n",
    "print(f'RMSE by fold {np.mean(cv_rmse):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d0f50",
   "metadata": {},
   "source": [
    "adding wc_change (proper)\n",
    "\n",
    "\n",
    "< Learning and Evaluation > adding vectoriz\n",
    "Final RMSE 0.615059.\n",
    "RMSE by fold 0.614998\n",
    "\n",
    "5 iterations baseline\n",
    "Final RMSE 0.619785.\n",
    "RMSE by fold 0.619458\n",
    "\n",
    "< Learning and Evaluation > adding at_by_activity\n",
    "Final RMSE 0.621999.\n",
    "RMSE by fold 0.621681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23091e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE 0.612482.\n",
      "RMSE by fold 0.611805\n"
     ]
    }
   ],
   "source": [
    "data_x = x.copy()\n",
    "data_y = y.copy()\n",
    "test_x=testin_x.copy()\n",
    "n_splits = 10\n",
    "model = LGBMRegressor(**param)\n",
    "\n",
    "skf    = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "test_y = np.zeros(len(data_x)) if (test_x is None) else np.zeros((len(test_x), n_splits))\n",
    "test_preds = []\n",
    "\n",
    "valid_preds = pd.DataFrame(columns = ['id', 'score', 'preds', 'iteration'])\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(data_x, data_y.astype(str))):\n",
    "    train_x, train_y, valid_x, valid_y = train_valid_split(data_x, data_y, train_index, valid_index)\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    valid_predictions = model.predict(valid_x)\n",
    "    test_predictions = model.predict(test_x)\n",
    "    test_preds.append(test_predictions)\n",
    "\n",
    "    tmp_df = data.loc[valid_index][['id','score']]\n",
    "    tmp_df['preds'] = valid_predictions\n",
    "    tmp_df['iteration'] = i + 1\n",
    "    valid_preds = pd.concat([valid_preds, tmp_df])\n",
    "\n",
    "final_rmse = mean_squared_error(valid_preds['score'], valid_preds['preds'], squared=False)\n",
    "cv_rmse = valid_preds.groupby(['iteration']).apply(lambda g: calculate_rmse(g['score'], g['preds']))\n",
    "print(f'Final RMSE {final_rmse:.6f}.')\n",
    "print(f'RMSE by fold {np.mean(cv_rmse):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "04996eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iteration\n",
       "1     0.595718\n",
       "2     0.601724\n",
       "3     0.597549\n",
       "4     0.607840\n",
       "5     0.575182\n",
       "6     0.576292\n",
       "7     0.612651\n",
       "8     0.636930\n",
       "9     0.641946\n",
       "10    0.672214\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b273cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds.iteration.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69723ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iteration\n",
       "1     0.595718\n",
       "2     0.601724\n",
       "3     0.597549\n",
       "4     0.607840\n",
       "5     0.575182\n",
       "6     0.576292\n",
       "7     0.612651\n",
       "8     0.636930\n",
       "9     0.641946\n",
       "10    0.672214\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_rmse(y, yhat):\n",
    "    return mean_squared_error(y, yhat, squared=False)\n",
    "\n",
    "valid_preds.groupby(['iteration']).apply(lambda g: calculate_rmse(g['score'], g['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7da6b6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6124817170301459"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(valid_preds['score'], valid_preds['preds'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1db64fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7826121114767812"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(valid_preds['score'], valid_preds['preds'], squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb35d1",
   "metadata": {
    "papermill": {
     "duration": 0.004305,
     "end_time": "2023-12-06T06:43:56.426590",
     "exception": false,
     "start_time": "2023-12-06T06:43:56.422285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6934ff20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T06:43:56.438293Z",
     "iopub.status.busy": "2023-12-06T06:43:56.437798Z",
     "iopub.status.idle": "2023-12-06T06:46:44.581107Z",
     "shell.execute_reply": "2023-12-06T06:46:44.579963Z"
    },
    "papermill": {
     "duration": 168.15235,
     "end_time": "2023-12-06T06:46:44.583943",
     "exception": false,
     "start_time": "2023-12-06T06:43:56.431593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "< Essay Reconstruction >\n",
      "< Mapping >\n",
      "Number of features: 165\n",
      "< Testing Data >\n",
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "< Learning and Evaluation >\n"
     ]
    }
   ],
   "source": [
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(data_path + 'train_logs.csv')\n",
    "train_feats   = dev_feats(train_logs)\n",
    "train_feats   = train_feats.collect().to_pandas()\n",
    "\n",
    "print('< Essay Reconstruction >')\n",
    "train_logs             = train_logs.collect().to_pandas()\n",
    "train_essays           = get_essay_df(train_logs)\n",
    "train_feats            = train_feats.merge(word_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(get_keys_pressed_per_second(train_logs), on='id', how='left')\n",
    "train_feats            = train_feats.merge(product_to_keys(train_logs, train_essays), on='id', how='left')\n",
    "\n",
    "\n",
    "print('< Mapping >')\n",
    "train_scores   = pd.read_csv(data_path + 'train_scores.csv')\n",
    "data           = train_feats.merge(train_scores, on='id', how='left')\n",
    "x              = data.drop(['id', 'score'], axis=1)\n",
    "y              = data['score'].values\n",
    "print(f'Number of features: {len(x.columns)}')\n",
    "\n",
    "\n",
    "print('< Testing Data >')\n",
    "test_logs   = pl.scan_csv(data_path + 'test_logs.csv')\n",
    "test_feats  = dev_feats(test_logs)\n",
    "test_feats  = test_feats.collect().to_pandas()\n",
    "\n",
    "test_logs             = test_logs.collect().to_pandas()\n",
    "test_essays           = get_essay_df(test_logs)\n",
    "test_feats            = test_feats.merge(word_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(get_keys_pressed_per_second(test_logs), on='id', how='left')\n",
    "test_feats            = test_feats.merge(product_to_keys(test_logs, test_essays), on='id', how='left')\n",
    "\n",
    "\n",
    "test_ids = test_feats['id'].values\n",
    "testin_x = test_feats.drop(['id'], axis=1)\n",
    "\n",
    "print('< Learning and Evaluation >')\n",
    "param = {'n_estimators': 1024,\n",
    "         'learning_rate': 0.005,\n",
    "         'metric': 'rmse',\n",
    "         'random_state': 42,\n",
    "         'force_col_wise': True,\n",
    "         'verbosity': 0,}\n",
    "solution = LGBMRegressor(**param)\n",
    "y_pred   = evaluate(x.copy(), y.copy(), solution, test_x=testin_x.copy()) \n",
    "\n",
    "sub = pd.DataFrame({'id': test_ids, 'score': y_pred})\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a48cc6",
   "metadata": {
    "papermill": {
     "duration": 0.004677,
     "end_time": "2023-12-06T06:46:44.593933",
     "exception": false,
     "start_time": "2023-12-06T06:46:44.589256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19928ea",
   "metadata": {
    "papermill": {
     "duration": 0.004739,
     "end_time": "2023-12-06T06:46:44.603604",
     "exception": false,
     "start_time": "2023-12-06T06:46:44.598865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e75f34",
   "metadata": {
    "papermill": {
     "duration": 0.004601,
     "end_time": "2023-12-06T06:46:44.613343",
     "exception": false,
     "start_time": "2023-12-06T06:46:44.608742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6678907,
     "sourceId": 59291,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 176.983197,
   "end_time": "2023-12-06T06:46:45.642128",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-06T06:43:48.658931",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
