{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from m4_feats_polars import *\n",
    "from m5_sb_models import lgb_pipeline\n",
    "import polars as pl\n",
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_STORE = 'feature_store'\n",
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n",
    "test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n",
    "train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')\n",
    "train_scores = train_scores.collect().to_pandas()\n",
    "\n",
    "param = {'n_estimators': 1024,\n",
    "         'learning_rate': 0.005,\n",
    "         'metric': 'rmse',\n",
    "         'force_col_wise': True,\n",
    "         'verbosity': 0,}\n",
    "\n",
    "feat_list = os.listdir(FEAT_STORE)\n",
    "list_train_feats = [feat for feat in feat_list if feat.startswith('train')]\n",
    "#test_feats = [feat for feat in feat_list if feat.startswith('test')]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essays           = get_essay_df(train_logs.collect().to_pandas())\n",
    "test_essays           = get_essay_df(test_logs.collect().to_pandas())\n",
    " \n",
    "tr_feats, ts_feats = product_to_keys([train_logs.collect().to_pandas(),\n",
    "                                      test_logs.collect().to_pandas()], \n",
    "                                      [train_essays,test_essays])\n",
    "tr_feats, ts_feats = get_keys_pressed_per_second(train_logs.collect().to_pandas(), test_logs.collect().to_pandas())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                                              essay\n",
      "0     001519c8  qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...\n",
      "1     0022f953  qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...\n",
      "2     0042269b  qqqqqqqqqqq qq qqqqq qqqqqqqqq qq qqqqqqqqqqq ...\n",
      "3     0059420b  qq qqqqqqq qqqqqq qqqqqqqqqqqqq qqqq q qqqq qq...\n",
      "4     0075873a  qqqqqqqqqqq qq qqq qqqqq qq qqqqqqqqqq, qqq qq...\n",
      "...        ...                                                ...\n",
      "2466  ffb8c745       qq qqqqq'q qqqqqqq, qqq'q qqqqq q qqqq qq...\n",
      "2467  ffbef7e5  qqqq qqqqqq qqqqq qq qqqqq qqqqq, qq qq q qqqq...\n",
      "2468  ffccd6fd  qqqqqq qqqq q qqqqqqq qqqqqqqqq qq qqqqqq qqqq...\n",
      "2469  ffec5b38  qqqqqqqqqq qqqqqqq, qqqqqq qqqq qqqqq qqqq qqq...\n",
      "2470  fff05981  qq qqqq qqqqqqq qqqqqqqq qq qqqqqqqqqqq qq qq ...\n",
      "\n",
      "[2471 rows x 2 columns]\n",
      "         id essay\n",
      "0  0000aaaa      \n",
      "1  2222bbbb    qq\n",
      "2  4444cccc    q \n",
      "< Essays word feats >\n",
      "< Essays word feats >\n",
      "< Essays sentences feats >\n",
      "< Essays sentences feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n"
     ]
    }
   ],
   "source": [
    "train_logs = train_logs.collect().to_pandas()\n",
    "test_logs = test_logs.collect().to_pandas()\n",
    "train_essays = get_essay_df(train_logs)\n",
    "test_essays = get_essay_df(test_logs)\n",
    "file_name = 'count_vectorise'\n",
    "tr, ts = countvectorize_one_one(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'count_vectorise_bigrams'\n",
    "tr, ts = countvectorize_two_one(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_words'\n",
    "tr = word_feats(train_essays)\n",
    "ts = word_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_sentences'\n",
    "tr = sent_feats(train_essays)\n",
    "ts = sent_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_paragraphs'\n",
    "tr = parag_feats(train_essays)\n",
    "ts = parag_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 0 of training feats\n",
      "feats empty - setting up train_feats\n",
      "Training... train_event_id_stats.pkl\n",
      "Train feats cols Index(['id', 'eid_stats_sum', 'eid_stats_mean', 'eid_stats_std',\n",
      "       'eid_stats_max', 'eid_stats_q1', 'eid_stats_median', 'eid_stats_q3',\n",
      "       'eid_stats_kurt', 'eid_stats_skew', 'score'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.767516. Std 0.7233\n",
      "RMSE by fold 0.767447. Std 0.0103\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_categorical_nunique.pkl\n",
      "Train feats cols Index(['id', 'score', 'activity_nunique', 'down_event_nunique',\n",
      "       'text_change_nunique'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.906628. Std 0.5417\n",
      "RMSE by fold 0.906537. Std 0.0123\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_sentences.pkl\n",
      "Train feats cols Index(['id', 'score', 'sent_count', 'sent_len_mean', 'sent_len_min',\n",
      "       'sent_len_max', 'sent_len_first', 'sent_len_last', 'sent_len_q1',\n",
      "       'sent_len_median', 'sent_len_q3', 'sent_len_sum',\n",
      "       'sent_word_count_mean', 'sent_word_count_min', 'sent_word_count_max',\n",
      "       'sent_word_count_first', 'sent_word_count_last', 'sent_word_count_q1',\n",
      "       'sent_word_count_median', 'sent_word_count_q3', 'sent_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.664262. Std 0.8011\n",
      "RMSE by fold 0.664100. Std 0.0146\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_vectorise_bigrams.pkl\n",
      "Train feats cols Index(['id', 'score', 'bigram_tok_0', 'bigram_tok_1', 'bigram_tok_2',\n",
      "       'bigram_tok_3', 'bigram_tok_4', 'bigram_tok_5', 'bigram_tok_6',\n",
      "       'bigram_tok_7', 'bigram_tok_8', 'bigram_tok_9', 'bigram_tok_10',\n",
      "       'bigram_tok_11', 'bigram_tok_12', 'bigram_tok_13', 'bigram_tok_14',\n",
      "       'bigram_tok_15'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.725255. Std 0.7523\n",
      "RMSE by fold 0.725136. Std 0.0127\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_by_activity.pkl\n",
      "Train feats cols Index(['id', 'score', 'Remove/Cut', 'Replace', 'Nonproduction', 'Input',\n",
      "       'Paste'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.824715. Std 0.6646\n",
      "RMSE by fold 0.824539. Std 0.0165\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'score', 'roc_zro_count', 'pos_change_count', 'neg_change_count',\n",
      "       'roc_count', 'roc_mean', 'roc_std', 'roc_sum', 'roc_max', 'roc_q1',\n",
      "       'roc_median', 'roc_q3', 'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.712249. Std 0.7711\n",
      "RMSE by fold 0.712094. Std 0.0145\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_stats.pkl\n",
      "Train feats cols Index(['id', 'score', 'word_count_sum', 'word_count_mean', 'word_count_std',\n",
      "       'word_count_max', 'word_count_q1', 'word_count_median', 'word_count_q3',\n",
      "       'word_count_kurt', 'word_count_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.733178. Std 0.7506\n",
      "RMSE by fold 0.732996. Std 0.0158\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_pauses.pkl\n",
      "Train feats cols Index(['id', 'score', 'inter_key_largest_lantency',\n",
      "       'inter_key_median_lantency', 'mean_pause_time', 'std_pause_time',\n",
      "       'total_pause_time', 'pauses_half_sec', 'pauses_1_sec',\n",
      "       'pauses_1_half_sec', 'pauses_2_sec', 'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.733643. Std 0.7413\n",
      "RMSE by fold 0.733535. Std 0.0124\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts.pkl\n",
      "Train feats cols Index(['id', 'score', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5',\n",
      "       'event_6', 'event_7', 'event_8', 'event_9', 'event_10', 'event_11',\n",
      "       'event_12', 'event_13', 'event_14', 'event_15', 'event_16', 'event_17',\n",
      "       'event_18', 'event_19', 'event_20'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.653867. Std 0.7974\n",
      "RMSE by fold 0.653762. Std 0.0117\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_change.pkl\n",
      "Train feats cols Index(['id', 'score', 'input_text_count', 'input_text_len_mean',\n",
      "       'input_text_len_max', 'input_text_len_std', 'input_text_len_median',\n",
      "       'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.757319. Std 0.7408\n",
      "RMSE by fold 0.757154. Std 0.0153\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_vectorise.pkl\n",
      "Train feats cols Index(['id', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3', 'tok_4', 'tok_5',\n",
      "       'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10', 'tok_11', 'tok_12',\n",
      "       'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.670668. Std 0.7934\n",
      "RMSE by fold 0.670534. Std 0.0130\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'score', 'eid_roc_count_zr', 'eid_roc_count', 'eid_roc_mean',\n",
      "       'eid_roc_std', 'eid_roc_max', 'eid_roc_q1', 'eid_roc_median',\n",
      "       'eid_roc_q3', 'eid_roc_kurt', 'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.788705. Std 0.6973\n",
      "RMSE by fold 0.788636. Std 0.0105\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_of_activities.pkl\n",
      "Train feats cols Index(['id', 'score', 'activity_0_cnt', 'activity_1_cnt', 'activity_2_cnt',\n",
      "       'activity_3_cnt', 'activity_4_cnt'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.729591. Std 0.7562\n",
      "RMSE by fold 0.729496. Std 0.0113\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_time_based_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'score', 'cursor_pos_mean', 'cursor_pos_std', 'cursor_pos_max',\n",
      "       'cursor_pos_q1', 'cursor_pos_median', 'cursor_pos_q3',\n",
      "       'cursor_pos_kurt', 'cursor_pos_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.730703. Std 0.7570\n",
      "RMSE by fold 0.730479. Std 0.0176\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_p_burst.pkl\n",
      "Train feats cols Index(['id', 'score', 'burst_count', 'burst_mean', 'burst_sum', 'burst_std',\n",
      "       'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.761667. Std 0.7352\n",
      "RMSE by fold 0.761553. Std 0.0128\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_stats.pkl\n",
      "Train feats cols Index(['id', 'score', 'action_time_mean', 'action_time_std',\n",
      "       'action_time_max'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.968697. Std 0.4566\n",
      "RMSE by fold 0.968533. Std 0.0177\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'score', 'action_time_mean', 'action_time_std', 'action_time_max',\n",
      "       'action_time_q1', 'action_time_median', 'action_time_q3',\n",
      "       'action_time_kurt', 'action_time_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.744848. Std 0.7530\n",
      "RMSE by fold 0.744659. Std 0.0163\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_words.pkl\n",
      "Train feats cols Index(['id', 'score', 'word_len_count', 'word_len_mean', 'word_len_min',\n",
      "       'word_len_max', 'word_len_first', 'word_len_last', 'word_len_q1',\n",
      "       'word_len_median', 'word_len_q3', 'word_len_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.679655. Std 0.8024\n",
      "RMSE by fold 0.679459. Std 0.0161\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_paragraphs.pkl\n",
      "Train feats cols Index(['id', 'score', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.677797. Std 0.7969\n",
      "RMSE by fold 0.677633. Std 0.0148\n",
      "Train feats  before merging Index(['id', 'score'], dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst.pkl\n",
      "Train feats cols Index(['id', 'score', 'r_burst_count', 'r_burst_mean', 'r_burst_sum',\n",
      "       'r_burst_std', 'r_burst_max', 'r_burst_min', 'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.947562. Std 0.5231\n",
      "RMSE by fold 0.947499. Std 0.0109\n",
      "                                feat_name      RMSE\n",
      "0                train_event_id_stats.pkl  0.767516\n",
      "0           train_categorical_nunique.pkl  0.906628\n",
      "0               train_essay_sentences.pkl  0.664262\n",
      "0       train_count_vectorise_bigrams.pkl  0.725255\n",
      "0       train_action_time_by_activity.pkl  0.824715\n",
      "0    train_word_counts_rate_of_change.pkl  0.712249\n",
      "0              train_word_count_stats.pkl  0.733178\n",
      "0                        train_pauses.pkl  0.733643\n",
      "0                 train_events_counts.pkl  0.653867\n",
      "0                  train_input_change.pkl  0.757319\n",
      "0               train_count_vectorise.pkl  0.670668\n",
      "0  train_events_counts_rate_of_change.pkl  0.788705\n",
      "0           train_count_of_activities.pkl  0.729591\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.730703\n",
      "0                       train_p_burst.pkl  0.761667\n",
      "0             train_action_time_stats.pkl  0.968697\n",
      "0              train_cursor_pos_stats.pkl  0.744848\n",
      "0                   train_essay_words.pkl  0.679655\n",
      "0              train_essay_paragraphs.pkl  0.677797\n",
      "0                       train_r_burst.pkl  0.947562\n",
      "Results:                                 feat_name      RMSE\n",
      "0                 train_events_counts.pkl  0.653867\n",
      "0               train_essay_sentences.pkl  0.664262\n",
      "0               train_count_vectorise.pkl  0.670668\n",
      "0              train_essay_paragraphs.pkl  0.677797\n",
      "0                   train_essay_words.pkl  0.679655\n",
      "0    train_word_counts_rate_of_change.pkl  0.712249\n",
      "0       train_count_vectorise_bigrams.pkl  0.725255\n",
      "0           train_count_of_activities.pkl  0.729591\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.730703\n",
      "0              train_word_count_stats.pkl  0.733178\n",
      "0                        train_pauses.pkl  0.733643\n",
      "0              train_cursor_pos_stats.pkl  0.744848\n",
      "0                  train_input_change.pkl  0.757319\n",
      "0                       train_p_burst.pkl  0.761667\n",
      "0                train_event_id_stats.pkl  0.767516\n",
      "0  train_events_counts_rate_of_change.pkl  0.788705\n",
      "0       train_action_time_by_activity.pkl  0.824715\n",
      "0           train_categorical_nunique.pkl  0.906628\n",
      "0                       train_r_burst.pkl  0.947562\n",
      "0             train_action_time_stats.pkl  0.968697\n",
      "Results improved!\n",
      "list_train_feats: ['train_event_id_stats.pkl', 'train_categorical_nunique.pkl', 'train_essay_sentences.pkl', 'train_count_vectorise_bigrams.pkl', 'train_action_time_by_activity.pkl', 'train_word_counts_rate_of_change.pkl', 'train_word_count_stats.pkl', 'train_pauses.pkl', 'train_input_change.pkl', 'train_count_vectorise.pkl', 'train_events_counts_rate_of_change.pkl', 'train_count_of_activities.pkl', 'train_time_based_cursor_pos_stats.pkl', 'train_p_burst.pkl', 'train_action_time_stats.pkl', 'train_cursor_pos_stats.pkl', 'train_essay_words.pkl', 'train_essay_paragraphs.pkl', 'train_r_burst.pkl']\n",
      "added_feats_list: ['train_events_counts.pkl']\n",
      "best feat: train_events_counts.pkl\n",
      "Starting round 1 of training feats\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_categorical_nunique.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'activity_nunique', 'down_event_nunique',\n",
      "       'text_change_nunique', 'score'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.651915. Std 0.7959\n",
      "RMSE by fold 0.651801. Std 0.0121\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_sentences.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'sent_count', 'sent_len_mean',\n",
      "       'sent_len_min', 'sent_len_max', 'sent_len_first', 'sent_len_last',\n",
      "       'sent_len_q1', 'sent_len_median', 'sent_len_q3', 'sent_len_sum',\n",
      "       'sent_word_count_mean', 'sent_word_count_min', 'sent_word_count_max',\n",
      "       'sent_word_count_first', 'sent_word_count_last', 'sent_word_count_q1',\n",
      "       'sent_word_count_median', 'sent_word_count_q3', 'sent_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.636796. Std 0.8129\n",
      "RMSE by fold 0.636697. Std 0.0110\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_vectorise_bigrams.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'bigram_tok_0', 'bigram_tok_1',\n",
      "       'bigram_tok_2', 'bigram_tok_3', 'bigram_tok_4', 'bigram_tok_5',\n",
      "       'bigram_tok_6', 'bigram_tok_7', 'bigram_tok_8', 'bigram_tok_9',\n",
      "       'bigram_tok_10', 'bigram_tok_11', 'bigram_tok_12', 'bigram_tok_13',\n",
      "       'bigram_tok_14', 'bigram_tok_15'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.650828. Std 0.8009\n",
      "RMSE by fold 0.650641. Std 0.0153\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_by_activity.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'Remove/Cut', 'Replace',\n",
      "       'Nonproduction', 'Input', 'Paste'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.654091. Std 0.7954\n",
      "RMSE by fold 0.653965. Std 0.0128\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'roc_zro_count', 'pos_change_count',\n",
      "       'neg_change_count', 'roc_count', 'roc_mean', 'roc_std', 'roc_sum',\n",
      "       'roc_max', 'roc_q1', 'roc_median', 'roc_q3', 'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.644114. Std 0.8053\n",
      "RMSE by fold 0.644001. Std 0.0119\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'word_count_sum', 'word_count_mean',\n",
      "       'word_count_std', 'word_count_max', 'word_count_q1',\n",
      "       'word_count_median', 'word_count_q3', 'word_count_kurt',\n",
      "       'word_count_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.654467. Std 0.7998\n",
      "RMSE by fold 0.654339. Std 0.0127\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_pauses.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'inter_key_largest_lantency',\n",
      "       'inter_key_median_lantency', 'mean_pause_time', 'std_pause_time',\n",
      "       'total_pause_time', 'pauses_half_sec', 'pauses_1_sec',\n",
      "       'pauses_1_half_sec', 'pauses_2_sec', 'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.642837. Std 0.8034\n",
      "RMSE by fold 0.642698. Std 0.0132\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'input_text_count',\n",
      "       'input_text_len_mean', 'input_text_len_max', 'input_text_len_std',\n",
      "       'input_text_len_median', 'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.656129. Std 0.7979\n",
      "RMSE by fold 0.656041. Std 0.0107\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_vectorise.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.631284. Std 0.8140\n",
      "RMSE by fold 0.631146. Std 0.0130\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'eid_roc_count_zr', 'eid_roc_count',\n",
      "       'eid_roc_mean', 'eid_roc_std', 'eid_roc_max', 'eid_roc_q1',\n",
      "       'eid_roc_median', 'eid_roc_q3', 'eid_roc_kurt', 'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.651657. Std 0.7960\n",
      "RMSE by fold 0.651570. Std 0.0105\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_of_activities.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'activity_0_cnt', 'activity_1_cnt',\n",
      "       'activity_2_cnt', 'activity_3_cnt', 'activity_4_cnt'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.654893. Std 0.7955\n",
      "RMSE by fold 0.654831. Std 0.0090\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_time_based_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'cursor_pos_mean', 'cursor_pos_std',\n",
      "       'cursor_pos_max', 'cursor_pos_q1', 'cursor_pos_median', 'cursor_pos_q3',\n",
      "       'cursor_pos_kurt', 'cursor_pos_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.651236. Std 0.8024\n",
      "RMSE by fold 0.651125. Std 0.0119\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_p_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'burst_count', 'burst_mean',\n",
      "       'burst_sum', 'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.658135. Std 0.7940\n",
      "RMSE by fold 0.658049. Std 0.0108\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'action_time_mean', 'action_time_std',\n",
      "       'action_time_max'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.658503. Std 0.7934\n",
      "RMSE by fold 0.658407. Std 0.0112\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'action_time_mean', 'action_time_std',\n",
      "       'action_time_max', 'action_time_q1', 'action_time_median',\n",
      "       'action_time_q3', 'action_time_kurt', 'action_time_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.653055. Std 0.7999\n",
      "RMSE by fold 0.652929. Std 0.0127\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_words.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'word_len_count', 'word_len_mean',\n",
      "       'word_len_min', 'word_len_max', 'word_len_first', 'word_len_last',\n",
      "       'word_len_q1', 'word_len_median', 'word_len_q3', 'word_len_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.636652. Std 0.8155\n",
      "RMSE by fold 0.636547. Std 0.0113\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_paragraphs.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'paragraph_count',\n",
      "       'paragraph_len_mean', 'paragraph_len_min', 'paragraph_len_max',\n",
      "       'paragraph_len_first', 'paragraph_len_last', 'paragraph_len_q1',\n",
      "       'paragraph_len_median', 'paragraph_len_q3', 'paragraph_len_sum',\n",
      "       'paragraph_word_count_mean', 'paragraph_word_count_min',\n",
      "       'paragraph_word_count_max', 'paragraph_word_count_first',\n",
      "       'paragraph_word_count_last', 'paragraph_word_count_q1',\n",
      "       'paragraph_word_count_median', 'paragraph_word_count_q3',\n",
      "       'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.638007. Std 0.8095\n",
      "RMSE by fold 0.637869. Std 0.0129\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'r_burst_count', 'r_burst_mean',\n",
      "       'r_burst_sum', 'r_burst_std', 'r_burst_max', 'r_burst_min',\n",
      "       'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.657154. Std 0.7942\n",
      "RMSE by fold 0.657056. Std 0.0114\n",
      "                                feat_name      RMSE\n",
      "0                 train_events_counts.pkl  0.653867\n",
      "0               train_essay_sentences.pkl  0.664262\n",
      "0               train_count_vectorise.pkl  0.670668\n",
      "0              train_essay_paragraphs.pkl  0.677797\n",
      "0                   train_essay_words.pkl  0.679655\n",
      "0    train_word_counts_rate_of_change.pkl  0.712249\n",
      "0       train_count_vectorise_bigrams.pkl  0.725255\n",
      "0           train_count_of_activities.pkl  0.729591\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.730703\n",
      "0              train_word_count_stats.pkl  0.733178\n",
      "0                        train_pauses.pkl  0.733643\n",
      "0              train_cursor_pos_stats.pkl  0.744848\n",
      "0                  train_input_change.pkl  0.757319\n",
      "0                       train_p_burst.pkl  0.761667\n",
      "0                train_event_id_stats.pkl  0.767516\n",
      "0  train_events_counts_rate_of_change.pkl  0.788705\n",
      "0       train_action_time_by_activity.pkl  0.824715\n",
      "0           train_categorical_nunique.pkl  0.906628\n",
      "0                       train_r_burst.pkl  0.947562\n",
      "0             train_action_time_stats.pkl  0.968697\n",
      "0           train_categorical_nunique.pkl  0.651915\n",
      "0               train_essay_sentences.pkl  0.636796\n",
      "0       train_count_vectorise_bigrams.pkl  0.650828\n",
      "0       train_action_time_by_activity.pkl  0.654091\n",
      "0    train_word_counts_rate_of_change.pkl  0.644114\n",
      "0              train_word_count_stats.pkl  0.654467\n",
      "0                        train_pauses.pkl  0.642837\n",
      "0                  train_input_change.pkl  0.656129\n",
      "0               train_count_vectorise.pkl  0.631284\n",
      "0  train_events_counts_rate_of_change.pkl  0.651657\n",
      "0           train_count_of_activities.pkl  0.654893\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.651236\n",
      "0                       train_p_burst.pkl  0.658135\n",
      "0             train_action_time_stats.pkl  0.658503\n",
      "0              train_cursor_pos_stats.pkl  0.653055\n",
      "0                   train_essay_words.pkl  0.636652\n",
      "0              train_essay_paragraphs.pkl  0.638007\n",
      "0                       train_r_burst.pkl  0.657154\n",
      "Results:                                 feat_name      RMSE\n",
      "0               train_count_vectorise.pkl  0.631284\n",
      "0                   train_essay_words.pkl  0.636652\n",
      "0               train_essay_sentences.pkl  0.636796\n",
      "0              train_essay_paragraphs.pkl  0.638007\n",
      "0                        train_pauses.pkl  0.642837\n",
      "0    train_word_counts_rate_of_change.pkl  0.644114\n",
      "0       train_count_vectorise_bigrams.pkl  0.650828\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.651236\n",
      "0  train_events_counts_rate_of_change.pkl  0.651657\n",
      "0           train_categorical_nunique.pkl  0.651915\n",
      "0              train_cursor_pos_stats.pkl  0.653055\n",
      "0                 train_events_counts.pkl  0.653867\n",
      "0       train_action_time_by_activity.pkl  0.654091\n",
      "0              train_word_count_stats.pkl  0.654467\n",
      "0           train_count_of_activities.pkl  0.654893\n",
      "0                  train_input_change.pkl  0.656129\n",
      "0                       train_r_burst.pkl  0.657154\n",
      "0                       train_p_burst.pkl  0.658135\n",
      "0             train_action_time_stats.pkl  0.658503\n",
      "0               train_essay_sentences.pkl  0.664262\n",
      "0               train_count_vectorise.pkl  0.670668\n",
      "0              train_essay_paragraphs.pkl  0.677797\n",
      "0                   train_essay_words.pkl  0.679655\n",
      "0    train_word_counts_rate_of_change.pkl  0.712249\n",
      "0       train_count_vectorise_bigrams.pkl  0.725255\n",
      "0           train_count_of_activities.pkl  0.729591\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.730703\n",
      "0              train_word_count_stats.pkl  0.733178\n",
      "0                        train_pauses.pkl  0.733643\n",
      "0              train_cursor_pos_stats.pkl  0.744848\n",
      "0                  train_input_change.pkl  0.757319\n",
      "0                       train_p_burst.pkl  0.761667\n",
      "0                train_event_id_stats.pkl  0.767516\n",
      "0  train_events_counts_rate_of_change.pkl  0.788705\n",
      "0       train_action_time_by_activity.pkl  0.824715\n",
      "0           train_categorical_nunique.pkl  0.906628\n",
      "0                       train_r_burst.pkl  0.947562\n",
      "0             train_action_time_stats.pkl  0.968697\n",
      "Results improved!\n",
      "list_train_feats: ['train_event_id_stats.pkl', 'train_categorical_nunique.pkl', 'train_essay_sentences.pkl', 'train_count_vectorise_bigrams.pkl', 'train_action_time_by_activity.pkl', 'train_word_counts_rate_of_change.pkl', 'train_word_count_stats.pkl', 'train_pauses.pkl', 'train_input_change.pkl', 'train_events_counts_rate_of_change.pkl', 'train_count_of_activities.pkl', 'train_time_based_cursor_pos_stats.pkl', 'train_p_burst.pkl', 'train_action_time_stats.pkl', 'train_cursor_pos_stats.pkl', 'train_essay_words.pkl', 'train_essay_paragraphs.pkl', 'train_r_burst.pkl']\n",
      "added_feats_list: ['train_events_counts.pkl', 'train_count_vectorise.pkl']\n",
      "best feat: train_count_vectorise.pkl\n",
      "Starting round 2 of training feats\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_sentences.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'sent_count',\n",
      "       'sent_len_mean', 'sent_len_min', 'sent_len_max', 'sent_len_first',\n",
      "       'sent_len_last', 'sent_len_q1', 'sent_len_median', 'sent_len_q3',\n",
      "       'sent_len_sum', 'sent_word_count_mean', 'sent_word_count_min',\n",
      "       'sent_word_count_max', 'sent_word_count_first', 'sent_word_count_last',\n",
      "       'sent_word_count_q1', 'sent_word_count_median', 'sent_word_count_q3',\n",
      "       'sent_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.623422. Std 0.8178\n",
      "RMSE by fold 0.623305. Std 0.0118\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_vectorise_bigrams.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'bigram_tok_0',\n",
      "       'bigram_tok_1', 'bigram_tok_2', 'bigram_tok_3', 'bigram_tok_4',\n",
      "       'bigram_tok_5', 'bigram_tok_6', 'bigram_tok_7', 'bigram_tok_8',\n",
      "       'bigram_tok_9', 'bigram_tok_10', 'bigram_tok_11', 'bigram_tok_12',\n",
      "       'bigram_tok_13', 'bigram_tok_14', 'bigram_tok_15'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.631367. Std 0.8139\n",
      "RMSE by fold 0.631205. Std 0.0140\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_by_activity.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'Remove/Cut',\n",
      "       'Replace', 'Nonproduction', 'Input', 'Paste'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.630595. Std 0.8145\n",
      "RMSE by fold 0.630436. Std 0.0139\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.625925. Std 0.8176\n",
      "RMSE by fold 0.625779. Std 0.0134\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'word_count_sum',\n",
      "       'word_count_mean', 'word_count_std', 'word_count_max', 'word_count_q1',\n",
      "       'word_count_median', 'word_count_q3', 'word_count_kurt',\n",
      "       'word_count_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.631754. Std 0.8133\n",
      "RMSE by fold 0.631608. Std 0.0133\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_pauses.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.619496. Std 0.8196\n",
      "RMSE by fold 0.619324. Std 0.0144\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'input_text_count',\n",
      "       'input_text_len_mean', 'input_text_len_max', 'input_text_len_std',\n",
      "       'input_text_len_median', 'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.633285. Std 0.8141\n",
      "RMSE by fold 0.633136. Std 0.0135\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'eid_roc_count_zr',\n",
      "       'eid_roc_count', 'eid_roc_mean', 'eid_roc_std', 'eid_roc_max',\n",
      "       'eid_roc_q1', 'eid_roc_median', 'eid_roc_q3', 'eid_roc_kurt',\n",
      "       'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.627550. Std 0.8148\n",
      "RMSE by fold 0.627398. Std 0.0136\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_of_activities.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'activity_0_cnt',\n",
      "       'activity_1_cnt', 'activity_2_cnt', 'activity_3_cnt', 'activity_4_cnt'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.632093. Std 0.8147\n",
      "RMSE by fold 0.631973. Std 0.0121\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_time_based_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'cursor_pos_mean',\n",
      "       'cursor_pos_std', 'cursor_pos_max', 'cursor_pos_q1',\n",
      "       'cursor_pos_median', 'cursor_pos_q3', 'cursor_pos_kurt',\n",
      "       'cursor_pos_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.635080. Std 0.8129\n",
      "RMSE by fold 0.634954. Std 0.0125\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_p_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'burst_count',\n",
      "       'burst_mean', 'burst_sum', 'burst_std', 'burst_max', 'burst_min',\n",
      "       'burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.632122. Std 0.8128\n",
      "RMSE by fold 0.631964. Std 0.0139\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'action_time_mean',\n",
      "       'action_time_std', 'action_time_max'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.632090. Std 0.8138\n",
      "RMSE by fold 0.631951. Std 0.0131\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'action_time_mean',\n",
      "       'action_time_std', 'action_time_max', 'action_time_q1',\n",
      "       'action_time_median', 'action_time_q3', 'action_time_kurt',\n",
      "       'action_time_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.632777. Std 0.8108\n",
      "RMSE by fold 0.632660. Std 0.0120\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_words.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'word_len_count',\n",
      "       'word_len_mean', 'word_len_min', 'word_len_max', 'word_len_first',\n",
      "       'word_len_last', 'word_len_q1', 'word_len_median', 'word_len_q3',\n",
      "       'word_len_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.629940. Std 0.8176\n",
      "RMSE by fold 0.629814. Std 0.0123\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_paragraphs.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'paragraph_count',\n",
      "       'paragraph_len_mean', 'paragraph_len_min', 'paragraph_len_max',\n",
      "       'paragraph_len_first', 'paragraph_len_last', 'paragraph_len_q1',\n",
      "       'paragraph_len_median', 'paragraph_len_q3', 'paragraph_len_sum',\n",
      "       'paragraph_word_count_mean', 'paragraph_word_count_min',\n",
      "       'paragraph_word_count_max', 'paragraph_word_count_first',\n",
      "       'paragraph_word_count_last', 'paragraph_word_count_q1',\n",
      "       'paragraph_word_count_median', 'paragraph_word_count_q3',\n",
      "       'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.620188. Std 0.8188\n",
      "RMSE by fold 0.620047. Std 0.0129\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15', 'r_burst_count',\n",
      "       'r_burst_mean', 'r_burst_sum', 'r_burst_std', 'r_burst_max',\n",
      "       'r_burst_min', 'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.631072. Std 0.8137\n",
      "RMSE by fold 0.630917. Std 0.0138\n",
      "                                feat_name      RMSE\n",
      "0               train_count_vectorise.pkl  0.631284\n",
      "0                   train_essay_words.pkl  0.636652\n",
      "0               train_essay_sentences.pkl  0.636796\n",
      "0              train_essay_paragraphs.pkl  0.638007\n",
      "0                        train_pauses.pkl  0.642837\n",
      "0    train_word_counts_rate_of_change.pkl  0.644114\n",
      "0       train_count_vectorise_bigrams.pkl  0.650828\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.651236\n",
      "0  train_events_counts_rate_of_change.pkl  0.651657\n",
      "0           train_categorical_nunique.pkl  0.651915\n",
      "0              train_cursor_pos_stats.pkl  0.653055\n",
      "0                 train_events_counts.pkl  0.653867\n",
      "0       train_action_time_by_activity.pkl  0.654091\n",
      "0              train_word_count_stats.pkl  0.654467\n",
      "0           train_count_of_activities.pkl  0.654893\n",
      "0                  train_input_change.pkl  0.656129\n",
      "0                       train_r_burst.pkl  0.657154\n",
      "0                       train_p_burst.pkl  0.658135\n",
      "0             train_action_time_stats.pkl  0.658503\n",
      "0               train_essay_sentences.pkl  0.664262\n",
      "0               train_count_vectorise.pkl  0.670668\n",
      "0              train_essay_paragraphs.pkl  0.677797\n",
      "0                   train_essay_words.pkl  0.679655\n",
      "0    train_word_counts_rate_of_change.pkl  0.712249\n",
      "0       train_count_vectorise_bigrams.pkl  0.725255\n",
      "0           train_count_of_activities.pkl  0.729591\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.730703\n",
      "0              train_word_count_stats.pkl  0.733178\n",
      "0                        train_pauses.pkl  0.733643\n",
      "0              train_cursor_pos_stats.pkl  0.744848\n",
      "0                  train_input_change.pkl  0.757319\n",
      "0                       train_p_burst.pkl  0.761667\n",
      "0                train_event_id_stats.pkl  0.767516\n",
      "0  train_events_counts_rate_of_change.pkl  0.788705\n",
      "0       train_action_time_by_activity.pkl  0.824715\n",
      "0           train_categorical_nunique.pkl  0.906628\n",
      "0                       train_r_burst.pkl  0.947562\n",
      "0             train_action_time_stats.pkl  0.968697\n",
      "0               train_essay_sentences.pkl  0.623422\n",
      "0       train_count_vectorise_bigrams.pkl  0.631367\n",
      "0       train_action_time_by_activity.pkl  0.630595\n",
      "0    train_word_counts_rate_of_change.pkl  0.625925\n",
      "0              train_word_count_stats.pkl  0.631754\n",
      "0                        train_pauses.pkl  0.619496\n",
      "0                  train_input_change.pkl  0.633285\n",
      "0  train_events_counts_rate_of_change.pkl  0.627550\n",
      "0           train_count_of_activities.pkl  0.632093\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.635080\n",
      "0                       train_p_burst.pkl  0.632122\n",
      "0             train_action_time_stats.pkl  0.632090\n",
      "0              train_cursor_pos_stats.pkl  0.632777\n",
      "0                   train_essay_words.pkl  0.629940\n",
      "0              train_essay_paragraphs.pkl  0.620188\n",
      "0                       train_r_burst.pkl  0.631072\n",
      "Results:                                 feat_name      RMSE\n",
      "0                        train_pauses.pkl  0.619496\n",
      "0              train_essay_paragraphs.pkl  0.620188\n",
      "0               train_essay_sentences.pkl  0.623422\n",
      "0    train_word_counts_rate_of_change.pkl  0.625925\n",
      "0  train_events_counts_rate_of_change.pkl  0.627550\n",
      "0                   train_essay_words.pkl  0.629940\n",
      "0       train_action_time_by_activity.pkl  0.630595\n",
      "0                       train_r_burst.pkl  0.631072\n",
      "0               train_count_vectorise.pkl  0.631284\n",
      "0       train_count_vectorise_bigrams.pkl  0.631367\n",
      "0              train_word_count_stats.pkl  0.631754\n",
      "0             train_action_time_stats.pkl  0.632090\n",
      "0           train_count_of_activities.pkl  0.632093\n",
      "0                       train_p_burst.pkl  0.632122\n",
      "0              train_cursor_pos_stats.pkl  0.632777\n",
      "0                  train_input_change.pkl  0.633285\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.635080\n",
      "0                   train_essay_words.pkl  0.636652\n",
      "0               train_essay_sentences.pkl  0.636796\n",
      "0              train_essay_paragraphs.pkl  0.638007\n",
      "0                        train_pauses.pkl  0.642837\n",
      "0    train_word_counts_rate_of_change.pkl  0.644114\n",
      "0       train_count_vectorise_bigrams.pkl  0.650828\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.651236\n",
      "0  train_events_counts_rate_of_change.pkl  0.651657\n",
      "0           train_categorical_nunique.pkl  0.651915\n",
      "0              train_cursor_pos_stats.pkl  0.653055\n",
      "0                 train_events_counts.pkl  0.653867\n",
      "0       train_action_time_by_activity.pkl  0.654091\n",
      "0              train_word_count_stats.pkl  0.654467\n",
      "0           train_count_of_activities.pkl  0.654893\n",
      "0                  train_input_change.pkl  0.656129\n",
      "0                       train_r_burst.pkl  0.657154\n",
      "0                       train_p_burst.pkl  0.658135\n",
      "0             train_action_time_stats.pkl  0.658503\n",
      "0               train_essay_sentences.pkl  0.664262\n",
      "0               train_count_vectorise.pkl  0.670668\n",
      "0              train_essay_paragraphs.pkl  0.677797\n",
      "0                   train_essay_words.pkl  0.679655\n",
      "0    train_word_counts_rate_of_change.pkl  0.712249\n",
      "0       train_count_vectorise_bigrams.pkl  0.725255\n",
      "0           train_count_of_activities.pkl  0.729591\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.730703\n",
      "0              train_word_count_stats.pkl  0.733178\n",
      "0                        train_pauses.pkl  0.733643\n",
      "0              train_cursor_pos_stats.pkl  0.744848\n",
      "0                  train_input_change.pkl  0.757319\n",
      "0                       train_p_burst.pkl  0.761667\n",
      "0                train_event_id_stats.pkl  0.767516\n",
      "0  train_events_counts_rate_of_change.pkl  0.788705\n",
      "0       train_action_time_by_activity.pkl  0.824715\n",
      "0           train_categorical_nunique.pkl  0.906628\n",
      "0                       train_r_burst.pkl  0.947562\n",
      "0             train_action_time_stats.pkl  0.968697\n",
      "Results improved!\n",
      "list_train_feats: ['train_event_id_stats.pkl', 'train_categorical_nunique.pkl', 'train_essay_sentences.pkl', 'train_count_vectorise_bigrams.pkl', 'train_action_time_by_activity.pkl', 'train_word_counts_rate_of_change.pkl', 'train_word_count_stats.pkl', 'train_input_change.pkl', 'train_events_counts_rate_of_change.pkl', 'train_count_of_activities.pkl', 'train_time_based_cursor_pos_stats.pkl', 'train_p_burst.pkl', 'train_action_time_stats.pkl', 'train_cursor_pos_stats.pkl', 'train_essay_words.pkl', 'train_essay_paragraphs.pkl', 'train_r_burst.pkl']\n",
      "added_feats_list: ['train_events_counts.pkl', 'train_count_vectorise.pkl', 'train_pauses.pkl']\n",
      "best feat: train_pauses.pkl\n",
      "Starting round 3 of training feats\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_vectorise_bigrams.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'bigram_tok_0', 'bigram_tok_1', 'bigram_tok_2',\n",
      "       'bigram_tok_3', 'bigram_tok_4', 'bigram_tok_5', 'bigram_tok_6',\n",
      "       'bigram_tok_7', 'bigram_tok_8', 'bigram_tok_9', 'bigram_tok_10',\n",
      "       'bigram_tok_11', 'bigram_tok_12', 'bigram_tok_13', 'bigram_tok_14',\n",
      "       'bigram_tok_15'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.618509. Std 0.8206\n",
      "RMSE by fold 0.618334. Std 0.0145\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_by_activity.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'Remove/Cut', 'Replace', 'Nonproduction', 'Input',\n",
      "       'Paste'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.619394. Std 0.8194\n",
      "RMSE by fold 0.619236. Std 0.0138\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'roc_zro_count', 'pos_change_count', 'neg_change_count',\n",
      "       'roc_count', 'roc_mean', 'roc_std', 'roc_sum', 'roc_max', 'roc_q1',\n",
      "       'roc_median', 'roc_q3', 'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.620745. Std 0.8189\n",
      "RMSE by fold 0.620597. Std 0.0134\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'word_count_sum', 'word_count_mean', 'word_count_std',\n",
      "       'word_count_max', 'word_count_q1', 'word_count_median', 'word_count_q3',\n",
      "       'word_count_kurt', 'word_count_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.622746. Std 0.8184\n",
      "RMSE by fold 0.622576. Std 0.0143\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'input_text_count', 'input_text_len_mean',\n",
      "       'input_text_len_max', 'input_text_len_std', 'input_text_len_median',\n",
      "       'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.620756. Std 0.8181\n",
      "RMSE by fold 0.620592. Std 0.0140\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'eid_roc_count_zr', 'eid_roc_count', 'eid_roc_mean',\n",
      "       'eid_roc_std', 'eid_roc_max', 'eid_roc_q1', 'eid_roc_median',\n",
      "       'eid_roc_q3', 'eid_roc_kurt', 'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.619622. Std 0.8186\n",
      "RMSE by fold 0.619441. Std 0.0148\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_of_activities.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'activity_0_cnt', 'activity_1_cnt', 'activity_2_cnt',\n",
      "       'activity_3_cnt', 'activity_4_cnt'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.618854. Std 0.8202\n",
      "RMSE by fold 0.618668. Std 0.0150\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_time_based_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'cursor_pos_mean', 'cursor_pos_std', 'cursor_pos_max',\n",
      "       'cursor_pos_q1', 'cursor_pos_median', 'cursor_pos_q3',\n",
      "       'cursor_pos_kurt', 'cursor_pos_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.623699. Std 0.8175\n",
      "RMSE by fold 0.623551. Std 0.0134\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_p_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'burst_count', 'burst_mean', 'burst_sum', 'burst_std',\n",
      "       'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.619034. Std 0.8187\n",
      "RMSE by fold 0.618852. Std 0.0149\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'action_time_mean', 'action_time_std',\n",
      "       'action_time_max'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.619938. Std 0.8183\n",
      "RMSE by fold 0.619778. Std 0.0139\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'action_time_mean', 'action_time_std',\n",
      "       'action_time_max', 'action_time_q1', 'action_time_median',\n",
      "       'action_time_q3', 'action_time_kurt', 'action_time_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.622597. Std 0.8180\n",
      "RMSE by fold 0.622458. Std 0.0130\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_words.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'word_len_count', 'word_len_mean', 'word_len_min',\n",
      "       'word_len_max', 'word_len_first', 'word_len_last', 'word_len_q1',\n",
      "       'word_len_median', 'word_len_q3', 'word_len_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.617678. Std 0.8245\n",
      "RMSE by fold 0.617498. Std 0.0147\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_paragraphs.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612384. Std 0.8228\n",
      "RMSE by fold 0.612232. Std 0.0134\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'r_burst_count', 'r_burst_mean', 'r_burst_sum',\n",
      "       'r_burst_std', 'r_burst_max', 'r_burst_min', 'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.619195. Std 0.8184\n",
      "RMSE by fold 0.619013. Std 0.0149\n",
      "                                 feat_name      RMSE\n",
      "0                         train_pauses.pkl  0.619496\n",
      "0               train_essay_paragraphs.pkl  0.620188\n",
      "0                train_essay_sentences.pkl  0.623422\n",
      "0     train_word_counts_rate_of_change.pkl  0.625925\n",
      "0   train_events_counts_rate_of_change.pkl  0.627550\n",
      "..                                     ...       ...\n",
      "0              train_action_time_stats.pkl  0.619938\n",
      "0               train_cursor_pos_stats.pkl  0.622597\n",
      "0                    train_essay_words.pkl  0.617678\n",
      "0               train_essay_paragraphs.pkl  0.612384\n",
      "0                        train_r_burst.pkl  0.619195\n",
      "\n",
      "[68 rows x 2 columns]\n",
      "Results:                                  feat_name      RMSE\n",
      "0               train_essay_paragraphs.pkl  0.612384\n",
      "0                    train_essay_words.pkl  0.617678\n",
      "0        train_count_vectorise_bigrams.pkl  0.618509\n",
      "0            train_count_of_activities.pkl  0.618854\n",
      "0                        train_p_burst.pkl  0.619034\n",
      "..                                     ...       ...\n",
      "0   train_events_counts_rate_of_change.pkl  0.788705\n",
      "0        train_action_time_by_activity.pkl  0.824715\n",
      "0            train_categorical_nunique.pkl  0.906628\n",
      "0                        train_r_burst.pkl  0.947562\n",
      "0              train_action_time_stats.pkl  0.968697\n",
      "\n",
      "[68 rows x 2 columns]\n",
      "Results improved!\n",
      "list_train_feats: ['train_event_id_stats.pkl', 'train_categorical_nunique.pkl', 'train_essay_sentences.pkl', 'train_count_vectorise_bigrams.pkl', 'train_action_time_by_activity.pkl', 'train_word_counts_rate_of_change.pkl', 'train_word_count_stats.pkl', 'train_input_change.pkl', 'train_events_counts_rate_of_change.pkl', 'train_count_of_activities.pkl', 'train_time_based_cursor_pos_stats.pkl', 'train_p_burst.pkl', 'train_action_time_stats.pkl', 'train_cursor_pos_stats.pkl', 'train_essay_words.pkl', 'train_r_burst.pkl']\n",
      "added_feats_list: ['train_events_counts.pkl', 'train_count_vectorise.pkl', 'train_pauses.pkl', 'train_essay_paragraphs.pkl']\n",
      "best feat: train_essay_paragraphs.pkl\n",
      "Starting round 4 of training feats\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_by_activity.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'Remove/Cut',\n",
      "       'Replace', 'Nonproduction', 'Input', 'Paste'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611987. Std 0.8230\n",
      "RMSE by fold 0.611830. Std 0.0136\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611422. Std 0.8219\n",
      "RMSE by fold 0.611250. Std 0.0143\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'word_count_sum',\n",
      "       'word_count_mean', 'word_count_std', 'word_count_max', 'word_count_q1',\n",
      "       'word_count_median', 'word_count_q3', 'word_count_kurt',\n",
      "       'word_count_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.614259. Std 0.8216\n",
      "RMSE by fold 0.614107. Std 0.0134\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum',\n",
      "       'input_text_count', 'input_text_len_mean', 'input_text_len_max',\n",
      "       'input_text_len_std', 'input_text_len_median', 'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612859. Std 0.8221\n",
      "RMSE by fold 0.612702. Std 0.0137\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum',\n",
      "       'eid_roc_count_zr', 'eid_roc_count', 'eid_roc_mean', 'eid_roc_std',\n",
      "       'eid_roc_max', 'eid_roc_q1', 'eid_roc_median', 'eid_roc_q3',\n",
      "       'eid_roc_kurt', 'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.613033. Std 0.8217\n",
      "RMSE by fold 0.612878. Std 0.0135\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_of_activities.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'activity_0_cnt',\n",
      "       'activity_1_cnt', 'activity_2_cnt', 'activity_3_cnt', 'activity_4_cnt'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612923. Std 0.8229\n",
      "RMSE by fold 0.612769. Std 0.0135\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_time_based_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum',\n",
      "       'cursor_pos_mean', 'cursor_pos_std', 'cursor_pos_max', 'cursor_pos_q1',\n",
      "       'cursor_pos_median', 'cursor_pos_q3', 'cursor_pos_kurt',\n",
      "       'cursor_pos_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612322. Std 0.8220\n",
      "RMSE by fold 0.612187. Std 0.0126\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_p_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'burst_count',\n",
      "       'burst_mean', 'burst_sum', 'burst_std', 'burst_max', 'burst_min',\n",
      "       'burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612868. Std 0.8218\n",
      "RMSE by fold 0.612709. Std 0.0137\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum',\n",
      "       'action_time_mean', 'action_time_std', 'action_time_max'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612752. Std 0.8215\n",
      "RMSE by fold 0.612598. Std 0.0135\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum',\n",
      "       'action_time_mean', 'action_time_std', 'action_time_max',\n",
      "       'action_time_q1', 'action_time_median', 'action_time_q3',\n",
      "       'action_time_kurt', 'action_time_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611905. Std 0.8213\n",
      "RMSE by fold 0.611766. Std 0.0128\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_words.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'word_len_count',\n",
      "       'word_len_mean', 'word_len_min', 'word_len_max', 'word_len_first',\n",
      "       'word_len_last', 'word_len_q1', 'word_len_median', 'word_len_q3',\n",
      "       'word_len_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612217. Std 0.8255\n",
      "RMSE by fold 0.612042. Std 0.0144\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'r_burst_count',\n",
      "       'r_burst_mean', 'r_burst_sum', 'r_burst_std', 'r_burst_max',\n",
      "       'r_burst_min', 'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612466. Std 0.8226\n",
      "RMSE by fold 0.612311. Std 0.0135\n",
      "                            feat_name      RMSE\n",
      "0          train_essay_paragraphs.pkl  0.612384\n",
      "0               train_essay_words.pkl  0.617678\n",
      "0   train_count_vectorise_bigrams.pkl  0.618509\n",
      "0       train_count_of_activities.pkl  0.618854\n",
      "0                   train_p_burst.pkl  0.619034\n",
      "..                                ...       ...\n",
      "0                   train_p_burst.pkl  0.612868\n",
      "0         train_action_time_stats.pkl  0.612752\n",
      "0          train_cursor_pos_stats.pkl  0.611905\n",
      "0               train_essay_words.pkl  0.612217\n",
      "0                   train_r_burst.pkl  0.612466\n",
      "\n",
      "[80 rows x 2 columns]\n",
      "Results:                                  feat_name      RMSE\n",
      "0     train_word_counts_rate_of_change.pkl  0.611422\n",
      "0               train_cursor_pos_stats.pkl  0.611905\n",
      "0        train_action_time_by_activity.pkl  0.611987\n",
      "0                    train_essay_words.pkl  0.612217\n",
      "0    train_time_based_cursor_pos_stats.pkl  0.612322\n",
      "..                                     ...       ...\n",
      "0   train_events_counts_rate_of_change.pkl  0.788705\n",
      "0        train_action_time_by_activity.pkl  0.824715\n",
      "0            train_categorical_nunique.pkl  0.906628\n",
      "0                        train_r_burst.pkl  0.947562\n",
      "0              train_action_time_stats.pkl  0.968697\n",
      "\n",
      "[80 rows x 2 columns]\n",
      "Results improved!\n",
      "list_train_feats: ['train_event_id_stats.pkl', 'train_categorical_nunique.pkl', 'train_essay_sentences.pkl', 'train_count_vectorise_bigrams.pkl', 'train_action_time_by_activity.pkl', 'train_word_count_stats.pkl', 'train_input_change.pkl', 'train_events_counts_rate_of_change.pkl', 'train_count_of_activities.pkl', 'train_time_based_cursor_pos_stats.pkl', 'train_p_burst.pkl', 'train_action_time_stats.pkl', 'train_cursor_pos_stats.pkl', 'train_essay_words.pkl', 'train_r_burst.pkl']\n",
      "added_feats_list: ['train_events_counts.pkl', 'train_count_vectorise.pkl', 'train_pauses.pkl', 'train_essay_paragraphs.pkl', 'train_word_counts_rate_of_change.pkl']\n",
      "best feat: train_word_counts_rate_of_change.pkl\n",
      "Starting round 5 of training feats\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'word_count_sum', 'word_count_mean',\n",
      "       'word_count_std', 'word_count_max', 'word_count_q1',\n",
      "       'word_count_median', 'word_count_q3', 'word_count_kurt',\n",
      "       'word_count_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612422. Std 0.8216\n",
      "RMSE by fold 0.612272. Std 0.0133\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'input_text_count', 'input_text_len_mean',\n",
      "       'input_text_len_max', 'input_text_len_std', 'input_text_len_median',\n",
      "       'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611956. Std 0.8214\n",
      "RMSE by fold 0.611800. Std 0.0136\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'eid_roc_count_zr', 'eid_roc_count',\n",
      "       'eid_roc_mean', 'eid_roc_std', 'eid_roc_max', 'eid_roc_q1',\n",
      "       'eid_roc_median', 'eid_roc_q3', 'eid_roc_kurt', 'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611917. Std 0.8211\n",
      "RMSE by fold 0.611751. Std 0.0140\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_of_activities.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'activity_0_cnt', 'activity_1_cnt',\n",
      "       'activity_2_cnt', 'activity_3_cnt', 'activity_4_cnt'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612815. Std 0.8221\n",
      "RMSE by fold 0.612653. Std 0.0138\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_time_based_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'cursor_pos_mean', 'cursor_pos_std',\n",
      "       'cursor_pos_max', 'cursor_pos_q1', 'cursor_pos_median', 'cursor_pos_q3',\n",
      "       'cursor_pos_kurt', 'cursor_pos_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611665. Std 0.8200\n",
      "RMSE by fold 0.611520. Std 0.0131\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_p_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611297. Std 0.8213\n",
      "RMSE by fold 0.611141. Std 0.0136\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'action_time_mean', 'action_time_std',\n",
      "       'action_time_max'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612032. Std 0.8209\n",
      "RMSE by fold 0.611865. Std 0.0141\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'action_time_mean', 'action_time_std',\n",
      "       'action_time_max', 'action_time_q1', 'action_time_median',\n",
      "       'action_time_q3', 'action_time_kurt', 'action_time_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612106. Std 0.8213\n",
      "RMSE by fold 0.611961. Std 0.0131\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_words.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'word_len_count', 'word_len_mean',\n",
      "       'word_len_min', 'word_len_max', 'word_len_first', 'word_len_last',\n",
      "       'word_len_q1', 'word_len_median', 'word_len_q3', 'word_len_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612172. Std 0.8252\n",
      "RMSE by fold 0.612011. Std 0.0138\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'r_burst_count', 'r_burst_mean', 'r_burst_sum',\n",
      "       'r_burst_std', 'r_burst_max', 'r_burst_min', 'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612421. Std 0.8220\n",
      "RMSE by fold 0.612252. Std 0.0142\n",
      "                                feat_name      RMSE\n",
      "0    train_word_counts_rate_of_change.pkl  0.611422\n",
      "0              train_cursor_pos_stats.pkl  0.611905\n",
      "0       train_action_time_by_activity.pkl  0.611987\n",
      "0                   train_essay_words.pkl  0.612217\n",
      "0   train_time_based_cursor_pos_stats.pkl  0.612322\n",
      "..                                    ...       ...\n",
      "0                       train_p_burst.pkl  0.611297\n",
      "0             train_action_time_stats.pkl  0.612032\n",
      "0              train_cursor_pos_stats.pkl  0.612106\n",
      "0                   train_essay_words.pkl  0.612172\n",
      "0                       train_r_burst.pkl  0.612421\n",
      "\n",
      "[90 rows x 2 columns]\n",
      "Results:                                  feat_name      RMSE\n",
      "0                        train_p_burst.pkl  0.611297\n",
      "0     train_word_counts_rate_of_change.pkl  0.611422\n",
      "0    train_time_based_cursor_pos_stats.pkl  0.611665\n",
      "0               train_cursor_pos_stats.pkl  0.611905\n",
      "0   train_events_counts_rate_of_change.pkl  0.611917\n",
      "..                                     ...       ...\n",
      "0   train_events_counts_rate_of_change.pkl  0.788705\n",
      "0        train_action_time_by_activity.pkl  0.824715\n",
      "0            train_categorical_nunique.pkl  0.906628\n",
      "0                        train_r_burst.pkl  0.947562\n",
      "0              train_action_time_stats.pkl  0.968697\n",
      "\n",
      "[90 rows x 2 columns]\n",
      "Results improved!\n",
      "list_train_feats: ['train_event_id_stats.pkl', 'train_categorical_nunique.pkl', 'train_essay_sentences.pkl', 'train_count_vectorise_bigrams.pkl', 'train_action_time_by_activity.pkl', 'train_word_count_stats.pkl', 'train_input_change.pkl', 'train_events_counts_rate_of_change.pkl', 'train_count_of_activities.pkl', 'train_time_based_cursor_pos_stats.pkl', 'train_action_time_stats.pkl', 'train_cursor_pos_stats.pkl', 'train_essay_words.pkl', 'train_r_burst.pkl']\n",
      "added_feats_list: ['train_events_counts.pkl', 'train_count_vectorise.pkl', 'train_pauses.pkl', 'train_essay_paragraphs.pkl', 'train_word_counts_rate_of_change.pkl', 'train_p_burst.pkl']\n",
      "best feat: train_p_burst.pkl\n",
      "Starting round 6 of training feats\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median',\n",
      "       'input_text_count', 'input_text_len_mean', 'input_text_len_max',\n",
      "       'input_text_len_std', 'input_text_len_median', 'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612100. Std 0.8208\n",
      "RMSE by fold 0.611941. Std 0.0138\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median',\n",
      "       'eid_roc_count_zr', 'eid_roc_count', 'eid_roc_mean', 'eid_roc_std',\n",
      "       'eid_roc_max', 'eid_roc_q1', 'eid_roc_median', 'eid_roc_q3',\n",
      "       'eid_roc_kurt', 'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611373. Std 0.8205\n",
      "RMSE by fold 0.611198. Std 0.0144\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_of_activities.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median', 'activity_0_cnt',\n",
      "       'activity_1_cnt', 'activity_2_cnt', 'activity_3_cnt', 'activity_4_cnt'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612154. Std 0.8210\n",
      "RMSE by fold 0.611997. Std 0.0137\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_time_based_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median',\n",
      "       'cursor_pos_mean', 'cursor_pos_std', 'cursor_pos_max', 'cursor_pos_q1',\n",
      "       'cursor_pos_median', 'cursor_pos_q3', 'cursor_pos_kurt',\n",
      "       'cursor_pos_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611680. Std 0.8183\n",
      "RMSE by fold 0.611526. Std 0.0136\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median',\n",
      "       'action_time_mean', 'action_time_std', 'action_time_max'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611506. Std 0.8203\n",
      "RMSE by fold 0.611333. Std 0.0144\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_stats.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median',\n",
      "       'action_time_mean', 'action_time_std', 'action_time_max',\n",
      "       'action_time_q1', 'action_time_median', 'action_time_q3',\n",
      "       'action_time_kurt', 'action_time_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.611595. Std 0.8198\n",
      "RMSE by fold 0.611450. Std 0.0131\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_words.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median', 'word_len_count',\n",
      "       'word_len_mean', 'word_len_min', 'word_len_max', 'word_len_first',\n",
      "       'word_len_last', 'word_len_q1', 'word_len_median', 'word_len_q3',\n",
      "       'word_len_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612299. Std 0.8235\n",
      "RMSE by fold 0.612145. Std 0.0135\n",
      "Train feats  before merging Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median'],\n",
      "      dtype='object')\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst.pkl\n",
      "Train feats cols Index(['id', 'event_1', 'event_2', 'event_3', 'event_4', 'event_5', 'event_6',\n",
      "       'event_7', 'event_8', 'event_9', 'event_10', 'event_11', 'event_12',\n",
      "       'event_13', 'event_14', 'event_15', 'event_16', 'event_17', 'event_18',\n",
      "       'event_19', 'event_20', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3',\n",
      "       'tok_4', 'tok_5', 'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10',\n",
      "       'tok_11', 'tok_12', 'tok_13', 'tok_14', 'tok_15',\n",
      "       'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum', 'roc_zro_count',\n",
      "       'pos_change_count', 'neg_change_count', 'roc_count', 'roc_mean',\n",
      "       'roc_std', 'roc_sum', 'roc_max', 'roc_q1', 'roc_median', 'roc_q3',\n",
      "       'roc_kurt', 'roc_skew', 'burst_count', 'burst_mean', 'burst_sum',\n",
      "       'burst_std', 'burst_max', 'burst_min', 'burst_median', 'r_burst_count',\n",
      "       'r_burst_mean', 'r_burst_sum', 'r_burst_std', 'r_burst_max',\n",
      "       'r_burst_min', 'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.612298. Std 0.8210\n",
      "RMSE by fold 0.612128. Std 0.0143\n",
      "                                 feat_name      RMSE\n",
      "0                        train_p_burst.pkl  0.611297\n",
      "0     train_word_counts_rate_of_change.pkl  0.611422\n",
      "0    train_time_based_cursor_pos_stats.pkl  0.611665\n",
      "0               train_cursor_pos_stats.pkl  0.611905\n",
      "0   train_events_counts_rate_of_change.pkl  0.611917\n",
      "..                                     ...       ...\n",
      "0    train_time_based_cursor_pos_stats.pkl  0.611680\n",
      "0              train_action_time_stats.pkl  0.611506\n",
      "0               train_cursor_pos_stats.pkl  0.611595\n",
      "0                    train_essay_words.pkl  0.612299\n",
      "0                        train_r_burst.pkl  0.612298\n",
      "\n",
      "[98 rows x 2 columns]\n",
      "Results:                                  feat_name      RMSE\n",
      "0                        train_p_burst.pkl  0.611297\n",
      "0   train_events_counts_rate_of_change.pkl  0.611373\n",
      "0     train_word_counts_rate_of_change.pkl  0.611422\n",
      "0              train_action_time_stats.pkl  0.611506\n",
      "0               train_cursor_pos_stats.pkl  0.611595\n",
      "..                                     ...       ...\n",
      "0   train_events_counts_rate_of_change.pkl  0.788705\n",
      "0        train_action_time_by_activity.pkl  0.824715\n",
      "0            train_categorical_nunique.pkl  0.906628\n",
      "0                        train_r_burst.pkl  0.947562\n",
      "0              train_action_time_stats.pkl  0.968697\n",
      "\n",
      "[98 rows x 2 columns]\n",
      "Training Over!\n",
      "Best RMSE: 0.6113\n",
      "Best Feature Set: ['train_events_counts.pkl', 'train_count_vectorise.pkl', 'train_pauses.pkl', 'train_essay_paragraphs.pkl', 'train_word_counts_rate_of_change.pkl', 'train_p_burst.pkl']\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty DataFrames\n",
    "train_feats, test_feats = pd.DataFrame(), pd.DataFrame()\n",
    "best_rmse = float('inf')\n",
    "round = 0\n",
    "used_features = set()\n",
    "added_feats = []\n",
    "improved = True\n",
    "results = pd.DataFrame()\n",
    "\n",
    "while improved:\n",
    "    print(f'Starting round {round} of training feats')\n",
    "    improved = False\n",
    "    \n",
    "\n",
    "    for i in range(round, len(list_train_feats)):\n",
    "        tr_feats_cand = list_train_feats[i]\n",
    "\n",
    "        # Skip if this feature set has already been used\n",
    "        if tr_feats_cand in used_features:\n",
    "            continue\n",
    "\n",
    "        ts_feats_cand = tr_feats_cand.replace('train', 'test')\n",
    "        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{tr_feats_cand}')\n",
    "        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_feats_cand}')\n",
    "\n",
    "        # Keep track of columns before adding new features\n",
    "        existing_train_columns = set(train_feats.columns)\n",
    "        existing_test_columns = set(test_feats.columns)\n",
    "\n",
    "        if not(train_feats.empty & test_feats.empty):\n",
    "            print(f'feats not empty - merging with existing')\n",
    "            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "\n",
    "            if 'score' not in train_feats.columns:\n",
    "                train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "                \n",
    "            assert train_feats.shape[1] == test_feats.shape[1] + 1\n",
    "        else:\n",
    "            print(f'feats empty - setting up train_feats')\n",
    "            train_feats = tr_feats\n",
    "            test_feats = ts_feats\n",
    "            train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "        print(f'Training... {tr_feats_cand}')\n",
    "        print(f'Train feats cols {train_feats.columns}')\n",
    "        tr_cols = tr_feats.drop(columns=['id']).columns\n",
    "        ts_cols = ts_feats.drop(columns=['id']).columns\n",
    "        test_preds, valid_preds, final_rmse, cv_rm = lgb_pipeline(train_feats, test_feats, param)\n",
    "        temp_res = {'feat_name': tr_feats_cand, 'RMSE': final_rmse}\n",
    "        results = pd.concat([results, pd.DataFrame([temp_res])])\n",
    "\n",
    "        # Remove recently added features\n",
    "        train_feats.drop(columns=tr_cols, inplace=True)\n",
    "        test_feats.drop(columns=ts_cols, inplace=True)\n",
    "\n",
    "        # Add the current feature set to the used features\n",
    "        used_features.add(tr_feats_cand)\n",
    "    print(results)\n",
    "    results = results.sort_values('RMSE', ascending=True)\n",
    "    top_score = results.head(1).RMSE.values[0]\n",
    "    top_feat = results.head(1).feat_name.values[0]\n",
    "    print(f'Results: {results}')\n",
    "\n",
    "    if  top_score < best_rmse:\n",
    "        best_rmse = top_score\n",
    "        best_feat = top_feat\n",
    "        improved = True\n",
    "        used_features = set()\n",
    "        print(f'Results improved!')\n",
    "\n",
    "        ts_top_feat = top_feat.replace('train', 'test')\n",
    "        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{top_feat}')\n",
    "        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_top_feat}')\n",
    "\n",
    "        if round > 0:\n",
    "            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "\n",
    "        else:\n",
    "            train_feats = tr_feats\n",
    "            test_feats = ts_feats\n",
    "\n",
    "        added_feats.append(top_feat)\n",
    "        round += 1\n",
    "        list_train_feats = [feat for feat in list_train_feats if feat not in added_feats]\n",
    "        print(f'list_train_feats: {list_train_feats}')\n",
    "        print(f'added_feats_list: {added_feats}')\n",
    "        print(f'best feat: {top_feat}')\n",
    "\n",
    "    else:\n",
    "        print('Training Over!')\n",
    "\n",
    "print(f\"Best RMSE: {best_rmse:.4f}\")\n",
    "print(f\"Best Feature Set: {added_feats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... train_word_counts_rate_of_change.pkl\n"
     ]
    }
   ],
   "source": [
    "train_feats, test_feats = pd.DataFrame(), pd.DataFrame()\n",
    "results = pd.DataFrame()\n",
    "best_rmse = 0.8\n",
    "round = 0\n",
    "\n",
    "for k in range(len(list_train_feats)):\n",
    "    for i in range(round, len(list_train_feats)):\n",
    "        tr_feats_cand = list_train_feats[i]\n",
    "        ts_feats_cand = tr_feats_cand.replace('train', 'test')\n",
    "        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{tr_feats_cand}')\n",
    "        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_feats_cand}')\n",
    "\n",
    "        if not(train_feats.empty & test_feats.empty):\n",
    "            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "            assert train_feats.shape[1]==test_feats.shape[1]+1\n",
    "\n",
    "        else:\n",
    "            train_feats = tr_feats\n",
    "            test_feats = ts_feats\n",
    "            train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "        print(f'Training... {tr_feats_cand}')\n",
    "        tr_cols = train_feats.columns\n",
    "        ts_cols = test_feats.columns\n",
    "        test_preds, valid_preds, final_rmse, cv_rm = lgb_pipeline(train_feats, test_feats, param)\n",
    "        temp_res = {'feat_name':tr_feats_cand, 'RMSE': final_rmse}\n",
    "        results = pd.concat([results, pd.DataFrame([temp_res])])\n",
    "        train_feats.drop(columns=tr_cols, inplace=True)\n",
    "        test_feats.drop(columns=ts_cols, inplace=True)\n",
    "        #train_feats, test_feats = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    results = results.sort_values('RMSE', ascending=True)\n",
    "    best_feat = results.loc[round].feat_name\n",
    "    best_rmse = results.loc[round].RMSE\n",
    "    list_train_feats = list(results.feat_name)\n",
    "    round += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_word_counts_rate_of_change.pkl',\n",
       " 'train_count_of_activities.pkl',\n",
       " 'train_time_based_cursor_pos_stats.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_time_based_cursor_pos_stats.pkl</td>\n",
       "      <td>0.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_r_burst.pkl</td>\n",
       "      <td>0.709241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_word_counts_rate_of_change.pkl</td>\n",
       "      <td>0.711108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_time_based_cursor_pos_stats.pkl</td>\n",
       "      <td>0.732918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_word_count_stats.pkl</td>\n",
       "      <td>0.734315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_r_burst.pkl</td>\n",
       "      <td>0.949428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feat_name      RMSE\n",
       "0  train_time_based_cursor_pos_stats.pkl  0.691400\n",
       "0                      train_r_burst.pkl  0.709241\n",
       "0   train_word_counts_rate_of_change.pkl  0.711108\n",
       "0  train_time_based_cursor_pos_stats.pkl  0.732918\n",
       "0             train_word_count_stats.pkl  0.734315\n",
       "0                      train_r_burst.pkl  0.949428"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cursor_pos_mean</th>\n",
       "      <th>cursor_pos_std</th>\n",
       "      <th>cursor_pos_max</th>\n",
       "      <th>cursor_pos_q1</th>\n",
       "      <th>cursor_pos_median</th>\n",
       "      <th>cursor_pos_q3</th>\n",
       "      <th>cursor_pos_kurt</th>\n",
       "      <th>cursor_pos_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110982e4</td>\n",
       "      <td>1262.425000</td>\n",
       "      <td>561.058884</td>\n",
       "      <td>1804</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>-0.664586</td>\n",
       "      <td>-0.869034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe2065cc</td>\n",
       "      <td>613.865385</td>\n",
       "      <td>355.768763</td>\n",
       "      <td>1245</td>\n",
       "      <td>344.0</td>\n",
       "      <td>621.5</td>\n",
       "      <td>881.0</td>\n",
       "      <td>-0.982589</td>\n",
       "      <td>0.179027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9ce1a51f</td>\n",
       "      <td>1106.324324</td>\n",
       "      <td>426.571347</td>\n",
       "      <td>1708</td>\n",
       "      <td>946.0</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>-0.049410</td>\n",
       "      <td>-0.823053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8387640c</td>\n",
       "      <td>922.872727</td>\n",
       "      <td>483.943257</td>\n",
       "      <td>1621</td>\n",
       "      <td>492.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>-1.078332</td>\n",
       "      <td>-0.430539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ba082b4</td>\n",
       "      <td>2041.542373</td>\n",
       "      <td>1253.973675</td>\n",
       "      <td>3960</td>\n",
       "      <td>904.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3211.0</td>\n",
       "      <td>-1.348009</td>\n",
       "      <td>0.024787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>035f09fc</td>\n",
       "      <td>1036.129630</td>\n",
       "      <td>626.471642</td>\n",
       "      <td>2174</td>\n",
       "      <td>542.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>-1.037647</td>\n",
       "      <td>0.105922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>d68f5377</td>\n",
       "      <td>587.888889</td>\n",
       "      <td>361.275762</td>\n",
       "      <td>1300</td>\n",
       "      <td>281.0</td>\n",
       "      <td>586.5</td>\n",
       "      <td>903.0</td>\n",
       "      <td>-1.047864</td>\n",
       "      <td>0.052144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>5461650e</td>\n",
       "      <td>1013.368421</td>\n",
       "      <td>697.179948</td>\n",
       "      <td>2205</td>\n",
       "      <td>371.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>1733.0</td>\n",
       "      <td>-1.432414</td>\n",
       "      <td>0.153344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>21707506</td>\n",
       "      <td>778.227273</td>\n",
       "      <td>445.534060</td>\n",
       "      <td>1366</td>\n",
       "      <td>335.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>-1.508519</td>\n",
       "      <td>-0.007312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>b816ee8e</td>\n",
       "      <td>629.500000</td>\n",
       "      <td>508.636637</td>\n",
       "      <td>1585</td>\n",
       "      <td>141.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>-1.132734</td>\n",
       "      <td>0.467570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2471 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  cursor_pos_mean  cursor_pos_std  cursor_pos_max  \\\n",
       "0     110982e4      1262.425000      561.058884            1804   \n",
       "1     fe2065cc       613.865385      355.768763            1245   \n",
       "2     9ce1a51f      1106.324324      426.571347            1708   \n",
       "3     8387640c       922.872727      483.943257            1621   \n",
       "4     7ba082b4      2041.542373     1253.973675            3960   \n",
       "...        ...              ...             ...             ...   \n",
       "2466  035f09fc      1036.129630      626.471642            2174   \n",
       "2467  d68f5377       587.888889      361.275762            1300   \n",
       "2468  5461650e      1013.368421      697.179948            2205   \n",
       "2469  21707506       778.227273      445.534060            1366   \n",
       "2470  b816ee8e       629.500000      508.636637            1585   \n",
       "\n",
       "      cursor_pos_q1  cursor_pos_median  cursor_pos_q3  cursor_pos_kurt  \\\n",
       "0             925.0             1566.0         1722.0        -0.664586   \n",
       "1             344.0              621.5          881.0        -0.982589   \n",
       "2             946.0             1127.0         1426.0        -0.049410   \n",
       "3             492.0             1083.0         1292.0        -1.078332   \n",
       "4             904.0             2013.0         3211.0        -1.348009   \n",
       "...             ...                ...            ...              ...   \n",
       "2466          542.0             1029.0         1537.0        -1.037647   \n",
       "2467          281.0              586.5          903.0        -1.047864   \n",
       "2468          371.0              889.0         1733.0        -1.432414   \n",
       "2469          335.0              782.0         1303.0        -1.508519   \n",
       "2470          141.0              545.0         1102.0        -1.132734   \n",
       "\n",
       "      cursor_pos_skew  \n",
       "0           -0.869034  \n",
       "1            0.179027  \n",
       "2           -0.823053  \n",
       "3           -0.430539  \n",
       "4            0.024787  \n",
       "...               ...  \n",
       "2466         0.105922  \n",
       "2467         0.052144  \n",
       "2468         0.153344  \n",
       "2469        -0.007312  \n",
       "2470         0.467570  \n",
       "\n",
       "[2471 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>roc_zro_count</th>\n",
       "      <th>pos_change_count</th>\n",
       "      <th>neg_change_count</th>\n",
       "      <th>roc_count</th>\n",
       "      <th>roc_mean</th>\n",
       "      <th>roc_std</th>\n",
       "      <th>roc_sum</th>\n",
       "      <th>roc_max</th>\n",
       "      <th>roc_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>roc_skew</th>\n",
       "      <th>score</th>\n",
       "      <th>cursor_pos_mean</th>\n",
       "      <th>cursor_pos_std</th>\n",
       "      <th>cursor_pos_max</th>\n",
       "      <th>cursor_pos_q1</th>\n",
       "      <th>cursor_pos_median</th>\n",
       "      <th>cursor_pos_q3</th>\n",
       "      <th>cursor_pos_kurt</th>\n",
       "      <th>cursor_pos_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1c540433</td>\n",
       "      <td>103</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>224</td>\n",
       "      <td>0.197309</td>\n",
       "      <td>0.243458</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866687</td>\n",
       "      <td>3.0</td>\n",
       "      <td>579.277778</td>\n",
       "      <td>407.281062</td>\n",
       "      <td>1208</td>\n",
       "      <td>220.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>-1.359339</td>\n",
       "      <td>0.091134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b4e5001b</td>\n",
       "      <td>109</td>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>0.160727</td>\n",
       "      <td>0.199780</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.360474</td>\n",
       "      <td>2.5</td>\n",
       "      <td>755.673913</td>\n",
       "      <td>427.909131</td>\n",
       "      <td>1441</td>\n",
       "      <td>368.0</td>\n",
       "      <td>739.5</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>-1.184749</td>\n",
       "      <td>-0.001904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3c837aa3</td>\n",
       "      <td>215</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>0.128916</td>\n",
       "      <td>0.204499</td>\n",
       "      <td>42.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.465838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>603.725000</td>\n",
       "      <td>391.308455</td>\n",
       "      <td>1164</td>\n",
       "      <td>242.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>-1.425086</td>\n",
       "      <td>0.116625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3da4ab</td>\n",
       "      <td>187</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>370</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>0.374109</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763727</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1116.937500</td>\n",
       "      <td>891.496862</td>\n",
       "      <td>2711</td>\n",
       "      <td>264.0</td>\n",
       "      <td>1003.5</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>-1.288056</td>\n",
       "      <td>0.242083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497c5987</td>\n",
       "      <td>165</td>\n",
       "      <td>157</td>\n",
       "      <td>36</td>\n",
       "      <td>359</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.629851</td>\n",
       "      <td>69.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556865</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851.933333</td>\n",
       "      <td>456.773722</td>\n",
       "      <td>1766</td>\n",
       "      <td>567.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>-0.682669</td>\n",
       "      <td>0.380586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>a96dc180</td>\n",
       "      <td>260</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>0.324791</td>\n",
       "      <td>0.612918</td>\n",
       "      <td>116.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.640228</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2090.483871</td>\n",
       "      <td>984.694229</td>\n",
       "      <td>3540</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>2167.0</td>\n",
       "      <td>3096.0</td>\n",
       "      <td>-0.817958</td>\n",
       "      <td>-0.500164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>607f216d</td>\n",
       "      <td>157</td>\n",
       "      <td>183</td>\n",
       "      <td>12</td>\n",
       "      <td>353</td>\n",
       "      <td>0.288068</td>\n",
       "      <td>0.420927</td>\n",
       "      <td>101.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362688</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1684.074074</td>\n",
       "      <td>1042.431444</td>\n",
       "      <td>3098</td>\n",
       "      <td>630.0</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>2609.0</td>\n",
       "      <td>-1.355401</td>\n",
       "      <td>-0.182809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>f3b6b53e</td>\n",
       "      <td>118</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0.432530</td>\n",
       "      <td>0.452615</td>\n",
       "      <td>143.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873850</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2090.654545</td>\n",
       "      <td>1306.115391</td>\n",
       "      <td>4109</td>\n",
       "      <td>893.0</td>\n",
       "      <td>2216.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>-1.323111</td>\n",
       "      <td>-0.138195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>f01e26bb</td>\n",
       "      <td>162</td>\n",
       "      <td>201</td>\n",
       "      <td>6</td>\n",
       "      <td>370</td>\n",
       "      <td>0.308401</td>\n",
       "      <td>0.389481</td>\n",
       "      <td>113.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053007</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1733.836066</td>\n",
       "      <td>988.643788</td>\n",
       "      <td>3332</td>\n",
       "      <td>821.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>2571.0</td>\n",
       "      <td>-1.263554</td>\n",
       "      <td>-0.037653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>bf1a04b1</td>\n",
       "      <td>290</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>0.149584</td>\n",
       "      <td>0.343844</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.246229</td>\n",
       "      <td>3.0</td>\n",
       "      <td>928.863636</td>\n",
       "      <td>510.509577</td>\n",
       "      <td>1485</td>\n",
       "      <td>546.0</td>\n",
       "      <td>970.5</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>-1.208451</td>\n",
       "      <td>-0.383262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2471 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  roc_zro_count  pos_change_count  neg_change_count  roc_count  \\\n",
       "0     1c540433            103               115                 5        224   \n",
       "1     b4e5001b            109               164                 2        276   \n",
       "2     3c837aa3            215               116                 1        333   \n",
       "3     bc3da4ab            187               172                10        370   \n",
       "4     497c5987            165               157                36        359   \n",
       "...        ...            ...               ...               ...        ...   \n",
       "2466  a96dc180            260                98                 1        360   \n",
       "2467  607f216d            157               183                12        353   \n",
       "2468  f3b6b53e            118               212                 2        333   \n",
       "2469  f01e26bb            162               201                 6        370   \n",
       "2470  bf1a04b1            290                70                 1        362   \n",
       "\n",
       "      roc_mean   roc_std  roc_sum  roc_max  roc_q1  ...  roc_skew  score  \\\n",
       "0     0.197309  0.243458     44.0      1.0     0.0  ...  0.866687    3.0   \n",
       "1     0.160727  0.199780     44.2      0.6     0.0  ... -1.360474    2.5   \n",
       "2     0.128916  0.204499     42.8      1.0     0.0  ...  1.465838    2.0   \n",
       "3     0.260163  0.374109     96.0      1.4     0.0  ...  0.763727    4.5   \n",
       "4     0.193855  0.629851     69.4      4.4     0.0  ... -0.556865    3.0   \n",
       "...        ...       ...      ...      ...     ...  ...       ...    ...   \n",
       "2466  0.324791  0.612918    116.6      2.6     0.0  ...  1.640228    5.0   \n",
       "2467  0.288068  0.420927    101.4      1.8     0.0  ...  0.362688    5.0   \n",
       "2468  0.432530  0.452615    143.6      2.0     0.0  ...  0.873850    5.5   \n",
       "2469  0.308401  0.389481    113.8      1.8     0.0  ...  1.053007    5.5   \n",
       "2470  0.149584  0.343844     54.0      1.8     0.0  ...  2.246229    3.0   \n",
       "\n",
       "      cursor_pos_mean  cursor_pos_std  cursor_pos_max  cursor_pos_q1  \\\n",
       "0          579.277778      407.281062            1208          220.0   \n",
       "1          755.673913      427.909131            1441          368.0   \n",
       "2          603.725000      391.308455            1164          242.0   \n",
       "3         1116.937500      891.496862            2711          264.0   \n",
       "4          851.933333      456.773722            1766          567.0   \n",
       "...               ...             ...             ...            ...   \n",
       "2466      2090.483871      984.694229            3540         1553.0   \n",
       "2467      1684.074074     1042.431444            3098          630.0   \n",
       "2468      2090.654545     1306.115391            4109          893.0   \n",
       "2469      1733.836066      988.643788            3332          821.0   \n",
       "2470       928.863636      510.509577            1485          546.0   \n",
       "\n",
       "      cursor_pos_median  cursor_pos_q3  cursor_pos_kurt  cursor_pos_skew  \n",
       "0                 571.0         1001.0        -1.359339         0.091134  \n",
       "1                 739.5         1121.0        -1.184749        -0.001904  \n",
       "2                 571.0         1015.0        -1.425086         0.116625  \n",
       "3                1003.5         1953.0        -1.288056         0.242083  \n",
       "4                 720.0         1155.0        -0.682669         0.380586  \n",
       "...                 ...            ...              ...              ...  \n",
       "2466             2167.0         3096.0        -0.817958        -0.500164  \n",
       "2467             1824.0         2609.0        -1.355401        -0.182809  \n",
       "2468             2216.0         3329.0        -1.323111        -0.138195  \n",
       "2469             1775.0         2571.0        -1.263554        -0.037653  \n",
       "2470              970.5         1462.0        -1.208451        -0.383262  \n",
       "\n",
       "[2471 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Input text change features >\n",
      "< Action time by activities >\n",
      "< Events counts features >\n",
      "< Word counts rate of change features >\n",
      "< Categorical # unique values features >\n",
      "< word changes stats >\n",
      "< Count of events feats >\n",
      "< Cursor changes features >\n",
      "< Cursor changes based on time >\n",
      "< P-burst features >\n",
      "< R-burst features >\n",
      "< event_id rate of change >\n",
      "< Idle time features >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2471/2471 [00:04<00:00, 610.13it/s]\n",
      "100%|| 3/3 [00:00<00:00, 3084.80it/s]\n",
      "100%|| 2471/2471 [00:03<00:00, 640.53it/s]\n",
      "100%|| 3/3 [00:00<00:00, 3256.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Essays word feats >\n",
      "< Essays word feats >\n",
      "< Essays sentences feats >\n",
      "< Essays sentences feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n"
     ]
    }
   ],
   "source": [
    "file_name = 'input_change'\n",
    "tr, ts = input_text_change_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'count_of_activities'\n",
    "tr, ts = count_of_activities(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'action_time_by_activity'\n",
    "tr, ts = action_time_by_activity(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts'\n",
    "tr, ts = events_counts(train_logs, test_logs,)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_counts_rate_of_change'\n",
    "tr, ts = rate_of_change_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'categorical_nunique'\n",
    "tr, ts = categorical_nunique(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_count_stats'\n",
    "tr, ts = words_stats_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'event_id_stats'\n",
    "tr, ts = events_stats_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'action_time_stats'\n",
    "tr, ts = action_time_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'cursor_pos_stats'\n",
    "tr, ts = cursor_stats_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'time_based_cursor_pos_stats'\n",
    "tr, ts = time_based_cursor_stats_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'p_burst'\n",
    "tr, ts = p_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'r_burst'\n",
    "tr, ts = r_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts_rate_of_change'\n",
    "tr, ts = rate_of_change_events(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "# file_name = 'word_count_acceleration'\n",
    "# tr, ts = wc_acceleration_feats(train_logs, test_logs)\n",
    "# tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "# ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'pauses'\n",
    "tr, ts = create_pauses(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "\n",
    "train_logs = train_logs.collect().to_pandas()\n",
    "test_logs = test_logs.collect().to_pandas()\n",
    "file_name = 'count_vectorise'\n",
    "tr, ts = countvectorize_one_one(train_logs, test_logs)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'count_vectorise_bigrams'\n",
    "tr, ts = countvectorize_two_one(train_logs, test_logs)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_words'\n",
    "tr = word_feats(train_essays)\n",
    "ts = word_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_sentences'\n",
    "tr = sent_feats(train_essays)\n",
    "ts = sent_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_paragraphs'\n",
    "tr = parag_feats(train_essays)\n",
    "ts = parag_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Action time by activities >\n"
     ]
    }
   ],
   "source": [
    "file_name = 'p_burst'\n",
    "tr, ts = p_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'r_burst'\n",
    "tr, ts = r_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
