{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from m4_feats_polars import *\n",
    "from m5_sb_models import lgb_pipeline\n",
    "import polars as pl\n",
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_STORE = 'feature_store'\n",
    "data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n",
    "test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n",
    "train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')\n",
    "train_scores = train_scores.collect().to_pandas()\n",
    "\n",
    "param = {'n_estimators': 1024,\n",
    "         'learning_rate': 0.005,\n",
    "         'metric': 'rmse',\n",
    "         'force_col_wise': True,\n",
    "         'verbosity': 0,}\n",
    "\n",
    "feat_list = os.listdir(FEAT_STORE)\n",
    "list_train_feats = [feat for feat in feat_list if feat.startswith('train')]\n",
    "#test_feats = [feat for feat in feat_list if feat.startswith('test')]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 0 of training feats\n",
      "feats empty - setting up train_feats\n",
      "Training... train_categorical_nunique.pkl\n",
      "Train feats cols Index(['id', 'activity_nunique', 'down_event_nunique', 'text_change_nunique',\n",
      "       'score'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.908480. Std 0.5426\n",
      "RMSE by fold 0.908392. Std 0.0123\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_sentences.pkl\n",
      "Train feats cols Index(['id', 'score', 'sent_count', 'sent_len_mean', 'sent_len_min',\n",
      "       'sent_len_max', 'sent_len_first', 'sent_len_last', 'sent_len_q1',\n",
      "       'sent_len_median', 'sent_len_q3', 'sent_len_sum',\n",
      "       'sent_word_count_mean', 'sent_word_count_min', 'sent_word_count_max',\n",
      "       'sent_word_count_first', 'sent_word_count_last', 'sent_word_count_q1',\n",
      "       'sent_word_count_median', 'sent_word_count_q3', 'sent_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.665064. Std 0.8015\n",
      "RMSE by fold 0.664968. Std 0.0112\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst_feats.pkl\n",
      "Train feats cols Index(['id', 'score', 'r_burst_count', 'r_burst_mean', 'r_burst_sum',\n",
      "       'r_burst_std', 'r_burst_max', 'r_burst_min', 'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.948406. Std 0.5245\n",
      "RMSE by fold 0.948277. Std 0.0147\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_by_activity.pkl\n",
      "Train feats cols Index(['id', 'score', 'Input', 'Remove/Cut', 'Nonproduction', 'Replace',\n",
      "       'Paste'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.826575. Std 0.6673\n",
      "RMSE by fold 0.826376. Std 0.0181\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_time_based.pkl\n",
      "Train feats cols Index(['id', 'score', 'word_count_sum', 'word_count_mean', 'word_count_std',\n",
      "       'word_count_max', 'word_count_q1', 'word_count_median', 'word_count_q3',\n",
      "       'word_count_kurt', 'word_count_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.735067. Std 0.7535\n",
      "RMSE by fold 0.734832. Std 0.0187\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_acceleration.pkl\n",
      "Train feats cols Index(['id', 'score', 'cursor_pos_acc_zero', 'cursor_pos_acc_pst',\n",
      "       'cursor_pos_acc_neg', 'cursor_pos_acc_sum', 'cursor_pos_acc_mean',\n",
      "       'cursor_pos_acc_std', 'cursor_pos_acc_max', 'cursor_pos_acc_q1',\n",
      "       'cursor_pos_acc_median', 'cursor_pos_acc_q3', 'cursor_pos_acc_kurt',\n",
      "       'cursor_pos_acc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.806818. Std 0.6670\n",
      "RMSE by fold 0.806744. Std 0.0108\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'score', 'roc_zro_count', 'pos_change_count', 'neg_change_count',\n",
      "       'roc_count', 'roc_mean', 'roc_std', 'roc_sum', 'roc_max', 'roc_q1',\n",
      "       'roc_median', 'roc_q3', 'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.711248. Std 0.7719\n",
      "RMSE by fold 0.711106. Std 0.0145\n",
      "feats not empty - merging with existing\n",
      "Training... train_create_pauses.pkl\n",
      "Train feats cols Index(['id', 'score', 'inter_key_largest_lantency',\n",
      "       'inter_key_median_lantency', 'mean_pause_time', 'std_pause_time',\n",
      "       'total_pause_time', 'pauses_half_sec', 'pauses_1_sec',\n",
      "       'pauses_1_half_sec', 'pauses_2_sec', 'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.732684. Std 0.7417\n",
      "RMSE by fold 0.732418. Std 0.0197\n",
      "feats not empty - merging with existing\n",
      "Training... train_get_keys_pressed_per_second.pkl\n",
      "Train feats cols Index(['id', 'score', 'keys_per_second'], dtype='object')\n",
      "Final RMSE over 50: 0.799736. Std 0.6747\n",
      "RMSE by fold 0.799523. Std 0.0183\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_text_change_feats.pkl\n",
      "Train feats cols Index(['id', 'score', 'input_text_count', 'input_text_len_mean',\n",
      "       'input_text_len_max', 'input_text_len_std', 'input_text_len_median',\n",
      "       'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.754866. Std 0.7419\n",
      "RMSE by fold 0.754682. Std 0.0164\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_acceleration.pkl\n",
      "Train feats cols Index(['id', 'score', 'evid_acc_zero', 'evid_acc_pst', 'evid_acc_neg',\n",
      "       'evid_acc_sum', 'evid_acc_mean', 'evid_acc_std', 'evid_acc_max',\n",
      "       'evid_acc_q1', 'evid_acc_median', 'evid_acc_q3', 'evid_acc_kurt',\n",
      "       'evid_acc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.764311. Std 0.7185\n",
      "RMSE by fold 0.764117. Std 0.0171\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'score', 'eid_roc_count_zr', 'eid_roc_count', 'eid_roc_mean',\n",
      "       'eid_roc_std', 'eid_roc_max', 'eid_roc_q1', 'eid_roc_median',\n",
      "       'eid_roc_q3', 'eid_roc_kurt', 'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.788769. Std 0.6960\n",
      "RMSE by fold 0.788586. Std 0.0168\n",
      "feats not empty - merging with existing\n",
      "Training... train_p_burst_feats.pkl\n",
      "Train feats cols Index(['id', 'score', 'p_burst_count', 'p_burst_mean', 'p_burst_sum',\n",
      "       'p_burst_std', 'p_burst_max', 'p_burst_min', 'p_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.760490. Std 0.7358\n",
      "RMSE by fold 0.760338. Std 0.0152\n",
      "feats not empty - merging with existing\n",
      "Training... train_count_of_activities.pkl\n",
      "Train feats cols Index(['id', 'score', 'activity_0_cnt', 'activity_1_cnt', 'activity_2_cnt',\n",
      "       'activity_3_cnt', 'activity_4_cnt'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.731337. Std 0.7580\n",
      "RMSE by fold 0.731130. Std 0.0175\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_baseline.pkl\n",
      "Train feats cols Index(['id', 'score', 'eid_bline_sum', 'eid_bline_mean', 'eid_bline_std',\n",
      "       'eid_bline_max', 'eid_bline_q1', 'eid_bline_median', 'eid_bline_q3',\n",
      "       'eid_bline_kurt', 'eid_bline_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.794157. Std 0.6871\n",
      "RMSE by fold 0.793986. Std 0.0163\n",
      "feats not empty - merging with existing\n",
      "Training... train_down_events_counts.pkl\n",
      "Train feats cols Index(['id', 'score', 'down_event_1', 'down_event_2', 'down_event_3',\n",
      "       'down_event_4', 'down_event_5', 'down_event_6', 'down_event_7',\n",
      "       'down_event_8', 'down_event_9', 'down_event_10', 'down_event_11',\n",
      "       'down_event_12', 'down_event_13', 'down_event_14', 'down_event_15',\n",
      "       'down_event_16', 'down_event_17', 'down_event_18', 'down_event_19',\n",
      "       'down_event_20'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.655358. Std 0.7959\n",
      "RMSE by fold 0.655222. Std 0.0136\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_baseline_stats.pkl\n",
      "Train feats cols Index(['id', 'score', 'action_time_mean', 'action_time_std',\n",
      "       'action_time_max'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.968252. Std 0.4559\n",
      "RMSE by fold 0.968092. Std 0.0172\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_time_based.pkl\n",
      "Train feats cols Index(['id', 'score', 'cursor_pos_mean', 'cursor_pos_std', 'cursor_pos_max',\n",
      "       'cursor_pos_q1', 'cursor_pos_median', 'cursor_pos_q3',\n",
      "       'cursor_pos_kurt', 'cursor_pos_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.735820. Std 0.7568\n",
      "RMSE by fold 0.735572. Std 0.0193\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_words.pkl\n",
      "Train feats cols Index(['id', 'score', 'word_len_count', 'word_len_mean', 'word_len_min',\n",
      "       'word_len_max', 'word_len_first', 'word_len_last', 'word_len_q1',\n",
      "       'word_len_median', 'word_len_q3', 'word_len_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.677943. Std 0.8020\n",
      "RMSE by fold 0.677854. Std 0.0110\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_acceleration.pkl\n",
      "Train feats cols Index(['id', 'score', 'word_count_acc_zero', 'word_count_acc_pst',\n",
      "       'word_count_acc_neg', 'word_count_acc_sum', 'word_count_acc_mean',\n",
      "       'word_count_acc_std', 'word_count_acc_max', 'word_count_acc_q1',\n",
      "       'word_count_acc_median', 'word_count_acc_q3', 'word_count_acc_kurt',\n",
      "       'word_count_acc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.767324. Std 0.7143\n",
      "RMSE by fold 0.767015. Std 0.0215\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'score', 'cursor_pos_roc_count_zr', 'cursor_pos_pst_change_count',\n",
      "       'cursor_pos_neg_change_count', 'cursor_pos_roc_count',\n",
      "       'cursor_pos_roc_mean', 'cursor_pos_roc_std', 'cursor_pos_roc_max',\n",
      "       'cursor_pos_roc_q1', 'cursor_pos_roc_median', 'cursor_pos_roc_q3',\n",
      "       'cursor_pos_roc_kurt', 'cursor_pos_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.733840. Std 0.7479\n",
      "RMSE by fold 0.733684. Std 0.0153\n",
      "feats not empty - merging with existing\n",
      "Training... train_vector_two_gram.pkl\n",
      "Train feats cols Index(['id', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3', 'tok_4', 'tok_5',\n",
      "       'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10', 'tok_11', 'tok_12',\n",
      "       'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.726004. Std 0.7461\n",
      "RMSE by fold 0.725872. Std 0.0138\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_time_based.pkl\n",
      "Train feats cols Index(['id', 'score', 'eid_timeb_sum', 'eid_timeb_mean', 'eid_timeb_std',\n",
      "       'eid_timeb_max', 'eid_timeb_q1', 'eid_timeb_median', 'eid_timeb_q3',\n",
      "       'eid_timeb_kurt', 'eid_timeb_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.769167. Std 0.7228\n",
      "RMSE by fold 0.769029. Std 0.0147\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_paragraphs.pkl\n",
      "Train feats cols Index(['id', 'score', 'paragraph_count', 'paragraph_len_mean',\n",
      "       'paragraph_len_min', 'paragraph_len_max', 'paragraph_len_first',\n",
      "       'paragraph_len_last', 'paragraph_len_q1', 'paragraph_len_median',\n",
      "       'paragraph_len_q3', 'paragraph_len_sum', 'paragraph_word_count_mean',\n",
      "       'paragraph_word_count_min', 'paragraph_word_count_max',\n",
      "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
      "       'paragraph_word_count_q1', 'paragraph_word_count_median',\n",
      "       'paragraph_word_count_q3', 'paragraph_word_count_sum'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.678388. Std 0.7962\n",
      "RMSE by fold 0.678186. Std 0.0167\n",
      "feats not empty - merging with existing\n",
      "Training... train_vector_one_gram.pkl\n",
      "Train feats cols Index(['id', 'score', 'tok_0', 'tok_1', 'tok_2', 'tok_3', 'tok_4', 'tok_5',\n",
      "       'tok_6', 'tok_7', 'tok_8', 'tok_9', 'tok_10', 'tok_11', 'tok_12',\n",
      "       'tok_13', 'tok_14', 'tok_15'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.672245. Std 0.7933\n",
      "RMSE by fold 0.672101. Std 0.0138\n",
      "feats not empty - merging with existing\n",
      "Training... train_product_to_keys.pkl\n",
      "Train feats cols Index(['id', 'score', 'product_to_keys'], dtype='object')\n",
      "Final RMSE over 50: 1.031528. Std 0.2544\n",
      "RMSE by fold 1.031491. Std 0.0085\n",
      "Results improved!\n",
      "list_train_feats: ['train_categorical_nunique.pkl', 'train_essay_sentences.pkl', 'train_r_burst_feats.pkl', 'train_action_time_by_activity.pkl', 'train_word_count_time_based.pkl', 'train_cursor_pos_acceleration.pkl', 'train_word_counts_rate_of_change.pkl', 'train_create_pauses.pkl', 'train_get_keys_pressed_per_second.pkl', 'train_input_text_change_feats.pkl', 'train_events_counts_acceleration.pkl', 'train_events_counts_rate_of_change.pkl', 'train_p_burst_feats.pkl', 'train_count_of_activities.pkl', 'train_events_counts_baseline.pkl', 'train_action_time_baseline_stats.pkl', 'train_cursor_pos_time_based.pkl', 'train_essay_words.pkl', 'train_word_count_acceleration.pkl', 'train_cursor_pos_rate_of_change.pkl', 'train_vector_two_gram.pkl', 'train_events_counts_time_based.pkl', 'train_essay_paragraphs.pkl', 'train_vector_one_gram.pkl', 'train_product_to_keys.pkl']\n",
      "added_feats_list: ['train_down_events_counts.pkl']\n",
      "best feat: train_down_events_counts.pkl\n",
      "Starting round 1 of training feats\n",
      "feats not empty - merging with existing\n",
      "Training... train_essay_sentences.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'sent_count', 'sent_len_mean', 'sent_len_min', 'sent_len_max',\n",
      "       'sent_len_first', 'sent_len_last', 'sent_len_q1', 'sent_len_median',\n",
      "       'sent_len_q3', 'sent_len_sum', 'sent_word_count_mean',\n",
      "       'sent_word_count_min', 'sent_word_count_max', 'sent_word_count_first',\n",
      "       'sent_word_count_last', 'sent_word_count_q1', 'sent_word_count_median',\n",
      "       'sent_word_count_q3', 'sent_word_count_sum', 'score'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.636411. Std 0.8129\n",
      "RMSE by fold 0.636352. Std 0.0088\n",
      "feats not empty - merging with existing\n",
      "Training... train_r_burst_feats.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'r_burst_count', 'r_burst_mean', 'r_burst_sum', 'r_burst_std',\n",
      "       'r_burst_max', 'r_burst_min', 'r_burst_median'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.659306. Std 0.7949\n",
      "RMSE by fold 0.659243. Std 0.0092\n",
      "feats not empty - merging with existing\n",
      "Training... train_action_time_by_activity.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.655888. Std 0.7954\n",
      "RMSE by fold 0.655814. Std 0.0099\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_count_time_based.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'word_count_sum', 'word_count_mean', 'word_count_std',\n",
      "       'word_count_max', 'word_count_q1', 'word_count_median', 'word_count_q3',\n",
      "       'word_count_kurt', 'word_count_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.653274. Std 0.8004\n",
      "RMSE by fold 0.653178. Std 0.0111\n",
      "feats not empty - merging with existing\n",
      "Training... train_cursor_pos_acceleration.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'cursor_pos_acc_zero', 'cursor_pos_acc_pst',\n",
      "       'cursor_pos_acc_neg', 'cursor_pos_acc_sum', 'cursor_pos_acc_mean',\n",
      "       'cursor_pos_acc_std', 'cursor_pos_acc_max', 'cursor_pos_acc_q1',\n",
      "       'cursor_pos_acc_median', 'cursor_pos_acc_q3', 'cursor_pos_acc_kurt',\n",
      "       'cursor_pos_acc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.651792. Std 0.7965\n",
      "RMSE by fold 0.651733. Std 0.0087\n",
      "feats not empty - merging with existing\n",
      "Training... train_word_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'roc_zro_count', 'pos_change_count', 'neg_change_count',\n",
      "       'roc_count', 'roc_mean', 'roc_std', 'roc_sum', 'roc_max', 'roc_q1',\n",
      "       'roc_median', 'roc_q3', 'roc_kurt', 'roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.647113. Std 0.8056\n",
      "RMSE by fold 0.647038. Std 0.0098\n",
      "feats not empty - merging with existing\n",
      "Training... train_create_pauses.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'inter_key_largest_lantency', 'inter_key_median_lantency',\n",
      "       'mean_pause_time', 'std_pause_time', 'total_pause_time',\n",
      "       'pauses_half_sec', 'pauses_1_sec', 'pauses_1_half_sec', 'pauses_2_sec',\n",
      "       'pauses_3_sec'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.644624. Std 0.8048\n",
      "RMSE by fold 0.644551. Std 0.0095\n",
      "feats not empty - merging with existing\n",
      "Training... train_get_keys_pressed_per_second.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'keys_per_second'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.655823. Std 0.7975\n",
      "RMSE by fold 0.655750. Std 0.0097\n",
      "feats not empty - merging with existing\n",
      "Training... train_input_text_change_feats.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'input_text_count', 'input_text_len_mean',\n",
      "       'input_text_len_max', 'input_text_len_std', 'input_text_len_median',\n",
      "       'input_text_len_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.655855. Std 0.7982\n",
      "RMSE by fold 0.655759. Std 0.0113\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_acceleration.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'evid_acc_zero', 'evid_acc_pst', 'evid_acc_neg',\n",
      "       'evid_acc_sum', 'evid_acc_mean', 'evid_acc_std', 'evid_acc_max',\n",
      "       'evid_acc_q1', 'evid_acc_median', 'evid_acc_q3', 'evid_acc_kurt',\n",
      "       'evid_acc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.653901. Std 0.7967\n",
      "RMSE by fold 0.653867. Std 0.0066\n",
      "feats not empty - merging with existing\n",
      "Training... train_events_counts_rate_of_change.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'eid_roc_count_zr', 'eid_roc_count', 'eid_roc_mean',\n",
      "       'eid_roc_std', 'eid_roc_max', 'eid_roc_q1', 'eid_roc_median',\n",
      "       'eid_roc_q3', 'eid_roc_kurt', 'eid_roc_skew'],\n",
      "      dtype='object')\n",
      "Final RMSE over 50: 0.654432. Std 0.7975\n",
      "RMSE by fold 0.654360. Std 0.0097\n",
      "feats not empty - merging with existing\n",
      "Training... train_p_burst_feats.pkl\n",
      "Train feats cols Index(['id', 'down_event_1', 'down_event_2', 'down_event_3', 'down_event_4',\n",
      "       'down_event_5', 'down_event_6', 'down_event_7', 'down_event_8',\n",
      "       'down_event_9', 'down_event_10', 'down_event_11', 'down_event_12',\n",
      "       'down_event_13', 'down_event_14', 'down_event_15', 'down_event_16',\n",
      "       'down_event_17', 'down_event_18', 'down_event_19', 'down_event_20',\n",
      "       'score', 'p_burst_count', 'p_burst_mean', 'p_burst_sum', 'p_burst_std',\n",
      "       'p_burst_max', 'p_burst_min', 'p_burst_median'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty DataFrames\n",
    "train_feats, test_feats = pd.DataFrame(), pd.DataFrame()\n",
    "best_rmse = float('inf')\n",
    "round = 0\n",
    "used_features = set()\n",
    "added_feats = []\n",
    "improved = True\n",
    "results = pd.DataFrame()\n",
    "\n",
    "while improved:\n",
    "    print(f'Starting round {round} of training feats')\n",
    "    improved = False\n",
    "    \n",
    "\n",
    "    for i in range(round, len(list_train_feats)):\n",
    "        tr_feats_cand = list_train_feats[i]\n",
    "\n",
    "        # Skip if this feature set has already been used\n",
    "        if tr_feats_cand in used_features:\n",
    "            continue\n",
    "\n",
    "        ts_feats_cand = tr_feats_cand.replace('train', 'test')\n",
    "        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{tr_feats_cand}')\n",
    "        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_feats_cand}')\n",
    "\n",
    "        # Keep track of columns before adding new features\n",
    "        existing_train_columns = set(train_feats.columns)\n",
    "        existing_test_columns = set(test_feats.columns)\n",
    "\n",
    "        if not(train_feats.empty & test_feats.empty):\n",
    "            print(f'feats not empty - merging with existing')\n",
    "            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "\n",
    "            if 'score' not in train_feats.columns:\n",
    "                train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "                \n",
    "            assert train_feats.shape[1] == test_feats.shape[1] + 1\n",
    "        else:\n",
    "            print(f'feats empty - setting up train_feats')\n",
    "            train_feats = tr_feats\n",
    "            test_feats = ts_feats\n",
    "            train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "        print(f'Training... {tr_feats_cand}')\n",
    "        print(f'Train feats cols {train_feats.columns}')\n",
    "        tr_cols = tr_feats.drop(columns=['id']).columns\n",
    "        ts_cols = ts_feats.drop(columns=['id']).columns\n",
    "        test_preds, valid_preds, final_rmse, cv_rm = lgb_pipeline(train_feats, test_feats, param)\n",
    "        temp_res = {'feat_name': tr_feats_cand, 'RMSE': final_rmse}\n",
    "        results = pd.concat([results, pd.DataFrame([temp_res])])\n",
    "\n",
    "        # Remove recently added features\n",
    "        train_feats.drop(columns=tr_cols, inplace=True)\n",
    "        test_feats.drop(columns=ts_cols, inplace=True)\n",
    "\n",
    "        # Add the current feature set to the used features\n",
    "        used_features.add(tr_feats_cand)\n",
    "    #print(results)\n",
    "    results = results.sort_values('RMSE', ascending=True)\n",
    "    top_score = results.head(1).RMSE.values[0]\n",
    "    top_feat = results.head(1).feat_name.values[0]\n",
    "    #print(f'Results: {results}')\n",
    "\n",
    "    if  top_score < best_rmse:\n",
    "        best_rmse = top_score\n",
    "        best_feat = top_feat\n",
    "        improved = True\n",
    "        used_features = set()\n",
    "        print(f'Results improved!')\n",
    "\n",
    "        ts_top_feat = top_feat.replace('train', 'test')\n",
    "        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{top_feat}')\n",
    "        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_top_feat}')\n",
    "\n",
    "        if round > 0:\n",
    "            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "\n",
    "        else:\n",
    "            train_feats = tr_feats\n",
    "            test_feats = ts_feats\n",
    "\n",
    "        added_feats.append(top_feat)\n",
    "        round += 1\n",
    "        list_train_feats = [feat for feat in list_train_feats if feat not in added_feats]\n",
    "        print(f'list_train_feats: {list_train_feats}')\n",
    "        print(f'added_feats_list: {added_feats}')\n",
    "        print(f'best feat: {top_feat}')\n",
    "\n",
    "    else:\n",
    "        print('Training Over!')\n",
    "\n",
    "print(f\"Best RMSE: {best_rmse:.4f}\")\n",
    "print(f\"Best Feature Set: {added_feats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Input text change features >\n",
      "< Action time baseline stats >\n",
      "< Action time by activities >\n",
      "< Events counts features >\n",
      "< Categorical # unique values features >\n",
      "< word changes stats time based>\n",
      "< Word counts rate of change features >\n",
      "< word count acceleration >\n",
      "< Count of events baseline feats >\n",
      "< Count of events time based feats >\n",
      "< event_id rate of change >\n",
      "< events counts acceleration >\n",
      "< Cursor changes based on time >\n",
      "< event_id rate of change >\n",
      "< cursor position acceleration >\n",
      "< P-burst features >\n",
      "< R-burst features >\n",
      "< Idle time features >\n",
      "< Count vectorize one-grams >\n",
      "< Count vectorize bi-grams >\n",
      "< Essays word feats >\n",
      "< Essays word feats >\n",
      "< Essays sentences feats >\n",
      "< Essays sentences feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n"
     ]
    }
   ],
   "source": [
    "file_name = 'input_text_change_feats'\n",
    "tr, ts = input_text_change_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'count_of_activities'\n",
    "tr, ts = count_of_activities(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'action_time_baseline_stats'\n",
    "tr, ts = action_time_baseline_stats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'action_time_by_activity'\n",
    "tr, ts = action_time_by_activity(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'down_events_counts'\n",
    "tr, ts = down_events_counts(train_logs, test_logs, n_events=20)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'categorical_nunique'\n",
    "tr, ts = categorical_nunique(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_count_time_based'\n",
    "tr, ts = word_count_time_based(train_logs, test_logs, time_agg=12)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_counts_rate_of_change'\n",
    "tr, ts = word_counts_rate_of_change(train_logs, test_logs, time_agg=5)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_count_acceleration'\n",
    "tr, ts = word_count_acceleration(train_logs, test_logs, time_agg=8)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts_baseline'\n",
    "tr, ts = events_counts_baseline(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts_time_based'\n",
    "tr, ts = events_counts_time_based(train_logs, test_logs, time_agg=5)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts_rate_of_change'\n",
    "tr, ts = events_counts_rate_of_change(train_logs, test_logs, time_agg=10)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts_acceleration'\n",
    "tr, ts = events_counts_acceleration(train_logs, test_logs, time_agg=4)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'cursor_pos_time_based'\n",
    "tr, ts = cursor_pos_time_based(train_logs, test_logs, time_agg=30)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'cursor_pos_rate_of_change'\n",
    "tr, ts = cursor_pos_rate_of_change(train_logs, test_logs, time_agg=10)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'cursor_pos_acceleration'\n",
    "tr, ts = cursor_pos_acceleration(train_logs, test_logs, time_agg=6)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'p_burst_feats'\n",
    "tr, ts = p_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'r_burst_feats'\n",
    "tr, ts = r_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'create_pauses'\n",
    "tr, ts = create_pauses(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'get_keys_pressed_per_second'\n",
    "tr, ts = get_keys_pressed_per_second(train_logs.collect().to_pandas(), test_logs.collect().to_pandas())\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "\n",
    "train_essays = get_essay_df(train_logs.collect().to_pandas())\n",
    "test_essays = get_essay_df(test_logs.collect().to_pandas())\n",
    "\n",
    "file_name = 'vector_one_gram'\n",
    "tr, ts = countvectorize_one_one(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'vector_two_gram'\n",
    "tr, ts = countvectorize_two_one(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "\n",
    "file_name = 'product_to_keys'\n",
    "tr, ts = product_to_keys([train_logs.collect().to_pandas(), test_logs.collect().to_pandas()],\n",
    "                          [train_essays, test_essays])\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_words'\n",
    "tr = word_feats(train_essays)\n",
    "ts = word_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_sentences'\n",
    "tr = sent_feats(train_essays)\n",
    "ts = sent_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_paragraphs'\n",
    "tr = parag_feats(train_essays)\n",
    "ts = parag_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... train_word_counts_rate_of_change.pkl\n"
     ]
    }
   ],
   "source": [
    "train_feats, test_feats = pd.DataFrame(), pd.DataFrame()\n",
    "results = pd.DataFrame()\n",
    "best_rmse = 0.8\n",
    "round = 0\n",
    "\n",
    "for k in range(len(list_train_feats)):\n",
    "    for i in range(round, len(list_train_feats)):\n",
    "        tr_feats_cand = list_train_feats[i]\n",
    "        ts_feats_cand = tr_feats_cand.replace('train', 'test')\n",
    "        tr_feats = pd.read_pickle(f'{FEAT_STORE}/{tr_feats_cand}')\n",
    "        ts_feats = pd.read_pickle(f'{FEAT_STORE}/{ts_feats_cand}')\n",
    "\n",
    "        if not(train_feats.empty & test_feats.empty):\n",
    "            train_feats = train_feats.merge(tr_feats, on='id', how='left')\n",
    "            test_feats = test_feats.merge(ts_feats, on='id', how='left')\n",
    "            assert train_feats.shape[1]==test_feats.shape[1]+1\n",
    "\n",
    "        else:\n",
    "            train_feats = tr_feats\n",
    "            test_feats = ts_feats\n",
    "            train_feats = train_feats.merge(train_scores, on='id', how='left')\n",
    "\n",
    "        print(f'Training... {tr_feats_cand}')\n",
    "        tr_cols = train_feats.columns\n",
    "        ts_cols = test_feats.columns\n",
    "        test_preds, valid_preds, final_rmse, cv_rm = lgb_pipeline(train_feats, test_feats, param)\n",
    "        temp_res = {'feat_name':tr_feats_cand, 'RMSE': final_rmse}\n",
    "        results = pd.concat([results, pd.DataFrame([temp_res])])\n",
    "        train_feats.drop(columns=tr_cols, inplace=True)\n",
    "        test_feats.drop(columns=ts_cols, inplace=True)\n",
    "        #train_feats, test_feats = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    results = results.sort_values('RMSE', ascending=True)\n",
    "    best_feat = results.loc[round].feat_name\n",
    "    best_rmse = results.loc[round].RMSE\n",
    "    list_train_feats = list(results.feat_name)\n",
    "    round += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_word_counts_rate_of_change.pkl',\n",
       " 'train_count_of_activities.pkl',\n",
       " 'train_time_based_cursor_pos_stats.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Input text change features >\n",
      "< Action time by activities >\n",
      "< Events counts features >\n",
      "< Word counts rate of change features >\n",
      "< Categorical # unique values features >\n",
      "< word changes stats >\n",
      "< Count of events feats >\n",
      "< Cursor changes features >\n",
      "< Cursor changes based on time >\n",
      "< P-burst features >\n",
      "< R-burst features >\n",
      "< event_id rate of change >\n",
      "< Idle time features >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:04<00:00, 610.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3084.80it/s]\n",
      "100%|██████████| 2471/2471 [00:03<00:00, 640.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3256.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Essays word feats >\n",
      "< Essays word feats >\n",
      "< Essays sentences feats >\n",
      "< Essays sentences feats >\n",
      "< Essays paragraphs feats >\n",
      "< Essays paragraphs feats >\n"
     ]
    }
   ],
   "source": [
    "file_name = 'input_change'\n",
    "tr, ts = input_text_change_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'count_of_activities'\n",
    "tr, ts = count_of_activities(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'action_time_by_activity'\n",
    "tr, ts = action_time_by_activity(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts'\n",
    "tr, ts = events_counts(train_logs, test_logs,)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_counts_rate_of_change'\n",
    "tr, ts = rate_of_change_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'categorical_nunique'\n",
    "tr, ts = categorical_nunique(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'word_count_stats'\n",
    "tr, ts = words_stats_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'event_id_stats'\n",
    "tr, ts = events_stats_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'action_time_stats'\n",
    "tr, ts = action_time_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'cursor_pos_stats'\n",
    "tr, ts = cursor_stats_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'time_based_cursor_pos_stats'\n",
    "tr, ts = time_based_cursor_stats_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'p_burst'\n",
    "tr, ts = p_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'r_burst'\n",
    "tr, ts = r_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'events_counts_rate_of_change'\n",
    "tr, ts = rate_of_change_events(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "# file_name = 'word_count_acceleration'\n",
    "# tr, ts = wc_acceleration_feats(train_logs, test_logs)\n",
    "# tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "# ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'pauses'\n",
    "tr, ts = create_pauses(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "\n",
    "train_essays           = get_essay_df(train_logs.collect().to_pandas())\n",
    "test_essays           = get_essay_df(test_logs.collect().to_pandas())\n",
    "\n",
    "file_name = 'product_to_keys'\n",
    "tr, ts = product_to_keys([train_logs.collect().to_pandas(),\n",
    "                                      test_logs.collect().to_pandas()], \n",
    "                                      [train_essays,test_essays])\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "\n",
    "file_name = 'get_keys_pressed_per_second'\n",
    "tr, ts = get_keys_pressed_per_second(train_logs.collect().to_pandas(), test_logs.collect().to_pandas())\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "\n",
    "train_logs = train_logs.collect().to_pandas()\n",
    "test_logs = test_logs.collect().to_pandas()\n",
    "train_essays = get_essay_df(train_logs)\n",
    "test_essays = get_essay_df(test_logs)\n",
    "file_name = 'count_vectorise'\n",
    "tr, ts = countvectorize_one_one(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'count_vectorise_bigrams'\n",
    "tr, ts = countvectorize_two_one(train_essays, test_essays)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_words'\n",
    "tr = word_feats(train_essays)\n",
    "ts = word_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_sentences'\n",
    "tr = sent_feats(train_essays)\n",
    "ts = sent_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'essay_paragraphs'\n",
    "tr = parag_feats(train_essays)\n",
    "ts = parag_feats(test_essays)\n",
    "tr.to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Action time by activities >\n"
     ]
    }
   ],
   "source": [
    "file_name = 'p_burst'\n",
    "tr, ts = p_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')\n",
    "file_name = 'r_burst'\n",
    "tr, ts = r_burst_feats(train_logs, test_logs)\n",
    "tr.collect().to_pandas().to_pickle(f'{FEAT_STORE}/train_{file_name}.pkl')\n",
    "ts.collect().to_pandas().to_pickle(f'{FEAT_STORE}/test_{file_name}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
