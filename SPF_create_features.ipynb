{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from m4_feats_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'kaggle/input/linking-writing-processes-to-writing-quality'\n",
    "FEAT_STORE_DIR = 'feature_store'\n",
    "train_logs = pd.read_csv(f'{INPUT_DIR}/train_logs.csv')\n",
    "train_scores = pd.read_csv(f'{INPUT_DIR}/train_scores.csv')\n",
    "test_logs = pd.read_csv(f'{INPUT_DIR}/test_logs.csv')\n",
    "ss_df = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:04<00:00, 552.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2875.44it/s]\n"
     ]
    }
   ],
   "source": [
    "def countvectorize_one_one(train_logs, test_logs, train_feats, test_feats):\n",
    "    essays = getEssays(train_logs)\n",
    "    c_vect = CountVectorizer(ngram_range=(1, 2))\n",
    "    tr_toks = c_vect.fit_transform(essays['essay']).todense()\n",
    "    tr_toks_df = pd.DataFrame(columns = [f'tok_{i}' for i in range(tr_toks.shape[1])], data=tr_toks)\n",
    "    train_feats = pd.concat([train_feats['id'], tr_toks_df], axis=1)\n",
    "\n",
    "    test_essay = getEssays(test_logs)\n",
    "    ts_toks = c_vect.fit_transform(test_essay['essay']).todense()\n",
    "    ts_toks_df = pd.DataFrame(columns = [f'tok_{i}' for i in range(ts_toks.shape[1])], data=ts_toks)\n",
    "    test_feats = pd.concat([test_feats['id'], ts_toks_df], axis=1)\n",
    "    return train_feats, test_feats\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_1.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_1.pkl')\n",
    "train_, test_ = countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [00:04<00:00, 572.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2474, 27) (2474,)\n"
     ]
    }
   ],
   "source": [
    "def countvectorize_one_one(train_logs, test_logs, train_feats, test_feats):\n",
    "\n",
    "    tr_ids = train_feats.id\n",
    "    tst_ids = test_feats.id\n",
    "    tr_ts_logs = pd.concat([train_logs, test_logs], axis=0)\n",
    "    tr_ts_feats = pd.concat([train_feats['id'], test_feats['id']], axis=0).reset_index(drop=True)\n",
    "\n",
    "    essays = getEssays(tr_ts_logs)\n",
    "    c_vect = CountVectorizer(ngram_range=(1, 1))\n",
    "    toks = c_vect.fit_transform(essays['essay']).todense()\n",
    "    toks_df = pd.DataFrame(columns = [f'tok_{i}' for i in range(toks.shape[1])], data=toks)\n",
    "    toks_df.reset_index(drop=True, inplace=True)\n",
    "    print(toks_df.shape, tr_ts_feats.shape)\n",
    "\n",
    "    tr_ts_feats = pd.concat([tr_ts_feats, toks_df], axis=1)\n",
    "\n",
    "    train_feats = tr_ts_feats[tr_ts_feats['id'].isin(tr_ids)]\n",
    "    test_feats = tr_ts_feats[tr_ts_feats['id'].isin(tst_ids)]\n",
    "\n",
    "    return train_feats, test_feats\n",
    "\n",
    "train_feats = pd.read_pickle('feature_store/base_feats/train_base_feats_1.pkl')\n",
    "test_feats = pd.read_pickle('feature_store/base_feats/test_base_feats_1.pkl')\n",
    "train_, test_ = countvectorize_one_one(train_logs, test_logs, train_feats, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tok_0</th>\n",
       "      <th>tok_1</th>\n",
       "      <th>tok_2</th>\n",
       "      <th>tok_3</th>\n",
       "      <th>tok_4</th>\n",
       "      <th>tok_5</th>\n",
       "      <th>tok_6</th>\n",
       "      <th>tok_7</th>\n",
       "      <th>tok_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tok_17</th>\n",
       "      <th>tok_18</th>\n",
       "      <th>tok_19</th>\n",
       "      <th>tok_20</th>\n",
       "      <th>tok_21</th>\n",
       "      <th>tok_22</th>\n",
       "      <th>tok_23</th>\n",
       "      <th>tok_24</th>\n",
       "      <th>tok_25</th>\n",
       "      <th>tok_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022f953</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0042269b</td>\n",
       "      <td>61</td>\n",
       "      <td>88</td>\n",
       "      <td>67</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0059420b</td>\n",
       "      <td>64</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0075873a</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>ffb8c745</td>\n",
       "      <td>78</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>ffbef7e5</td>\n",
       "      <td>83</td>\n",
       "      <td>69</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>ffccd6fd</td>\n",
       "      <td>72</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>ffec5b38</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>fff05981</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>102</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2471 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  tok_0  tok_1  tok_2  tok_3  tok_4  tok_5  tok_6  tok_7  tok_8  \\\n",
       "0     001519c8      0      0      0      0      0      0      0      0      0   \n",
       "1     0022f953     53     46     36     37     21     19     13     19      8   \n",
       "2     0042269b     61     88     67     42     23     12      5      1      4   \n",
       "3     0059420b     64     70     61     49     29     37     31     32      6   \n",
       "4     0075873a     44     31     43     19     22     23      2      2      3   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2466  ffb8c745     78     49     45     37     27     20     17     26     10   \n",
       "2467  ffbef7e5     83     69     48     34     26     24      9     11     13   \n",
       "2468  ffccd6fd     72     56     56     47     23     21     14     13      8   \n",
       "2469  ffec5b38     49     39     55     37     19     26     13     11      3   \n",
       "2470  fff05981     74     78    102     51     34     30     23      8      3   \n",
       "\n",
       "      ...  tok_17  tok_18  tok_19  tok_20  tok_21  tok_22  tok_23  tok_24  \\\n",
       "0     ...       0       0       0       0       0       0       0       0   \n",
       "1     ...       0       0       0       0       0       0       0       0   \n",
       "2     ...       0       0       0       0       0       0       0       0   \n",
       "3     ...       0       0       0       0       0       0       0       0   \n",
       "4     ...       0       0       0       0       0       0       0       0   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2466  ...       0       0       0       0       0       0       0       0   \n",
       "2467  ...       0       0       0       0       0       0       0       0   \n",
       "2468  ...       0       0       0       0       0       0       0       0   \n",
       "2469  ...       0       0       0       0       0       0       0       0   \n",
       "2470  ...       0       0       0       0       0       0       0       0   \n",
       "\n",
       "      tok_25  tok_26  \n",
       "0          0       0  \n",
       "1          0       0  \n",
       "2          0       0  \n",
       "3          0       0  \n",
       "4          0       0  \n",
       "...      ...     ...  \n",
       "2466       0       0  \n",
       "2467       0       0  \n",
       "2468       0       0  \n",
       "2469       0       0  \n",
       "2470       0       0  \n",
       "\n",
       "[2471 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_id_max</th>\n",
       "      <th>up_time_max</th>\n",
       "      <th>action_time_max</th>\n",
       "      <th>action_time_min</th>\n",
       "      <th>action_time_mean</th>\n",
       "      <th>action_time_std</th>\n",
       "      <th>action_time_quantile</th>\n",
       "      <th>action_time_sem</th>\n",
       "      <th>action_time_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>tok_17</th>\n",
       "      <th>tok_18</th>\n",
       "      <th>tok_19</th>\n",
       "      <th>tok_20</th>\n",
       "      <th>tok_21</th>\n",
       "      <th>tok_22</th>\n",
       "      <th>tok_23</th>\n",
       "      <th>tok_24</th>\n",
       "      <th>tok_25</th>\n",
       "      <th>tok_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, event_id_max, up_time_max, action_time_max, action_time_min, action_time_mean, action_time_std, action_time_quantile, action_time_sem, action_time_sum, action_time_skew, action_time_kurt, activity_nunique, down_event_nunique, up_event_nunique, text_change_nunique, cursor_position_nunique, cursor_position_max, cursor_position_quantile, cursor_position_sem, cursor_position_mean, word_count_nunique, word_count_max, word_count_quantile, word_count_sem, word_count_mean, action_time_gap1_max, action_time_gap1_min, action_time_gap1_mean, action_time_gap1_std, action_time_gap1_quantile, action_time_gap1_sem, action_time_gap1_sum, action_time_gap1_skew, action_time_gap1_kurt, cursor_position_change1_max, cursor_position_change1_mean, cursor_position_change1_std, cursor_position_change1_quantile, cursor_position_change1_sem, cursor_position_change1_sum, cursor_position_change1_skew, cursor_position_change1_kurt, word_count_change1_max, word_count_change1_mean, word_count_change1_std, word_count_change1_quantile, word_count_change1_sem, word_count_change1_sum, word_count_change1_skew, word_count_change1_kurt, action_time_gap2_max, action_time_gap2_min, action_time_gap2_mean, action_time_gap2_std, action_time_gap2_quantile, action_time_gap2_sem, action_time_gap2_sum, action_time_gap2_skew, action_time_gap2_kurt, cursor_position_change2_max, cursor_position_change2_mean, cursor_position_change2_std, cursor_position_change2_quantile, cursor_position_change2_sem, cursor_position_change2_sum, cursor_position_change2_skew, cursor_position_change2_kurt, word_count_change2_max, word_count_change2_mean, word_count_change2_std, word_count_change2_quantile, word_count_change2_sem, word_count_change2_sum, word_count_change2_skew, word_count_change2_kurt, action_time_gap3_max, action_time_gap3_min, action_time_gap3_mean, action_time_gap3_std, action_time_gap3_quantile, action_time_gap3_sem, action_time_gap3_sum, action_time_gap3_skew, action_time_gap3_kurt, cursor_position_change3_max, cursor_position_change3_mean, cursor_position_change3_std, cursor_position_change3_quantile, cursor_position_change3_sem, cursor_position_change3_sum, cursor_position_change3_skew, cursor_position_change3_kurt, word_count_change3_max, word_count_change3_mean, word_count_change3_std, word_count_change3_quantile, word_count_change3_sem, word_count_change3_sum, word_count_change3_skew, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 445 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'count_vectorized_bigrams'\n",
    "\n",
    "train_.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:29<00:00,  2.72s/it, column=word_count_change100, method=kurt]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 12514.69it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 13338.93it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "100%|██████████| 2471/2471 [00:00<00:00, 9903.07it/s] \n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 13499.24it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 13254.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:360: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:361: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:362: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:363: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering ratios data\n",
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 22.36it/s, column=word_count_change100, method=kurt]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 39568.91it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 28992.88it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "100%|██████████| 3/3 [00:00<00:00, 26944.14it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 37008.56it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23087.91it/s]\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:360: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:361: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:362: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:363: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:04<00:00, 564.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2775.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2471, 375)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessor(seed=42)\n",
    "train_feats = preprocessor.make_feats(train_logs)\n",
    "test_feats = preprocessor.make_feats(test_logs)\n",
    "nan_cols = train_feats.columns[train_feats.isna().any()].tolist()\n",
    "train_feats = train_feats.drop(columns=nan_cols)\n",
    "test_feats = test_feats.drop(columns=nan_cols)\n",
    "\n",
    "train_, test_ = process_action_time_activity(train_logs, test_logs)\n",
    "train_feats = train_feats.merge(train_, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_, on='id', how='left')\n",
    "\n",
    "train_essay = getEssays(train_logs)\n",
    "test_essay = getEssays(test_logs)\n",
    "train_ = create_word_length_features(train_essay, 'essay_words', 'id', 'words')\n",
    "test_ = create_word_length_features(test_essay, 'essay_words', 'id', 'words')\n",
    "train_feats = train_feats.merge(train_, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_, on='id', how='left')\n",
    "\n",
    "train_sent_df = split_essays_into_sentences(train_essay)\n",
    "train_ = compute_sentence_aggregations(train_sent_df)\n",
    "test_ = compute_sentence_aggregations(split_essays_into_sentences(test_essay))\n",
    "train_feats = train_feats.merge(train_, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_, on='id', how='left')\n",
    "\n",
    "train_paragraph_df = split_essays_into_paragraphs(train_essay)\n",
    "train_ = compute_paragraph_aggregations(train_paragraph_df)\n",
    "test_ = compute_paragraph_aggregations(split_essays_into_paragraphs(test_essay))\n",
    "train_feats = train_feats.merge(train_, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_, on='id', how='left')\n",
    "##### feat_1\n",
    "train_, test_ = process_feats_time_gap_activity(train_logs, test_logs)\n",
    "train_feats = train_feats.merge(train_, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_, on='id', how='left')\n",
    "\n",
    "train_, test_ = process_feats_action_time_gap(train_logs, test_logs)\n",
    "train_feats = train_feats.merge(train_, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_, on='id', how='left')\n",
    "##### feat_2\n",
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2471, 495)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats = train_feats.merge(train_, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_, on='id', how='left')\n",
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train_feats_2_1.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test_feats_2_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:03<00:00, 630.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3413.70it/s]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'essay_words_feats'\n",
    "\n",
    "train_essay = getEssays(train_logs)\n",
    "test_essay = getEssays(test_logs)\n",
    "train_ = create_word_length_features(train_essay, 'essay_words', 'id', 'words')\n",
    "test_ = create_word_length_features(test_essay, 'essay_words', 'id', 'words')\n",
    "\n",
    "train_, test_ = process_feats_action_time_gap(train_logs, test_logs)\n",
    "\n",
    "train_, test_ = process_feats_time_gap_activity(train_logs, test_logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:24<00:00,  2.57s/it, column=word_count_change100, method=kurt]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 14360.23it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 12737.11it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "100%|██████████| 2471/2471 [00:00<00:00, 11716.33it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 14317.88it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 13897.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:360: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:361: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:362: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:363: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering ratios data\n",
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 23.38it/s, column=word_count_change100, method=kurt]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 18808.54it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 38956.38it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "100%|██████████| 3/3 [00:00<00:00, 36054.19it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 31855.47it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 38362.54it/s]\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:360: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:361: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:362: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:363: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n"
     ]
    }
   ],
   "source": [
    "file_name = 'base_feats'\n",
    "\n",
    "preprocessor = Preprocessor(seed=42)\n",
    "train_feats = preprocessor.make_feats(train_logs)\n",
    "test_feats = preprocessor.make_feats(test_logs)\n",
    "nan_cols = train_feats.columns[train_feats.isna().any()].tolist()\n",
    "train_feats = train_feats.drop(columns=nan_cols)\n",
    "test_feats = test_feats.drop(columns=nan_cols)\n",
    "\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essay_words = create_word_length_features(train_essay, 'essay_words', 'id', 'words')\n",
    "test_essay_words = create_word_length_features(test_essay, 'essay_words', 'id', 'words')\n",
    "train_essay_words.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_essay_words.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'at_by_bucket'\n",
    "train_action_buckets, test_action_buckets = action_time_by_bucket_feats(train_logs, test_logs)\n",
    "train_action_buckets.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_action_buckets.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'at_by_activ'\n",
    "train_at_by_act, test_at_by_act = process_action_time_activity(train_logs, test_logs)\n",
    "train_at_by_act.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_at_by_act.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'adj_eff_time'\n",
    "train_adj_eff_time, test_adj_eff_time = process_adjusted_eff_time(train_logs, test_logs)\n",
    "train_adj_eff_time.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_adj_eff_time.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2470/2470 [00:00<00:00, 4126.84it/s]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'rep_cut'\n",
    "train_rep_cut, test_rep_cut = process_re_cut_essays(train_logs, test_logs)\n",
    "train_rep_cut.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_rep_cut.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'action_time_gap'\n",
    "train_at_gap, test_at_gap = process_feats_action_time_gap(train_logs, test_logs)\n",
    "train_at_gap.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_at_gap.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'action_time_gap_by_acti'\n",
    "train_feats, test_feats = process_feats_time_gap_activity(train_logs, test_logs)\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'IKI'\n",
    "train_IKI = train_logs.groupby(['id']).apply(calculate_pause_features).reset_index()\n",
    "test_IKI = test_logs.groupby(['id']).apply(calculate_pause_features).reset_index()\n",
    "train_IKI.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_IKI.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'train_wc_chage'\n",
    "train_feats = create_feats_wc_change(train_logs)\n",
    "test_feats = create_feats_wc_change(test_logs)\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wpm_feats'\n",
    "train_feats, test_feats = wpm_feats(train_logs, test_logs)\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 317/317 [00:00<00:00, 16520.80it/s]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'essay_paste_words'\n",
    "train_feats, test_feats = essay_paste_words(train_logs, test_logs)\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:04<00:00, 578.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3821.11it/s]\n",
      "100%|██████████| 2471/2471 [00:04<00:00, 613.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_essays = getEssays(train_logs)\n",
    "test_essays = getEssays(test_logs)\n",
    "\n",
    "# Sentence features for train dataset\n",
    "train_essays = getEssays(train_logs)\n",
    "train_sent_df = split_essays_into_sentences(train_essays)\n",
    "train_sent_agg_df = compute_sentence_aggregations(train_sent_df)\n",
    "\n",
    "# Paragraph features for train dataset\n",
    "train_paragraph_df = split_essays_into_paragraphs(train_essays)\n",
    "train_paragraph_agg_df = compute_paragraph_aggregations(train_paragraph_df)\n",
    "\n",
    "# Features for test dataset\n",
    "test_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(test_essays))\n",
    "test_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(test_essays))\n",
    "\n",
    "file_name = 'essay_sen'\n",
    "train_sent_agg_df.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_sent_agg_df.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')\n",
    "\n",
    "file_name = 'essay_par'\n",
    "train_paragraph_agg_df.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_paragraph_agg_df.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
