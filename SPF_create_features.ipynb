{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from m4_feats_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'kaggle/input/linking-writing-processes-to-writing-quality'\n",
    "FEAT_STORE_DIR = 'feature_store'\n",
    "train_logs = pd.read_csv(f'{INPUT_DIR}/train_logs.csv')\n",
    "train_scores = pd.read_csv(f'{INPUT_DIR}/train_scores.csv')\n",
    "test_logs = pd.read_csv(f'{INPUT_DIR}/test_logs.csv')\n",
    "ss_df = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:24<00:00,  2.57s/it, column=word_count_change100, method=kurt]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 14360.23it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 12737.11it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "100%|██████████| 2471/2471 [00:00<00:00, 11716.33it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 14317.88it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 13897.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:360: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:361: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:362: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:363: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering ratios data\n",
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 23.38it/s, column=word_count_change100, method=kurt]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 18808.54it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 38956.38it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "100%|██████████| 3/3 [00:00<00:00, 36054.19it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 31855.47it/s]\n",
      "/root/miniconda3/envs/lrp/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 38362.54it/s]\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:360: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:361: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:362: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
      "/root/Projects/Kaggle/linking-writing/m4_feats_functions.py:363: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n"
     ]
    }
   ],
   "source": [
    "file_name = 'base_feats'\n",
    "\n",
    "preprocessor = Preprocessor(seed=42)\n",
    "train_feats = preprocessor.make_feats(train_logs)\n",
    "test_feats = preprocessor.make_feats(test_logs)\n",
    "nan_cols = train_feats.columns[train_feats.isna().any()].tolist()\n",
    "train_feats = train_feats.drop(columns=nan_cols)\n",
    "test_feats = test_feats.drop(columns=nan_cols)\n",
    "\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:03<00:00, 630.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3413.70it/s]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'essay_words_feats'\n",
    "\n",
    "train_essay = getEssays(train_logs)\n",
    "test_essay = getEssays(test_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essay_words = create_word_length_features(train_essay, 'essay_words', 'id', 'words')\n",
    "test_essay_words = create_word_length_features(test_essay, 'essay_words', 'id', 'words')\n",
    "train_essay_words.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_essay_words.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'at_by_bucket'\n",
    "train_action_buckets, test_action_buckets = action_time_by_bucket_feats(train_logs, test_logs)\n",
    "train_action_buckets.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_action_buckets.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'at_by_activ'\n",
    "train_at_by_act, test_at_by_act = process_action_time_activity(train_logs, test_logs)\n",
    "train_at_by_act.to_pickle(f'{FEAT_STORE_DIR}/train_{file_name}.pkl')\n",
    "test_at_by_act.to_pickle(f'{FEAT_STORE_DIR}/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'adj_eff_time'\n",
    "train_adj_eff_time, test_adj_eff_time = process_adjusted_eff_time(train_logs, test_logs)\n",
    "train_adj_eff_time.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_adj_eff_time.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2470/2470 [00:00<00:00, 4126.84it/s]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'rep_cut'\n",
    "train_rep_cut, test_rep_cut = process_re_cut_essays(train_logs, test_logs)\n",
    "train_rep_cut.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_rep_cut.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'action_time_gap'\n",
    "train_at_gap, test_at_gap = process_feats_action_time_gap(train_logs, test_logs)\n",
    "train_at_gap.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_at_gap.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'action_time_gap_by_acti'\n",
    "train_feats, test_feats = process_feats_time_gap_activity(train_logs, test_logs)\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'IKI'\n",
    "train_IKI = train_logs.groupby(['id']).apply(calculate_pause_features).reset_index()\n",
    "test_IKI = test_logs.groupby(['id']).apply(calculate_pause_features).reset_index()\n",
    "train_IKI.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_IKI.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'train_wc_chage'\n",
    "train_feats = create_feats_wc_change(train_logs)\n",
    "test_feats = create_feats_wc_change(test_logs)\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wpm_feats'\n",
    "train_feats, test_feats = wpm_feats(train_logs, test_logs)\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 317/317 [00:00<00:00, 16520.80it/s]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'essay_paste_words'\n",
    "train_feats, test_feats = essay_paste_words(train_logs, test_logs)\n",
    "train_feats.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_feats.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:04<00:00, 578.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3821.11it/s]\n",
      "100%|██████████| 2471/2471 [00:04<00:00, 613.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_essays = getEssays(train_logs)\n",
    "test_essays = getEssays(test_logs)\n",
    "\n",
    "# Sentence features for train dataset\n",
    "train_essays = getEssays(train_logs)\n",
    "train_sent_df = split_essays_into_sentences(train_essays)\n",
    "train_sent_agg_df = compute_sentence_aggregations(train_sent_df)\n",
    "\n",
    "# Paragraph features for train dataset\n",
    "train_paragraph_df = split_essays_into_paragraphs(train_essays)\n",
    "train_paragraph_agg_df = compute_paragraph_aggregations(train_paragraph_df)\n",
    "\n",
    "# Features for test dataset\n",
    "test_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(test_essays))\n",
    "test_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(test_essays))\n",
    "\n",
    "file_name = 'essay_sen'\n",
    "train_sent_agg_df.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_sent_agg_df.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')\n",
    "\n",
    "file_name = 'essay_par'\n",
    "train_paragraph_agg_df.to_pickle(f'{FEAT_STORE_DIR}/train/train_{file_name}.pkl')\n",
    "test_paragraph_agg_df.to_pickle(f'{FEAT_STORE_DIR}/test/test_{file_name}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
