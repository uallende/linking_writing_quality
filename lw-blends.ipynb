{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import polars as pl\n","import numpy as np\n","import re\n","from joblib import Parallel, delayed\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from scipy.stats import skew, kurtosis\n","from m4_feats_polars import *\n","from m5_sb_models import *\n","from m5_nn_models import *"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T01:54:18.577261Z","iopub.status.busy":"2024-01-01T01:54:18.576884Z","iopub.status.idle":"2024-01-01T01:54:18.594782Z","shell.execute_reply":"2024-01-01T01:54:18.593460Z","shell.execute_reply.started":"2024-01-01T01:54:18.577227Z"},"trusted":true},"outputs":[],"source":["lgb_params = {\n","    'boosting_type': 'gbdt', \n","    'metric': 'rmse',\n","    'reg_alpha': 0.0031, \n","    'reg_lambda': 0.001, \n","    'colsample_bytree': 0.8,  \n","    'subsample_freq': 1,  \n","    'subsample': 0.75,  \n","    'learning_rate': 0.017, \n","    'num_leaves': 19, \n","    'min_child_samples': 46,\n","    'n_estimators': 425,\n","    'verbosity': -1\n","    }\n","\n","xgb_params = {\n","    'alpha': 1,\n","    'colsample_bytree': 0.8,\n","    'gamma': 1.5,\n","    'learning_rate': 0.05,\n","    'max_depth': 4,\n","    'min_child_weight': 10,\n","    'subsample': 0.8,\n","    'device': 'cuda',\n","    'n_estimators': 400 \n","    }\n","\n","catboost_params = {\n","    'iterations': 250, \n","    'learning_rate': 0.1, \n","    'depth': 6, \n","    'loss_function': 'RMSE', \n","    'od_wait': 20, \n","    'od_type': 'Iter', \n","    'verbose': False, \n","    'metric_period': 50, \n","    'eval_metric': 'RMSE', \n","    'bagging_temperature': 0.2\n","}\n","\n","svr_params = {\n","    'C': 1.0, \n","    'cache_size': 200, \n","    'coef0': 0.0, \n","    'degree': 3, \n","    'epsilon': 0.1, \n","    'gamma': 'scale', \n","    'kernel': 'rbf', \n","    'max_iter': -1, \n","    'shrinking': True, \n","    'tol': 0.001, \n","    'verbose': False}\n","\n","ridge_params = {'alpha':325}\n","\n","data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n","train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n","test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n","train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T01:54:18.600448Z","iopub.status.busy":"2024-01-01T01:54:18.599074Z","iopub.status.idle":"2024-01-01T01:55:48.032489Z","shell.execute_reply":"2024-01-01T01:55:48.031438Z","shell.execute_reply.started":"2024-01-01T01:54:18.600397Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["< Events counts features >\n","< Count vectorize one-grams >\n","< Idle time features >\n","< word count acceleration >\n","< remove_words_time_spent >\n","< Count vectorize bi-grams >\n","< cursor position acceleration >\n","< R-burst features >\n","< Categorical # unique values features >\n","< removed words pauses basic\n","< word_wait_shift >\n","< event_id rate of change >\n","< Essays paragraphs feats >\n","< Essays paragraphs feats >\n","< Essays sentences feats >\n","< Essays sentences feats >\n","< Essays word feats >\n","< Essays word feats >\n","train feats shape (2471, 185)\n"]}],"source":["# PANDAS FEATS\n","train_essays          = get_essay_df(train_logs.collect().to_pandas())\n","test_essays           = get_essay_df(test_logs.collect().to_pandas())\n","\n","tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n","tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n","tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n","tr_word_c_acc, ts_word_c_acc = word_count_acceleration(train_logs, test_logs)\n","tr_rem_words_time_spent, ts_rem_words_time_spent = remove_words_time_spent(train_logs, test_logs)\n","tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n","tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n","tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n","tr_nuni, ts_nuni = categorical_nunique(train_logs, test_logs)\n","tr_remove_pause, ts_remove_pause = remove_word_pauses(train_logs, test_logs)\n","tr_word_wait, ts_word_wait = word_wait_shift(train_logs, test_logs, 1)\n","tr_e_counts_roc, ts_e_counts_roc = events_counts_rate_of_change(train_logs, test_logs, time_agg=3)\n","\n","train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n","train_feats = train_feats.join(tr_pauses, on='id', how='left')\n","train_feats = train_feats.join(tr_word_c_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_rem_words_time_spent, on='id', how='left')\n","train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n","train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_nuni, on='id', how='left')\n","train_feats = train_feats.join(tr_remove_pause, on='id', how='left')\n","train_feats = train_feats.join(tr_word_wait, on='id', how='left')\n","train_feats = train_feats.join(tr_e_counts_roc, on='id', how='left')\n","\n","test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n","test_feats = test_feats.join(ts_pauses, on='id', how='left')\n","test_feats = test_feats.join(ts_word_c_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_rem_words_time_spent, on='id', how='left')\n","test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n","test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_nuni, on='id', how='left')\n","test_feats = test_feats.join(ts_remove_pause, on='id', how='left')\n","test_feats = test_feats.join(ts_word_wait, on='id', how='left')\n","test_feats = test_feats.join(ts_e_counts_roc, on='id', how='left')\n","\n","train_logs = train_logs.collect().to_pandas()\n","test_logs = test_logs.collect().to_pandas()\n","train_scores = train_scores.collect().to_pandas()\n","train_feats = train_feats.collect().to_pandas()\n","test_feats = test_feats.collect().to_pandas()\n","\n","train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n","train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n","train_feats           = train_feats.merge(word_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(word_feats(test_essays), on='id', how='left')\n","\n","tr_sent_df = split_essays_into_sentences(train_essays)\n","ts_sent_df = split_essays_into_sentences(test_essays)\n","\n","train_feats           = train_feats.merge(sent_long_word_count(tr_sent_df), on='id', how='left')\n","test_feats            = test_feats.merge(sent_long_word_count(ts_sent_df), on='id', how='left')\n","\n","train_feats           = train_feats.merge(train_scores, on=['id'], how='left')\n","print(f'train feats shape {train_feats.shape}')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T01:55:48.033930Z","iopub.status.busy":"2024-01-01T01:55:48.033636Z","iopub.status.idle":"2024-01-01T02:13:21.396885Z","shell.execute_reply":"2024-01-01T02:13:21.395679Z","shell.execute_reply.started":"2024-01-01T01:55:48.033903Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["LGBM completed: 0.6046\n","LGBM weights completed: 0.6049\n","XGB completed: 0.6036\n","Catboost completed: 0.6101\n","Ridge completed: 0.6844\n","NN Dense light completed: 0.6045\n"]}],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","test_preds_lgbm, valid_preds_lgbm, final_rmse_lgbm, _ = lgb_pipeline(train_feats, test_feats, lgb_params)\n","print(f'LGBM completed: {final_rmse_lgbm:.4f}')\n","test_preds_lgbm_w, valid_preds_lgbm_w, final_rmse_lgbm_w, _ = lgb_w_pipeline(train_feats, test_feats, lgb_params)\n","print(f'LGBM weights completed: {final_rmse_lgbm_w:.4f}')\n","test_preds_xgb, valid_preds_xgb, final_rmse_xgb, _ = xgb_pipeline(train_feats, test_feats, xgb_params)\n","print(f'XGB completed: {final_rmse_xgb:.4f}')\n","test_preds_cat, valid_preds_cat, final_rmse_cat, _ = catboost_pipeline(train_feats, test_feats, catboost_params)\n","print(f'Catboost completed: {final_rmse_cat:.4f}')\n","test_preds_ridge, valid_preds_ridge, final_rmse_ridge, _ = ridge_pipeline(train_feats, test_feats, ridge_params)\n","print(f'Ridge completed: {final_rmse_ridge:.4f}')\n","valid_preds_automl, test_preds_automl, final_rmse_automl = automl_pipeline(train_feats, test_feats) \n","print(f'NN Dense light completed: {final_rmse_automl:.4f}')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# model_dir = '/kaggle/input/lw-automl-models'\n","# model_files = [f for f in os.listdir(model_dir) if f.endswith('.joblib')]\n","# models = []\n","\n","# for model_file in model_files:\n","#     model_path = os.path.join(model_dir, model_file)\n","#     model = joblib.load(model_path)\n","#     models.append(model)\n","\n","# automl_predictions = []\n","\n","# for model in models:\n","#     pred = model.predict(test_feats)\n","#     automl_predictions.append(pred)\n","    \n","# test_preds_stack = np.stack([p.data[:, 0] for p in automl_predictions])\n","# test_preds_mean = np.mean(test_preds_stack, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["valid_preds = {\n","    'xgboost': valid_preds_xgb,\n","    'lgbm': valid_preds_lgbm,\n","    'catboost': valid_preds_cat,\n","    'lgbm_w': valid_preds_lgbm_w,\n","    'ridge': valid_preds_ridge,\n","    'automl': valid_preds_automl,\n","}\n","\n","\n","test_preds= {\n","\n","    'xgboost': test_preds_xgb,\n","    'lgbm': test_preds_lgbm,\n","    'catboost': test_preds_cat,\n","    'lgbm_w': test_preds_lgbm_w,\n","    'ridge': test_preds_ridge,\n","    'automl': test_preds_automl,\n","\n","}\n","\n","# import pickle\n","\n","# with open('valid_preds.pkl', 'wb') as file:\n","#     pickle.dump(valid_preds, file)\n","\n","# with open('test_preds.pkl', 'wb') as file:\n","#     pickle.dump(test_preds, file)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# import pickle\n","# with open('valid_preds.pkl', 'rb') as file:\n","#     valid_preds = pickle.load(file)\n","\n","# with open('test_preds.pkl', 'rb') as file:\n","#     test_preds = pickle.load(file)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Baseline RMSE with simple average: 0.5989250470999172\n","Best RMSE: 0.5931609278035441\n","Best Model Combination: ('xgboost', 'lgbm_w', 'automl')\n","Best Weights: (0.2, 0.1, 0.4)\n"]}],"source":["import itertools\n","\n","simple_avg_df = pd.concat(valid_preds).groupby(['id','score'])['preds'].mean().reset_index()\n","mean_squared_error(simple_avg_df['score'], simple_avg_df['preds'], squared=False)\n","\n","baseline_rmse = mean_squared_error(simple_avg_df['score'], simple_avg_df['preds'], squared=False)\n","best_rmse = baseline_rmse\n","print(f\"Baseline RMSE with simple average: {baseline_rmse}\")\n","\n","for L in range(1, len(valid_preds) + 1):\n","    for subset in itertools.combinations(valid_preds, L):\n","        model_subset = {model: valid_preds[model] for model in subset}\n","\n","        for weights in itertools.product(np.linspace(0.1, 1.0, 10), repeat=len(subset)):\n","            weighted_avg = calculate_weighted_avg(weights, model_subset)\n","            rmse = mean_squared_error(simple_avg_df['score'], weighted_avg, squared=False)\n","            if rmse < best_rmse:\n","                best_rmse = rmse\n","                best_combination = subset\n","                best_weights = weights\n","\n","print(f\"Best RMSE: {best_rmse}\")\n","print(f\"Best Model Combination: {best_combination}\")\n","print(f\"Best Weights: {best_weights}\")\n","\n","# Baseline RMSE with simple average: 0.5989250470999172\n","# Best RMSE: 0.5931609278035441\n","# Best Model Combination: ('xgboost', 'lgbm_w', 'automl')\n","# Best Weights: (0.2, 0.1, 0.4)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Weights for Segment 1: (0.6409496887359202, ('lgbm_w', 'automl'), (0.7000000000000001, 0.5))\n","Best Weights for Segment 2: (0.6896785907049993, ('xgboost', 'lgbm', 'automl'), (1.0, 0.2, 0.5))\n","Best Weights for Segment 3: (0.58313018442317, ('xgboost', 'lgbm_w', 'ridge', 'automl'), (0.5, 0.1, 0.1, 1.0))\n"]}],"source":["def segment_predictions_by_score(valid_preds, lower_bound, upper_bound):\n","    # Determine the segmentation indices from the 'preds' of the first model\n","    first_model_key = next(iter(valid_preds))\n","    mask = (valid_preds[first_model_key]['preds'] >= lower_bound) & (valid_preds[first_model_key]['preds'] <= upper_bound)\n","    segmented_models = {}\n","    for k, v in valid_preds.items():\n","        # Apply the same mask to all models\n","        segmented_models[k] = v[mask]\n","    return segmented_models\n","\n","\n","def calculate_weighted_avg(weights, model_subset):\n","    weighted_preds = sum(model['preds'] * weight for model, weight in zip(model_subset.values(), weights))\n","    return weighted_preds / sum(weights)\n","\n","def find_best_weights_for_segment(segmented_models):\n","    best_rmse = float('inf')\n","    best_combination = None\n","    best_weights = None\n","\n","    # Extract true values from the first model's DataFrame in the segmented models\n","    true_values_segment = next(iter(segmented_models.values()))['score']\n","\n","    for L in range(1, len(segmented_models) + 1):\n","        for subset in itertools.combinations(segmented_models, L):\n","            model_subset = {model: segmented_models[model] for model in subset}\n","\n","            for weights in itertools.product(np.linspace(0.1, 1.0, 10), repeat=len(subset)):\n","                weighted_avg = np.average([model_subset[model]['preds'] for model in subset], weights=weights, axis=0)\n","                rmse = mean_squared_error(true_values_segment, weighted_avg, squared=False)\n","                if rmse < best_rmse:\n","                    best_rmse = rmse\n","                    best_combination = subset\n","                    best_weights = weights\n","    \n","    return best_rmse, best_combination, best_weights\n","\n","# Segment the datasets\n","segment1_models = segment_predictions_by_score(valid_preds, 0, 2.5)\n","segment2_models = segment_predictions_by_score(valid_preds, 5, 6.0)\n","segment3_models = segment_predictions_by_score(valid_preds, 2.5, 5)\n","\n","# Find the best weights for each segment\n","best_weights_segment1 = find_best_weights_for_segment(segment1_models)\n","best_weights_segment2 = find_best_weights_for_segment(segment2_models)\n","best_weights_segment3 = find_best_weights_for_segment(segment3_models)\n","\n","# Print best weights for each segment\n","print(\"Best Weights for Segment 1:\", best_weights_segment1)\n","print(\"Best Weights for Segment 2:\", best_weights_segment2)\n","print(\"Best Weights for Segment 3:\", best_weights_segment3)\n","\n","# Best Weights for Segment 1: (0.6409496887359202, ('lgbm_w', 'automl'), (0.7000000000000001, 0.5))\n","# Best Weights for Segment 2: (0.6896785907049993, ('xgboost', 'lgbm', 'automl'), (1.0, 0.2, 0.5))\n","# Best Weights for Segment 3: (0.58313018442317, ('xgboost', 'lgbm_w', 'ridge', 'automl'), (0.5, 0.1, 0.1, 1.0))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Final CV RMSE: 0.5924647034989626\n"]}],"source":["def apply_weights_to_segment(segment_models, models_used, weights):\n","    # Use the DataFrame structure to maintain indices\n","    segment_predictions_df = pd.DataFrame(index=segment_models[next(iter(models_used))].index)\n","    segment_predictions_df['weighted_preds'] = np.zeros_like(segment_models[next(iter(models_used))]['preds'])\n","\n","    for model, weight in zip(models_used, weights):\n","        segment_predictions_df['weighted_preds'] += segment_models[model]['preds'] * weight\n","    segment_predictions_df['weighted_preds'] /= sum(weights)\n","    return segment_predictions_df\n","\n","\n","# Apply weights to each validation segment\n","segment1_valid_df = apply_weights_to_segment(segment1_models, best_weights_segment1[1], best_weights_segment1[2])\n","segment2_valid_df = apply_weights_to_segment(segment2_models, best_weights_segment2[1], best_weights_segment2[2])\n","segment3_valid_df = apply_weights_to_segment(segment3_models, best_weights_segment3[1], best_weights_segment3[2])\n","\n","# Combine the DataFrames\n","combined_valid_df = pd.concat([segment1_valid_df, segment2_valid_df, segment3_valid_df])\n","combined_valid_df_sorted = combined_valid_df.sort_index()\n","\n","final_cv_rmse = mean_squared_error(train_scores.collect().to_pandas()['score'], combined_valid_df_sorted['weighted_preds'], squared=False)\n","print(f\"Final CV RMSE: {final_cv_rmse}\")"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model xgboost missing or has invalid scores in the segment.\n","Model lgbm missing or has invalid scores in the segment.\n","Model automl missing or has invalid scores in the segment.\n","Model lgbm_w missing or has invalid scores in the segment.\n","Model automl missing or has invalid scores in the segment.\n"]}],"source":["def segment_test_predictions(models, lower_bound, upper_bound):\n","    \"\"\"\n","    Segments the test predictions based on predicted score ranges.\n","    \"\"\"\n","    segmented_models = {}\n","    for model_name, preds_df in models.items():\n","        segmented_models[model_name] = preds_df[(preds_df['score'] >= lower_bound) & (preds_df['score'] <= upper_bound)]\n","    return segmented_models\n","\n","def apply_test_segment_weights(segment_models, models_used, weights):\n","    \"\"\"\n","    Apply weights to the models' predictions in a test segment and return a DataFrame.\n","    \"\"\"\n","    # Ensure weights sum is not zero to avoid division by zero\n","    total_weight = sum(weights)\n","    if total_weight == 0:\n","        raise ValueError(\"Sum of weights cannot be zero.\")\n","\n","    weighted_predictions_df = segment_models[next(iter(models_used))][['id']].copy()\n","    weighted_predictions_df['weighted_score'] = np.zeros_like(segment_models[next(iter(models_used))]['score'])\n","\n","    for model, weight in zip(models_used, weights):\n","        # Check if the model is in the segment and has valid scores\n","        if model in segment_models and not segment_models[model]['score'].isnull().all():\n","            weighted_predictions_df['weighted_score'] += segment_models[model]['score'] * weight\n","        else:\n","            # If a model is missing or has invalid scores, handle accordingly\n","            print(f\"Model {model} missing or has invalid scores in the segment.\")\n","\n","    weighted_predictions_df['weighted_score'] /= total_weight\n","    return weighted_predictions_df\n","\n","test_segment1 = segment_test_predictions(test_preds, -10, 2.5)\n","test_segment2 = segment_test_predictions(test_preds, 5, 10)\n","test_segment3 = segment_test_predictions(test_preds, 2.5, 5)\n","\n","test_segment1_df = apply_test_segment_weights(test_segment1, best_weights_segment1[1], best_weights_segment1[2])\n","test_segment2_df = apply_test_segment_weights(test_segment2, best_weights_segment2[1], best_weights_segment2[2])\n","test_segment3_df = apply_test_segment_weights(test_segment3, best_weights_segment3[1], best_weights_segment3[2])"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["test_preds = pd.concat([test_segment1_df, test_segment2_df, test_segment3_df], axis=0)\n","test_preds = test_preds.groupby('id')['weighted_score'].mean().reset_index()\n","test_preds.columns = ['id', 'score']\n","test_preds.to_csv('submission.csv', Index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6678907,"sourceId":59291,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
