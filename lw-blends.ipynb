{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import polars as pl\n","import numpy as np\n","import re\n","from joblib import Parallel, delayed\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from scipy.stats import skew, kurtosis\n","from m4_feats_polars import *\n","from m5_sb_models import *\n","from m5_nn_models import *"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T01:54:18.577261Z","iopub.status.busy":"2024-01-01T01:54:18.576884Z","iopub.status.idle":"2024-01-01T01:54:18.594782Z","shell.execute_reply":"2024-01-01T01:54:18.593460Z","shell.execute_reply.started":"2024-01-01T01:54:18.577227Z"},"trusted":true},"outputs":[],"source":["lgb_params = {\n","    'boosting_type': 'gbdt', \n","    'metric': 'rmse',\n","    'reg_alpha': 0.0031, \n","    'reg_lambda': 0.001, \n","    'colsample_bytree': 0.8,  \n","    'subsample_freq': 1,  \n","    'subsample': 0.75,  \n","    'learning_rate': 0.017, \n","    'num_leaves': 19, \n","    'min_child_samples': 46,\n","    'n_estimators': 350,\n","    'verbosity': -1\n","    }\n","\n","xgb_params = {\n","    'alpha': 1,\n","    'colsample_bytree': 0.8,\n","    'gamma': 1.5,\n","    'learning_rate': 0.05,\n","    'max_depth': 4,\n","    'min_child_weight': 10,\n","    'subsample': 0.8,\n","    'device': 'cuda',\n","    'n_estimators': 225 \n","    }\n","\n","catboost_params = {\n","    'iterations': 275, \n","    'learning_rate': 0.1, \n","    'depth': 6, \n","    'loss_function': 'RMSE', \n","    'od_wait': 20, \n","    'od_type': 'Iter', \n","    'verbose': False, \n","    'metric_period': 50, \n","    'eval_metric': 'RMSE', \n","    'bagging_temperature': 0.2\n","}\n","\n","svr_params = {\n","    'C': 1.0, \n","    'cache_size': 200, \n","    'coef0': 0.0, \n","    'degree': 3, \n","    'epsilon': 0.1, \n","    'gamma': 'scale', \n","    'kernel': 'rbf', \n","    'max_iter': -1, \n","    'shrinking': True, \n","    'tol': 0.001, \n","    'verbose': False}\n","\n","ridge_params = {'alpha':110}\n","\n","data_path     = 'kaggle/input/linking-writing-processes-to-writing-quality/'\n","train_logs    = pl.scan_csv(f'{data_path}/train_logs.csv')\n","test_logs    = pl.scan_csv(f'{data_path}/test_logs.csv')\n","train_scores = pl.scan_csv(f'{data_path}/train_scores.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T01:54:18.600448Z","iopub.status.busy":"2024-01-01T01:54:18.599074Z","iopub.status.idle":"2024-01-01T01:55:48.032489Z","shell.execute_reply":"2024-01-01T01:55:48.031438Z","shell.execute_reply.started":"2024-01-01T01:54:18.600397Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["< Events counts features >\n","< Count vectorize one-grams >\n","< Idle time features >\n","< word count acceleration >\n","< remove_words_time_spent >\n","< Count vectorize bi-grams >\n","< cursor position acceleration >\n","< R-burst features >\n","< Categorical # unique values features >\n","< removed words pauses basic\n","< word_wait_shift >\n","< event_id rate of change >\n","< Essays paragraphs feats >\n","< Essays paragraphs feats >\n","< Essays sentences feats >\n","< Essays sentences feats >\n","< Essays word feats >\n","< Essays word feats >\n","train feats shape (2471, 193)\n"]}],"source":["# PANDAS FEATS\n","train_essays          = get_essay_df(train_logs.collect().to_pandas())\n","test_essays           = get_essay_df(test_logs.collect().to_pandas())\n","\n","tr_down_events_counts, ts_down_events_counts = down_events_counts(train_logs, test_logs)\n","tr_vect_one, ts_vect_one = countvectorize_one_one(train_essays, test_essays)\n","tr_pauses, ts_pauses = create_pauses(train_logs, test_logs)\n","tr_word_c_acc, ts_word_c_acc = word_count_acceleration(train_logs, test_logs)\n","tr_rem_words_time_spent, ts_rem_words_time_spent = remove_words_time_spent(train_logs, test_logs)\n","tr_vect_two, ts_vect_two = countvectorize_two_one(train_essays, test_essays)\n","tr_cursor_pos_acc, ts_cursor_pos_acc = cursor_pos_acceleration(train_logs, test_logs)\n","tr_r_burst, ts_r_burst = r_burst_feats(train_logs, test_logs)\n","tr_nuni, ts_nuni = categorical_nunique(train_logs, test_logs)\n","tr_remove_pause, ts_remove_pause = remove_word_pauses(train_logs, test_logs)\n","tr_word_wait, ts_word_wait = word_wait_shift(train_logs, test_logs, 1)\n","tr_e_counts_roc, ts_e_counts_roc = events_counts_rate_of_change(train_logs, test_logs, time_agg=3)\n","\n","train_feats = tr_down_events_counts.join(tr_vect_one, on='id', how='left')\n","train_feats = train_feats.join(tr_pauses, on='id', how='left')\n","train_feats = train_feats.join(tr_word_c_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_rem_words_time_spent, on='id', how='left')\n","train_feats = train_feats.join(tr_vect_two, on='id', how='left')\n","train_feats = train_feats.join(tr_r_burst, on='id', how='left')\n","train_feats = train_feats.join(tr_cursor_pos_acc, on='id', how='left')\n","train_feats = train_feats.join(tr_nuni, on='id', how='left')\n","train_feats = train_feats.join(tr_remove_pause, on='id', how='left')\n","train_feats = train_feats.join(tr_word_wait, on='id', how='left')\n","train_feats = train_feats.join(tr_e_counts_roc, on='id', how='left')\n","\n","test_feats = ts_down_events_counts.join(ts_vect_one, on='id', how='left')\n","test_feats = test_feats.join(ts_pauses, on='id', how='left')\n","test_feats = test_feats.join(ts_word_c_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_rem_words_time_spent, on='id', how='left')\n","test_feats = test_feats.join(ts_vect_two, on='id', how='left')\n","test_feats = test_feats.join(ts_r_burst, on='id', how='left')\n","test_feats = test_feats.join(ts_cursor_pos_acc, on='id', how='left')\n","test_feats = test_feats.join(ts_nuni, on='id', how='left')\n","test_feats = test_feats.join(ts_remove_pause, on='id', how='left')\n","test_feats = test_feats.join(ts_word_wait, on='id', how='left')\n","test_feats = test_feats.join(ts_e_counts_roc, on='id', how='left')\n","\n","train_logs = train_logs.collect().to_pandas()\n","test_logs = test_logs.collect().to_pandas()\n","train_scores = train_scores.collect().to_pandas()\n","train_feats = train_feats.collect().to_pandas()\n","test_feats = test_feats.collect().to_pandas()\n","\n","train_feats           = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n","train_feats           = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n","train_feats           = train_feats.merge(word_feats(train_essays), on='id', how='left')\n","test_feats            = test_feats.merge(word_feats(test_essays), on='id', how='left')\n","\n","train_feats           = train_feats.merge(train_scores, on=['id'], how='left')\n","print(f'train feats shape {train_feats.shape}')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T01:55:48.033930Z","iopub.status.busy":"2024-01-01T01:55:48.033636Z","iopub.status.idle":"2024-01-01T02:13:21.396885Z","shell.execute_reply":"2024-01-01T02:13:21.395679Z","shell.execute_reply.started":"2024-01-01T01:55:48.033903Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["LGBM completed: 0.6059\n","LGBM weights completed: 0.6066\n","XGB completed: 0.6061\n","Catboost completed: 0.6102\n","Final RMSE over 50: 0.662327. Std 0.7668\n"]},{"ename":"NameError","evalue":"name 'final_rmse_ridge' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/root/Projects/Kaggle/linking-writing/lw-blends.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lw-blends.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m test_preds_svr, valid_preds_svr, final_rmse_svr, _ \u001b[39m=\u001b[39m svr_pipeline(train_feats, test_feats)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lw-blends.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# print(f'SVR completed: {final_rmse_svr:.4f}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lw-blends.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# test_preds_ridge, valid_preds_ridge, final_rmse_ridge, _ = ridge_pipeline(train_feats, test_feats, ridge_params)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lw-blends.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRidge completed: \u001b[39m\u001b[39m{\u001b[39;00mfinal_rmse_ridge\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lw-blends.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m oof_preds_automl, test_preds_automl, final_rmse_automl \u001b[39m=\u001b[39m automl_pipeline(train_feats, test_feats) \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/Projects/Kaggle/linking-writing/lw-blends.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNN Dense light completed: \u001b[39m\u001b[39m{\u001b[39;00mfinal_rmse_automl\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'final_rmse_ridge' is not defined"]}],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","test_preds_lgbm, valid_preds_lgbm, final_rmse_lgbm, _ = lgb_pipeline(train_feats, test_feats, lgb_params)\n","print(f'LGBM completed: {final_rmse_lgbm:.4f}')\n","test_preds_lgbm_w, valid_preds_lgbm_w, final_rmse_lgbm_w, _ = lgb_w_pipeline(train_feats, test_feats, lgb_params)\n","print(f'LGBM weights completed: {final_rmse_lgbm_w:.4f}')\n","test_preds_xgb, valid_preds_xgb, final_rmse_xgb, _ = xgb_pipeline(train_feats, test_feats, xgb_params)\n","print(f'XGB completed: {final_rmse_xgb:.4f}')\n","test_preds_cat, valid_preds_cat, final_rmse_cat, _ = catboost_pipeline(train_feats, test_feats, catboost_params)\n","print(f'Catboost completed: {final_rmse_cat:.4f}')\n","test_preds_ridge, valid_preds_ridge, final_rmse_ridge, _ = ridge_pipeline(train_feats, test_feats, ridge_params)\n","print(f'Ridge completed: {final_rmse_ridge:.4f}')\n","oof_preds_automl, test_preds_automl, final_rmse_automl = automl_pipeline(train_feats, test_feats) \n","print(f'NN Dense light completed: {final_rmse_automl:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model_dir = '/kaggle/input/lw-automl-models'\n","# model_files = [f for f in os.listdir(model_dir) if f.endswith('.joblib')]\n","# models = []\n","\n","# for model_file in model_files:\n","#     model_path = os.path.join(model_dir, model_file)\n","#     model = joblib.load(model_path)\n","#     models.append(model)\n","\n","# automl_predictions = []\n","\n","# for model in models:\n","#     pred = model.predict(test_feats)\n","#     automl_predictions.append(pred)\n","    \n","# test_preds_stack = np.stack([p.data[:, 0] for p in automl_predictions])\n","# test_preds_mean = np.mean(test_preds_stack, axis=0)"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Baseline RMSE with simple average: 0.6002777923179674\n","Best RMSE: 0.5957565255661937\n","Best Model Combination: ('xgboost', 'catboost', 'lgbm_w', 'automl')\n","Best Weights: (0.30000000000000004, 0.1, 0.2, 0.8)\n"]}],"source":["import numpy as np\n","import itertools\n","from sklearn.metrics import mean_squared_error\n","\n","models = {\n","    'xgboost': valid_preds_xgb,\n","    'lgbm': valid_preds_lgbm,\n","    'catboost': valid_preds_cat,\n","    'lgbm_w': valid_preds_lgbm_w,\n","    'ridge': valid_preds_ridge,\n","    'automl': oof_preds_automl,\n","}\n","\n","simple_avg_df = pd.concat(models).groupby(['id','score'])['preds'].mean().reset_index()\n","mean_squared_error(simple_avg_df['score'], simple_avg_df['preds'], squared=False)\n","\n","baseline_rmse = mean_squared_error(simple_avg_df['score'], simple_avg_df['preds'], squared=False)\n","best_rmse = baseline_rmse\n","print(f\"Baseline RMSE with simple average: {baseline_rmse}\")\n","\n","for L in range(1, len(models) + 1):\n","    for subset in itertools.combinations(models, L):\n","        model_subset = {model: models[model] for model in subset}\n","\n","        for weights in itertools.product(np.linspace(0.1, 1.0, 10), repeat=len(subset)):\n","            weighted_avg = calculate_weighted_avg(weights, model_subset)\n","            rmse = mean_squared_error(simple_avg_df['score'], weighted_avg, squared=False)\n","            if rmse < best_rmse:\n","                best_rmse = rmse\n","                best_combination = subset\n","                best_weights = weights\n","\n","print(f\"Best RMSE: {best_rmse}\")\n","print(f\"Best Model Combination: {best_combination}\")\n","print(f\"Best Weights: {best_weights}\")"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Weights for Segment 1: (1.154713207676848, ('lgbm_w',), (0.1,))\n","Best Weights for Segment 2: (0.8705831743229661, ('lgbm_w', 'automl'), (0.6, 0.8))\n","Best Weights for Segment 3: (0.5171814898166595, ('xgboost', 'catboost', 'ridge', 'automl'), (0.9, 0.4, 0.30000000000000004, 0.7000000000000001))\n"]}],"source":["### TARGET BLENDS ###\n","\n","import numpy as np\n","import itertools\n","from sklearn.metrics import mean_squared_error\n","\n","def segment_predictions_by_score(models, lower_bound, upper_bound):\n","\n","    segmented_models = {}\n","    for k, v in models.items():\n","        mask = (v['preds'] >= lower_bound) & (v['preds'] <= upper_bound)\n","        x = v[mask]\n","        segmented_models[k] = x\n","    return segmented_models\n","\n","def calculate_weighted_avg(weights, model_subset):\n","\n","    weighted_preds = sum(model['preds'] * weight for model, weight in zip(model_subset.values(), weights))\n","    return weighted_preds / sum(weights)\n","\n","def find_best_weights_for_segment(models):\n","    best_rmse = float('inf')\n","    best_combination = None\n","    best_weights = None\n","\n","    # Extract true values from any model's DataFrame\n","    true_values_segment = next(iter(models.values()))['score']\n","\n","    for L in range(1, len(models) + 1):\n","        for subset in itertools.combinations(models, L):\n","            model_subset = {model: models[model]['preds'] for model in subset}\n","\n","            for weights in itertools.product(np.linspace(0.1, 1.0, 10), repeat=len(subset)):\n","                weighted_avg = np.average([model_subset[model] for model in subset], \n","                                          weights=weights, axis=0)\n","                rmse = mean_squared_error(true_values_segment, weighted_avg, squared=False)\n","                if rmse < best_rmse:\n","                    best_rmse = rmse\n","                    best_combination = subset\n","                    best_weights = weights\n","    \n","    return best_rmse, best_combination, best_weights\n","\n","# Segment the datasets\n","segment1_models = segment_predictions_by_score(models, lower_bound=0, upper_bound=2.5)\n","segment2_models = segment_predictions_by_score(models, lower_bound=5, upper_bound=6.0)\n","segment3_models = segment_predictions_by_score(models, lower_bound=3, upper_bound=4.5)\n","\n","# Find the best weights for each segment\n","best_weights_segment1 = find_best_weights_for_segment(segment1_models)\n","best_weights_segment2 = find_best_weights_for_segment(segment2_models)\n","best_weights_segment3 = find_best_weights_for_segment(segment3_models)\n","\n","# Print best weights for each segment\n","print(\"Best Weights for Segment 1:\", best_weights_segment1)\n","print(\"Best Weights for Segment 2:\", best_weights_segment2)\n","print(\"Best Weights for Segment 3:\", best_weights_segment3)\n","\n","# Optional: Apply these weights to the corresponding segments of your validation or test dataset"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Final CV Score with segmented weights: 0.5892737382828971\n"]}],"source":["import numpy as np\n","from sklearn.metrics import mean_squared_error\n","\n","# Function to apply weights to a segment\n","def apply_segment_weights(segment_models, models_used, weights):\n","    \"\"\"\n","    Apply weights to the models' predictions in a segment.\n","    \"\"\"\n","    # Initialize an array of zeros for the segment predictions\n","    segment_predictions = np.zeros_like(next(iter(segment_models.values()))['score'])\n","\n","    for model, weight in zip(models_used, weights):\n","        segment_predictions += segment_models[model]['preds'] * weight\n","\n","    return segment_predictions / sum(weights)\n","\n","# Extract model names and weights for each segment\n","_, models_used_segment1, weights_segment1 = best_weights_segment1\n","_, models_used_segment2, weights_segment2 = best_weights_segment2\n","_, models_used_segment3, weights_segment3 = best_weights_segment3\n","\n","# Apply weights to each segment\n","segment1_predictions = apply_segment_weights(segment1_models, models_used_segment1, weights_segment1)\n","segment2_predictions = apply_segment_weights(segment2_models, models_used_segment2, weights_segment2)\n","segment3_predictions = apply_segment_weights(segment3_models, models_used_segment3, weights_segment3)\n","\n","# Prepare an array for combined predictions\n","combined_predictions = np.zeros_like(train_scores['score'].values)\n","\n","# Fill the combined predictions with segment predictions\n","# Ensure that indices in train_scores match those in each segment\n","combined_predictions[segment1_models[next(iter(segment1_models))].index] = segment1_predictions\n","combined_predictions[segment2_models[next(iter(segment2_models))].index] = segment2_predictions\n","combined_predictions[segment3_models[next(iter(segment3_models))].index] = segment3_predictions\n","\n","# Calculate the final CV score\n","final_cv_score = mean_squared_error(train_scores['score'].values, combined_predictions, squared=False)\n","print(f\"Final CV Score with segmented weights: {final_cv_score}\")"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["def segment_test_predictions(models, lower_bound, upper_bound):\n","    \"\"\"\n","    Segments the test predictions based on predicted score ranges.\n","    \"\"\"\n","    segmented_models = {}\n","    for model_name, preds_df in models.items():\n","        segmented_models[model_name] = preds_df[(preds_df['score'] >= lower_bound) & (preds_df['score'] <= upper_bound)]\n","    return segmented_models\n","\n","def apply_test_segment_weights(segment_models, models_used, weights):\n","    \"\"\"\n","    Apply weights to the models' predictions in a test segment and return a DataFrame.\n","    \"\"\"\n","    # Initialize a DataFrame to store the weighted predictions\n","    weighted_predictions_df = segment_models[next(iter(models_used))][['id']].copy()\n","    weighted_predictions_df['weighted_score'] = np.zeros_like(segment_models[next(iter(models_used))]['score'])\n","\n","    for model, weight in zip(models_used, weights):\n","        weighted_predictions_df['weighted_score'] += segment_models[model]['score'] * weight\n","\n","    weighted_predictions_df['weighted_score'] /= sum(weights)\n","    return weighted_predictions_df\n","\n","\n","\n","test_predictions = {\n","\n","    'xgboost': test_preds_xgb,\n","    'lgbm': test_preds_lgbm,\n","    'catboost': test_preds_cat,\n","    'lgbm_w': test_preds_lgbm_w,\n","    'ridge': test_preds_ridge,\n","    'automl': test_preds_automl,\n","\n","}\n","\n","# Segment test data\n","test_segment1 = segment_test_predictions(test_predictions, lower_bound=0.0, upper_bound=2.5)\n","test_segment2 = segment_test_predictions(test_predictions, lower_bound=5.0, upper_bound=6.0)\n","test_segment3 = segment_test_predictions(test_predictions, lower_bound=3.0, upper_bound=4.5)\n","\n","# Apply weights to each test segment\n","test_segment1_df = apply_test_segment_weights(test_segment1, models_used_segment1, weights_segment1)\n","test_segment2_df = apply_test_segment_weights(test_segment2, models_used_segment2, weights_segment2)\n","test_segment3_df = apply_test_segment_weights(test_segment3, models_used_segment3, weights_segment3)\n","\n","# Concatenate the DataFrames\n","combined_test_predictions_df = pd.concat([test_segment1_df, test_segment2_df, test_segment3_df])\n","combined_test_predictions_df = combined_test_predictions_df.sort_values(by='id')\n","\n","combined_test_predictions_df.to_csv('submission.csv', index=False)\n","combined_test_predictions_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Averaging test predictions for each model\n","# avg_test_preds_lgbm = average_test_predictions(test_preds_lgbm)\n","# avg_test_preds_xgb = average_test_predictions(test_preds_xgb)\n","# avg_test_preds_cat = average_test_predictions(test_preds_cat)\n","# avg_test_preds_svr = average_test_predictions(test_preds_svr)\n","# avg_test_preds_ridge = average_test_predictions(test_preds_ridge)\n","# avg_test_preds_automl = average_test_predictions(test_preds_automl)\n","\n","# # Dictionary of averaged test predictions\n","# test_predictions = {\n","#     'xgboost': avg_test_preds_xgb,\n","#     'lgbm': avg_test_preds_lgbm,\n","#     'catboost': avg_test_preds_cat,\n","#     'svr': avg_test_preds_svr,\n","#     'ridge': avg_test_preds_ridge\n","#     'automl': avg_test_preds_automl\n","# }\n","\n","# Baseline RMSE with simple average: 0.602766801612399\n","# Best RMSE: 0.5971908162938702\n","# Best Model Combination: ('xgboost', 'lgbm', 'catboost', 'ridge', 'automl')\n","# Best Weights: (0.7000000000000001, 1.0, 0.7000000000000001, 0.1, 1.0)\n","\n","\n","# Baseline RMSE with simple average: 0.6002777923179674\n","# Best RMSE: 0.5957565286697363\n","# Best Model Combination: ('xgboost', 'catboost', 'lgbm_w', 'automl')\n","# Best Weights: (0.30000000000000004, 0.1, 0.2, 0.8)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6678907,"sourceId":59291,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
